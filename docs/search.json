{
  "articles": [
    {
      "path": "classifier_bert.html",
      "title": "캡스톤 프로젝트",
      "description": "2022학년도 2학기 텍스트 정보처리와 NLP 수업내용입니다.\n한 학기 과정의 핵심 내용을 실습을 통해서 다시한번 다지기\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n텍스트 데이터 수집\n데이터 수집\n간단한 데이터 요약\n\n정규표현식의 이해\n패턴 검색\n\nDocument Term Matrix의\n이해\nDTM 생성하기\n\nCorrelation Analysis\n연관분석\nBinary Term Frequency\n기반 DTM 생성\n불용어 제거\nTransactions 생성하기\n연관규칙 생성하기\n연관규칙 시각화하기\n\n단어의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\nClustering\n군집의 해석\n\n기사의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\n군집 개수 선정 및\n시각화\n군집의 해석\n기사 군집 1\n\nTopic 분석\nOTF 계산\n불용어 제거\nTopic Modeling\nTopic 개수 구하기\nTop beta 단어의 시각화\n문서에서의 토픽의 비중\n토픽이 포함된 문서 조회\n문서의 토픽 분해\n토픽의 단어 분해\n\n이진분류 모형\n패키지 로드하기\n파생변수 만들기\n불균형 데이터의 언더\n샘플링\n데이터셋 분리\ntokenize 반복기 정의\nFrequency 기반의 DTM\n생성\nN-Grams 기반의 DTM 생성\nTF-IDF 기반의 DTM 생성\nDTM의 크기 비교\nFrequency 기반 모델링\n모델의 이해\n모델의 평가\n\n\n텍스트 데이터 수집\n데이터 수집\n인증키와 키워드 입력\nclient_id, client_secret는 사용자의 API 인증키를 삽입\n\n\nlibrary(koscrap)\n\n# Naver 뉴스 API 인증키\nclient_id <- \"D_7oXG2_osfloS1rLW2X\"\nclient_secret <- \"7Q8pd9QSnM\"\n\n# 검색 키워드\nkeyword <- \"월드컵\"\n\n\n\n날짜 정렬 기준 수집\n날짜 기준 정렬로 1,000건의 뉴스를 수집\n\n\nn <- 1000\n# 날짜 정렬 수집\nnews_worldcup_date <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret,\n  do_done = TRUE, max_record = n\n)\n\n\n* 검색된 총 기사 건수는 2741091건입니다.\n- (100/1000)건 호출을 진행합니다.\n- (200/1000)건 호출을 진행합니다.\n- (300/1000)건 호출을 진행합니다.\n- (400/1000)건 호출을 진행합니다.\n- (500/1000)건 호출을 진행합니다.\n- (600/1000)건 호출을 진행합니다.\n- (700/1000)건 호출을 진행합니다.\n- (800/1000)건 호출을 진행합니다.\n- (900/1000)건 호출을 진행합니다.\n- (1000/1000)건 호출을 진행합니다.\n\n유사도 정렬 기준 수집\n유사도 기준 정렬로 1,000건의 뉴스를 수집\n\n\n# 유사도 정렬 수집\nnews_worldcup_sim <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret, sort = \"sim\",\n  do_done = TRUE, max_record = n\n)\n\n\n* 검색된 총 기사 건수는 2741091건입니다.\n- (100/1000)건 호출을 진행합니다.\n- (200/1000)건 호출을 진행합니다.\n- (300/1000)건 호출을 진행합니다.\n- (400/1000)건 호출을 진행합니다.\n- (500/1000)건 호출을 진행합니다.\n- (600/1000)건 호출을 진행합니다.\n- (700/1000)건 호출을 진행합니다.\n- (800/1000)건 호출을 진행합니다.\n- (900/1000)건 호출을 진행합니다.\n- (1000/1000)건 호출을 진행합니다.\n\n데이터를 수집하는 시점에 따라 결과가 다르겠지만, 각각 1000건의\n데이터가 수집되었습니다. 변수의 개수는 7개입니다.\n\n\ndim(news_worldcup_date)\n\n\n[1] 1000    7\n\ndim(news_worldcup_sim)\n\n\n[1] 1000    7\n\n앞, 뒤의 몇 건을 조회\n\n\nhead(news_worldcup_date)\n\n\n                                                                       title\n1   &apos;득점 선두&apos; 음바페, 20년만의 기록까지 &apos;두 골&apos; 남았다\n2      [<b>월드컵<\/b>] 세리머니가 싫어 왜 도망가?…크로아티아 야신, 미담 폭주\n3        실처럼 살짝 붙은 뼈… 英전문가 “손흥민의 <b>월드컵<\/b>은 도박이었다”\n4     [카타르 WC] 메시 행동 언짢은 모건 &quot;호날두가 했으면 어땠을까&quot;\n5           카세미루, &quot;내 나이 30…커리어 최고 순간, 맨유에서 행복&quot;\n6 &apos;혈투 끝 4강 진출&apos;에 순둥이 메시도 흥분...&quot;X발 가자!!&quot;\n                                                                                                                                         originallink\n1                                                                                      http://www.fourfourtwo.co.kr/news/articleView.html?idxno=25156\n2                                                                                      https://www.spotvnews.co.kr/news/articleView.html?idxno=570821\n3 https://www.chosun.com/sports/special-qatar2022/2022/12/10/KMVY4TIP2VHO7BSN5626UCXMZA/?utm_source=naver&utm_medium=referral&utm_campaign=naver-news\n4                                                                                       http://www.stnsports.co.kr/news/articleView.html?idxno=157704\n5                                                                                   http://www.interfootball.co.kr/news/articleView.html?idxno=591914\n6                                                                                                           http://www.osen.co.kr/article/G1112006052\n                                                           link\n1 https://sports.news.naver.com/news.nhn?oid=411&aid=0000020278\n2 https://sports.news.naver.com/news.nhn?oid=477&aid=0000399523\n3 https://n.news.naver.com/mnews/article/023/0003733895?sid=104\n4 https://sports.news.naver.com/news.nhn?oid=450&aid=0000089770\n5 https://sports.news.naver.com/news.nhn?oid=413&aid=0000151551\n6 https://sports.news.naver.com/news.nhn?oid=109&aid=0004755853\n                                                                                                                                                                                                                                       description\n1               카타르 <b>월드컵<\/b> 8강전에서 잉글랜드와 맞대결을 펼친다. 프랑스의 목표는 확실하다. 바로 자국 축구 역사상 처음으로 <b>월드컵<\/b> 2연패를 달성하는 것. 지난 대회인 2018 러시아 <b>월드컵<\/b>에서 우승을 차지했던 프랑스는 이번... \n2 카타르 <b>월드컵<\/b>&apos; 8강전 브라질과 맞대결에서 선발 출전했다. 경기 내내 리바코비치의 활약은 돋보였다.... 준결승에서 크로아티아가 한 번 더 승리한다면, 지난 &apos;2018 러시아<b>월드컵<\/b>&apos;에 이어 2회 연속 <b>월드컵<\/b> 결승전에... \n3                  “손흥민의 <b>월드컵<\/b> 출전은 도박이었다.” 손흥민(30·토트넘)이 한국의 16강 진출 꿈을 이끌며 무사히 <b>월드컵<\/b> 여정을 마쳤지만, 한편에서는 그의 몸 상태에 대한 우려가 잇따르고 있다. 충분한 회복 없이 마스크 투혼을 펼친... \n4                            아르헨티나는 10일(한국시간) 카타르 루사일의 루사일 스타디움에서 열린 2022 국제축구연맹(FIFA) 카타르 <b>월드컵<\/b> 8강전 네덜란드와의 경기에서 전후반 90분과 연장전까지 120분을 2-2로 비긴 뒤 승부차기에서 4-3으로... \n5         카타르 <b>월드컵<\/b> 8강전에서 크로아티아와 1-1로 비긴 뒤 승부차기에서 2-4로 패배했다. 이로써 브라질은 20년... 몸 관리만 잘한다면 다음 <b>월드컵<\/b> 출전도 바라볼 수 있다. 다니 알베스만 봐도 39세의 나이에 <b>월드컵<\/b>을 밟았다.... \n6                          아르헨티나 대표팀은 10일 카타르 루사일의 루사일 아이코닉 스타디움에서 열린 2022 국제축구연맹(FIFA) 카타르 <b>월드컵<\/b> 8강 네덜란드와 연장 접전 끝에 2-2 무승부를 기록한 뒤 승부차기에서 4-3으로 승리했다. 이 경기... \n         publish_date\n1 2022-12-10 22:31:00\n2 2022-12-10 22:31:00\n3 2022-12-10 22:30:00\n4 2022-12-10 22:26:00\n5 2022-12-10 22:26:00\n6 2022-12-10 22:20:00\n                                                 title_text\n1           득점 선두 음바페 20년만의 기록까지 두 골 남았다\n2 월드컵 세리머니가 싫어 왜 도망가크로아티아 야신 미담 폭주\n3 실처럼 살짝 붙은 뼈 英전문가 손흥민의 월드컵은 도박이었다\n4  카타르 WC 메시 행동 언짢은 모건 호날두가 했으면 어땠을까\n5         카세미루 내 나이 30커리어 최고 순간 맨유에서 행복\n6             혈투 끝 4강 진출에 순둥이 메시도 흥분X발 가자\n                                                                                                                                                                                                     description_text\n1       카타르 월드컵 8강전에서 잉글랜드와 맞대결을 펼친다. 프랑스의 목표는 확실하다. 바로 자국 축구 역사상 처음으로 월드컵 2연패를 달성하는 것. 지난 대회인 2018 러시아 월드컵에서 우승을 차지했던 프랑스는 이번... \n2           카타르 월드컵 8강전 브라질과 맞대결에서 선발 출전했다. 경기 내내 리바코비치의 활약은 돋보였다.... 준결승에서 크로아티아가 한 번 더 승리한다면, 지난 2018 러시아월드컵에 이어 2회 연속 월드컵 결승전에... \n3     손흥민의 월드컵 출전은 도박이었다. 손흥민(30·토트넘)이 한국의 16강 진출 꿈을 이끌며 무사히 월드컵 여정을 마쳤지만, 한편에서는 그의 몸 상태에 대한 우려가 잇따르고 있다. 충분한 회복 없이 마스크 투혼을 펼친... \n4      아르헨티나는 10일(한국시간) 카타르 루사일의 루사일 스타디움에서 열린 2022 국제축구연맹(FIFA) 카타르 월드컵 8강전 네덜란드와의 경기에서 전후반 90분과 연장전까지 120분을 2-2로 비긴 뒤 승부차기에서 4-3으로... \n5 카타르 월드컵 8강전에서 크로아티아와 1-1로 비긴 뒤 승부차기에서 2-4로 패배했다. 이로써 브라질은 20년... 몸 관리만 잘한다면 다음 월드컵 출전도 바라볼 수 있다. 다니 알베스만 봐도 39세의 나이에 월드컵을 밟았다.... \n6    아르헨티나 대표팀은 10일 카타르 루사일의 루사일 아이코닉 스타디움에서 열린 2022 국제축구연맹(FIFA) 카타르 월드컵 8강 네덜란드와 연장 접전 끝에 2-2 무승부를 기록한 뒤 승부차기에서 4-3으로 승리했다. 이 경기... \n\ntail(news_worldcup_sim)\n\n\n                                                                                                       title\n995                                           한국에 러브레터 썼던 美기자, <b>월드컵<\/b> 8강전 취재중 돌연사\n996  [2022<b>월드컵<\/b>] &apos;만찢남&apos; 조규성, 10일 저녁 6시!, &apos;뉴스룸&apos;서 유럽행 구상 밝힌...\n997                                                    [이도경의 플레e] 게임법안과 <b>월드컵<\/b>의 상관 관계\n998                  카타르<b>월드컵<\/b> 조직위원장, 이주 노동자 사망에 &quot;죽음은 삶의 자연스러운 부분...\n999                                             <b>월드컵<\/b> 8강전도 멈췄다…그라운드로 뛰어드는 관중들, 왜?\n1000                          &apos;랭킹 1위&apos; 김민선, <b>월드컵<\/b> 3회 연속 우승...생애 첫 36초대 진입\n                                                                          originallink\n995                                        https://www.sedaily.com/NewsView/26EUKLXBRE\n996                    https://news.jtbc.co.kr/article/article.aspx?news_id=NB12106519\n997                                      http://www.fnnews.com/news/202212101603192736\n998  https://news.sbs.co.kr/news/endPage.do?news_id=N1007001480&plink=ORI&cooper=NAVER\n999                               https://view.asiae.co.kr/article/2022121018544394179\n1000                                         http://www.osen.co.kr/article/G1112005893\n                                                              link\n995  https://n.news.naver.com/mnews/article/011/0004132098?sid=104\n996  https://n.news.naver.com/mnews/article/437/0000324529?sid=104\n997  https://n.news.naver.com/mnews/article/014/0004940285?sid=105\n998  https://n.news.naver.com/mnews/article/055/0001019146?sid=104\n999  https://n.news.naver.com/mnews/article/277/0005190071?sid=104\n1000 https://sports.news.naver.com/news.nhn?oid=109&aid=0004755695\n                                                                                                                                                                                                                                      description\n995               미국의 한 유명 축구기자가 2022 카타르 <b>월드컵<\/b> 취재 도중 현장에서 돌연 사망했다. 10일(한국시간)... 다만 <b>월드컵<\/b> 개막 이후 살인적인 스케줄을 소화했으며 최근 건강이 악화된 상태였다고 알려졌다. 월은 뉴스레터에서... \n996  카타르 <b>월드컵<\/b> 스타&apos; 조규성이 대회 종료 후 처음으로 10일 오후 6시 &apos;JTBC 주말 뉴스룸&apos;에서 강렬했던 <b>월드컵<\/b> 16강을 되돌아봅니다. 조규성은 이번 인터뷰에서 유럽 진출에 관한 진행 상황, 호날두와의 설전 등 다양한... \n997                        우리나라가 카타르 <b>월드컵<\/b> 16강에 진출했다는 기쁜 소식을 접한 다음날이었다. 상임위 간사실로부터 연락이 왔다. 본래 7일로 예정되어 있던 법안소위가 9일로 연기될 전망이라는 설명이었다. 문화체육관광부 제1차관이... \n998      카타르 <b>월드컵<\/b> 조직위원장이 대회 기간 이주 노동자 사망 사건과 관련해 &apos;죽음은 삶의 일부&apos;라는 표현을 사용해 빈축을 샀습니다. 로이터통신과 영국 BBC 등에 따르면 나세르 알 카터 카타르 <b>월드컵<\/b> 조직위원장은 사망한... \n999                   2022 국제축구연맹(FIFA) 카타르 <b>월드컵<\/b>에서 관중의 경기장 난입이 잇따르고 있다. 조별리그 경기 도중... 그는 2014년 브라질 <b>월드컵<\/b> 결승전 독일과 아르헨티나의 경기에서도 그라운드에 난입해 물의를 빚었다. 당시... \n1000                     의정부시청)이 <b>월드컵<\/b> 3회 연속 우승을 달성하며 랭킹 1위의 위용을 떨쳤다. 김민선은 10일(한국시간) 캐나다 캘거리 올림픽 오벌에서 열린 2022-2023 국제빙상경기연맹(ISU) 스피드스케이팅 <b>월드컵<\/b> 3차 대회 여자... \n            publish_date\n995  2022-12-10 19:38:00\n996  2022-12-09 16:58:00\n997  2022-12-10 16:13:00\n998  2022-12-09 12:21:00\n999  2022-12-10 20:22:00\n1000 2022-12-10 14:59:00\n                                                                 title_text\n995                  한국에 러브레터 썼던 美기자 월드컵 8강전 취재중 돌연사\n996        2022월드컵 만찢남 조규성 10일 저녁 6시 뉴스룸서 유럽행 구상 밝힌\n997                            이도경의 플레e 게임법안과 월드컵의 상관 관계\n998  카타르월드컵 조직위원장 이주 노동자 사망에 죽음은 삶의 자연스러운 부분\n999                      월드컵 8강전도 멈췄다그라운드로 뛰어드는 관중들 왜\n1000                랭킹 1위 김민선 월드컵 3회 연속 우승생애 첫 36초대 진입\n                                                                                                                                                                                                      description_text\n995  미국의 한 유명 축구기자가 2022 카타르 월드컵 취재 도중 현장에서 돌연 사망했다. 10일(한국시간)... 다만 월드컵 개막 이후 살인적인 스케줄을 소화했으며 최근 건강이 악화된 상태였다고 알려졌다. 월은 뉴스레터에서... \n996       카타르 월드컵 스타 조규성이 대회 종료 후 처음으로 10일 오후 6시 JTBC 주말 뉴스룸에서 강렬했던 월드컵 16강을 되돌아봅니다. 조규성은 이번 인터뷰에서 유럽 진출에 관한 진행 상황, 호날두와의 설전 등 다양한... \n997    우리나라가 카타르 월드컵 16강에 진출했다는 기쁜 소식을 접한 다음날이었다. 상임위 간사실로부터 연락이 왔다. 본래 7일로 예정되어 있던 법안소위가 9일로 연기될 전망이라는 설명이었다. 문화체육관광부 제1차관이... \n998     카타르 월드컵 조직위원장이 대회 기간 이주 노동자 사망 사건과 관련해 죽음은 삶의 일부라는 표현을 사용해 빈축을 샀습니다. 로이터통신과 영국 BBC 등에 따르면 나세르 알 카터 카타르 월드컵 조직위원장은 사망한... \n999      2022 국제축구연맹(FIFA) 카타르 월드컵에서 관중의 경기장 난입이 잇따르고 있다. 조별리그 경기 도중... 그는 2014년 브라질 월드컵 결승전 독일과 아르헨티나의 경기에서도 그라운드에 난입해 물의를 빚었다. 당시... \n1000        의정부시청)이 월드컵 3회 연속 우승을 달성하며 랭킹 1위의 위용을 떨쳤다. 김민선은 10일(한국시간) 캐나다 캘거리 올림픽 오벌에서 열린 2022-2023 국제빙상경기연맹(ISU) 스피드스케이팅 월드컵 3차 대회 여자... \n\n간단한 데이터 요약\n뉴스 빈발 단어\n빈발단어를 워드클라우드로 시각화하는 함수를 만듦\n\n\n# create UDF\ncreate_wordcloud <- function(data, remove_n = 5, min_freq = 5, background = \"white\") {\n  data %>% \n    filter(nchar(description_text) > 0) %>%   \n    tidytext::unnest_tokens(noun, description_text, bitTA::morpho_mecab, type = \"noun\") %>% \n    group_by(noun) %>% \n    count() %>% \n    arrange(desc(n)) %>%     \n    ungroup() %>%\n    filter(n >= min_freq) %>% \n    filter(row_number() > remove_n) %>% \n    wordcloud2::wordcloud2(backgroundColor = background, \n                           fontFamily = \"NanumSquare\")\n}\n\n\n\n날짜 기준으로 정렬 수집한 뉴스에 대해서 워드클라우드를 그려\n봅니다.\n\n\nlibrary(bitReport)\n\nnews_worldcup_date %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n\n\n(#fig:wcloud_wcupdate)날짜 기준 월드컵 뉴스\n\n\n\n유사도 기준으로 정렬 수집한 뉴스에 대해서 워드클라우드를 그려\n봅니다.\n\n\nnews_worldcup_sim %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n\n\n(#fig:wcloud_wcupsim)유사도 기준 월드컵 뉴스\n\n\n\n정규표현식의 이해\n패턴 검색\n유사도 정렬 기준으로 수집한 뉴스 중에서 선수와 감독의 이름이 포함된\n기사의 건수를 계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_int(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        tally() %>% \n        pull()\n    }\n  )\n\n\n[1]  20 123  55  10  25 107\n\n각각의 기사에서 해당 선수와 감독의 이름이 평균 몇 번 등장하는지\n계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_dbl(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        mutate(n_talk = stringr::str_count(description_text, x)) %>% \n        summarise(n_avg = mean(n_talk, na.rm = TRUE)) %>% \n        pull()\n    }\n  )\n\n\n[1] 1.000000 1.821138 1.818182 1.000000 1.800000 1.168224\n\nDocument Term Matrix의 이해\nDTM 생성하기\n유사도 정렬 기준 뉴스의 Term Frequency 기반의 DTM과 TF-IDF 기반의\nDTM을 생성합니다. 뉴스 데이터는 문서 아이디로 사용할 변수가 없기 때문에\n아이디를 만듧니다.\n\n\nnews_worldcup_sim <- news_worldcup_sim %>% \n  mutate(id = row_number())\n\n\n\nTERM FREQUENCY 기반의 DTM\n인명인 고유명사도 함께 추출한 DTM을 만들기 위해서\nunnest_noun_ngrams() 함수의 type 인수값에 “noun2”를 사용합니다\n\n\nlibrary(tidyverse)\nlibrary(bitTA)\nlibrary(tidytext)\nlibrary(tm)\n\ndtm_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n)\n\ntm::inspect(dtm_tf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 710)>>\nNon-/sparse entries: 20380/689620\nSparsity           : 97%\nMaximal term length: 6\nWeighting          : term frequency (tf)\nSample             :\n     Terms\nDocs  강 년 대표 시간 월드컵 일 축구 카타르 팀 한국\n  148  0  2    1    0      2  1    1      1  1    0\n  247  0  2    1    0      2  1    1      1  1    0\n  346  0  2    1    0      2  1    1      1  1    0\n  445  0  2    1    0      2  1    1      1  1    0\n  49   0  2    1    0      2  1    1      1  1    0\n  544  0  2    1    0      2  1    1      1  1    0\n  643  0  2    1    0      2  1    1      1  1    0\n  742  0  2    1    0      2  1    1      1  1    0\n  841  0  2    1    0      2  1    1      1  1    0\n  940  0  2    1    0      2  1    1      1  1    0\n\nTF-IDF 기반의 DTM\n\n\ndtm_tfidf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightTfIdf)\n\ntm::inspect(dtm_tfidf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 710)>>\nNon-/sparse entries: 20380/689620\nSparsity           : 97%\nMaximal term length: 6\nWeighting          : term frequency - inverse document frequency (normalized) (tf-idf)\nSample             :\n     Terms\nDocs          강 강전 년 대표 브라질 손흥민 아르헨티나 우승 팀 한국\n  123 0.00000000    0  0    0      0      0          0    0  0    0\n  222 0.00000000    0  0    0      0      0          0    0  0    0\n  24  0.00000000    0  0    0      0      0          0    0  0    0\n  321 0.00000000    0  0    0      0      0          0    0  0    0\n  420 0.00000000    0  0    0      0      0          0    0  0    0\n  519 0.00000000    0  0    0      0      0          0    0  0    0\n  700 0.06068335    0  0    0      0      0          0    0  0    0\n  799 0.06068335    0  0    0      0      0          0    0  0    0\n  898 0.06068335    0  0    0      0      0          0    0  0    0\n  997 0.06068335    0  0    0      0      0          0    0  0    0\n\nCorrelation Analysis\n각각의 선수와 감독별로 상관계수가 0.4 이상인 단어를 추출해봅니다. ###\nTerm Frequency\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map(\n    function(x) tm::findAssocs(dtm_tf, terms = x, corlimit = 0.4)\n  )\n\n\n[[1]]\n[[1]]$벤투\n  결별   역대   원정 파울루   독일   연속 러시아 \n  1.00   1.00   1.00   1.00   0.88   0.50   0.44 \n\n\n[[2]]\n[[2]]$손흥민\n토트넘   도박   감사   결정   수술   투명   출전   안면   의학 전문가 \n  0.70   0.64   0.55   0.55   0.55   0.55   0.52   0.50   0.50   0.50 \n  주장   인사     팬   우려   생각   결장   응원 \n  0.50   0.49   0.49   0.45   0.44   0.42   0.41 \n\n\n[[3]]\n[[3]]$조규성\n      전북       출연   아나운서       주시       뉴스       대세 \n      0.90       0.79       0.67       0.67       0.67       0.67 \n      현대       적설       스타       자신     이야기       가치 \n      0.67       0.59       0.58       0.48       0.46       0.44 \n      강조 스트라이커       중요       증명         건       구체 \n      0.44       0.44       0.44       0.44       0.44       0.44 \n      멀티   에피소드     와이드       이적       최초       토요 \n      0.44       0.44       0.44       0.44       0.44       0.44 \n      예정       진행 \n      0.42       0.41 \n\n\n[[4]]\n[[4]]$이강인\n  여기   조규   주목   처음 북중미   본선   성공     이 \n  1.00   1.00   1.00   0.81   0.66   0.57   0.57   0.51 \n\n\n[[5]]\n[[5]]$호날두\n        제외     포르투갈         선발         보도       스위스 \n        0.97         0.84         0.68         0.68         0.68 \n        시각         코르 크리스티아누         교체         명단 \n        0.68         0.68         0.68         0.68         0.68 \n        벤치       산투스     페르난두         협박         매체 \n        0.68         0.68         0.68         0.68         0.60 \n        도중           드       이야기         현지         소식 \n        0.50         0.47         0.47         0.46         0.43 \n\n\n[[6]]\n[[6]]$메시\n아르헨티나       도움       희비       통산       환호         골 \n      0.57       0.55       0.52       0.49       0.49       0.46 \n  네덜란드   토너먼트         호       남미 바티스투타 \n      0.44       0.44       0.44       0.40       0.40 \n\n연관분석\nBinary Term Frequency 기반\nDTM 생성\n\n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\n불용어 제거\n상위 50위인 단어를 불용어로 처리하여 제거합니다.\n\n\nstop_words <- dtm_bin_tf %>% \n  apply(2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  \"[\"(1:30) %>% \n  names()\nstop_words\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"한국\"        \n [5] \"축구\"         \"팀\"           \"강\"           \"대표\"        \n [9] \"시간\"         \"국제축구연맹\" \"년\"           \"강전\"        \n[13] \"우승\"         \"브라질\"       \"대회\"         \"경기\"        \n[17] \"진출\"         \"아르헨티나\"   \"이번\"         \"승부차기\"    \n[21] \"카타르월드컵\" \"연속\"         \"만\"           \"크로아티아\"  \n[25] \"손흥민\"       \"출전\"         \"차\"           \"회\"          \n[29] \"감독\"         \"끝\"          \n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!term %in% stop_words) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\nTransactions 생성하기\n\n\nlibrary(\"arules\")\n\ntrans <- as(dtm_bin_tf %>% as.matrix(), \"transactions\")\ntrans\n\n\ntransactions in sparse format with\n 1000 transactions (rows) and\n 679 items (columns)\n\nsummary(trans)\n\n\ntransactions as itemMatrix in sparse format with\n 1000 rows (elements/itemsets/transactions) and\n 679 columns (items) and a density of 0.01916495 \n\nmost frequent items:\n    메시 네덜란드     기자 스타디움       전  (Other) \n     107      107      105      105      104    12485 \n\nelement (itemset/transaction) length distribution:\nsizes\n  5   6   7   9  10  11  12  13  14  15  16  17  18  19  20  21 \n 10  40  30  70  81  49 159 138  97  80  87  71  41  13  24  10 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.00   11.00   13.00   13.01   15.00   21.00 \n\nincludes extended item information - examples:\n  labels\n1   호재\n2 스페인\n3   국가\n\nincludes extended transaction information - examples:\n  transactionID\n1            24\n2            28\n3            29\n\n연관규칙 생성하기\n\n\nrules <- apriori(trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support\n        0.6    0.1    1 none FALSE            TRUE       5    0.05\n minlen maxlen target  ext\n      1     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 50 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[679 item(s), 1000 transaction(s)] done [0.01s].\nsorting and recoding items ... [54 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4 5 6 7 done [0.00s].\nwriting ... [505 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\nsummary(rules)\n\n\nset of 505 rules\n\nrule length distribution (lhs + rhs):sizes\n  2   3   4   5   6   7 \n 71 132 148 105  42   7 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   3.000   4.000   3.873   5.000   7.000 \n\nsummary of quality measures:\n    support          confidence        coverage      \n Min.   :0.05000   Min.   :0.6190   Min.   :0.05000  \n 1st Qu.:0.05100   1st Qu.:1.0000   1st Qu.:0.05100  \n Median :0.05100   Median :1.0000   Median :0.05100  \n Mean   :0.05227   Mean   :0.9716   Mean   :0.05436  \n 3rd Qu.:0.05100   3rd Qu.:1.0000   3rd Qu.:0.05100  \n Max.   :0.07100   Max.   :1.0000   Max.   :0.10500  \n      lift            count      \n Min.   : 7.867   Min.   :50.00  \n 1st Qu.:14.085   1st Qu.:51.00  \n Median :14.085   Median :51.00  \n Mean   :15.535   Mean   :52.27  \n 3rd Qu.:19.608   3rd Qu.:51.00  \n Max.   :20.000   Max.   :71.00  \n\nmining info:\n  data ntransactions support confidence\n trans          1000    0.05        0.6\n                                                                                  call\n apriori(data = trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\narules::inspect(rules[1:5])\n\n\n    lhs             rhs          support confidence coverage lift    \n[1] {에듀케이션} => {시티}       0.057   1          0.057    17.54386\n[2] {시티}       => {에듀케이션} 0.057   1          0.057    17.54386\n[3] {에듀케이션} => {스타디움}   0.057   1          0.057     9.52381\n[4] {시티}       => {스타디움}   0.057   1          0.057     9.52381\n[5] {조별}       => {리그}       0.052   1          0.052    12.19512\n    count\n[1] 57   \n[2] 57   \n[3] 57   \n[4] 57   \n[5] 52   \n\n연관규칙 시각화하기\n\n\nlibrary(\"arulesViz\")\n\nplot(rules)\n\n\n\nrule2 <- sort(rules, by = \"confidence\")\ninspect(head(rule2, n = 10))\n\n\n     lhs             rhs          support confidence coverage\n[1]  {에듀케이션} => {시티}       0.057   1          0.057   \n[2]  {시티}       => {에듀케이션} 0.057   1          0.057   \n[3]  {에듀케이션} => {스타디움}   0.057   1          0.057   \n[4]  {시티}       => {스타디움}   0.057   1          0.057   \n[5]  {조별}       => {리그}       0.052   1          0.052   \n[6]  {윤석열}     => {여러분}     0.050   1          0.050   \n[7]  {윤석열}     => {대통령}     0.050   1          0.050   \n[8]  {캐나다}     => {빙상}       0.051   1          0.051   \n[9]  {빙상}       => {캐나다}     0.051   1          0.051   \n[10] {캐나다}     => {국제}       0.051   1          0.051   \n     lift     count\n[1]  17.54386 57   \n[2]  17.54386 57   \n[3]   9.52381 57   \n[4]   9.52381 57   \n[5]  12.19512 52   \n[6]  16.66667 50   \n[7]  14.28571 50   \n[8]  19.60784 51   \n[9]  19.60784 51   \n[10] 19.60784 51   \n\nplot(rules, method = \"grouped\")\n\n\n\nplot(rules, method = \"graph\")\n\n\n\n\n단어의 계층적 군집분석\n희박 단어의 제거\n\n\ndim(dtm_bin_tf)\n\n\n[1] 1000  679\n\ncompact_bin <- tm::removeSparseTerms(dtm_bin_tf, sparse = 0.985) %>%\n  as.matrix(compact_bin)\n\ndim(compact_bin)\n\n\n[1] 1000  243\n\n비상사도 행렬 생성\n\n\nmat <- t(compact_bin)\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 243 \n\nClustering\nk개 군집을 나눕니다.\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n(#fig:plot_cluster)Clustering\n\n\n\n군집의 해석\nk개 클러스터를 구성하는 단어들의 목록을 조회합니다.\n\n\nk %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n[[1]]\n  김민선     최고 스케이팅   스피드   금메달       초     국제 \n      22       24       37       38       43       46      133 \n  디비전     빙상     여자     연맹     오벌   올림픽   의정부 \n     134      135      137      138      139      140      141 \n  캐나다   캘거리     행진     빙속       신     여제       新 \n     142      143      144      178      179      180      181 \n    개인     차지 \n     209      210 \n\n[[2]]\n  기자 기자석   미국   취재 경기장   발생   나이 베테랑   사고     세 \n     4      7      8     12     54     67    108    110    111    112 \n  세상   정도   통신 \n   113    115    156 \n\n[[3]]\n  대통령     만찬     귀국   여러분     우리     결과     국민 \n      18       21       49       55       56      159      160 \n대한민국     성과   윤석열     환영     지원   청와대     초청 \n     161      162      163      164      170      171      177 \n  영빈관       저 \n     211      212 \n\n[[4]]\n      메시     루사일   네덜란드   스타디움       시티         얀 \n        40         42         96        102        103        104 \n에듀케이션     연장전 \n       105        106 \n\n[[5]]\n스포츠   전문 경쟁국 글로벌   채널   소속     곳   어디   제목 \n    10     14     60     61     64    200    234    235    236 \n\n[[6]]\n        호재       스페인         국가       조규성         인사 \n           1            2            3            5            6 \n        사망           중       아시아       토트넘           그 \n           9           11           13           15           16 \n        선전           윤         황희         세계         감사 \n          17           19           20           23           25 \n          팬     포르투갈       호날두         리그         조별 \n          26           27           28           29           30 \n        개최         이후         선발         호골         기록 \n          31           32           33           34           35 \n        치치     네이마르     잉글랜드         결승           분 \n          36           39           41           44           45 \n        적설         독일         응원           위         승리 \n          47           48           50           51           52 \n      프랑스         도움       위원장         조직         도전 \n          53           57           58           59           62 \n      마무리         기사         내용         요약       가운데 \n          63           65           66           68           69 \n      북중미         전망         현지           것         도박 \n          70           71           72           73           74 \n          등       마스크         부상         안면           전 \n          75           76           77           78           79 \n        착용         상태           수         우려         결장 \n          80           81           82           83           84 \n        결정         수술         영국         의학       전문가 \n          85           86           87           88           89 \n        주장         투명           후         개막           골 \n          90           91           92           93           94 \n          꿈       리오넬       마지막       맞대결         생애 \n          95           97           98           99          100 \n          뒤         탈락           번           월         남미 \n         101          107          109          114          116 \n  바티스투타         통산       공격수         스타         자신 \n         117          118          119          120          121 \n        전북           개       러시아         자리     준준결승 \n         122          123          124          125          126 \n        관련         기간       나세르       노동자         이주 \n         127          128          129          130          131 \n        카터         시청         득점           승         좌절 \n         132          136          145          146          147 \n        최다         펠레         희비     마라도나       지난달 \n         148          149          150          151          152 \n        후보         논란         달성           이         격려 \n         153          154          155          157          158 \n          데         등장         역할         이상           찬 \n         165          166          167          168          169 \n      김건희         도하         여사         예정         이날 \n         172          173          174          175          176 \n        과정         외신         격돌 프리미어리그   사회관계망 \n         182          183          184          185          186 \n      서비스       아쉬움         캡틴         후회         분석 \n         187          188          189          190          191 \n          때         도중           드         보도         소식 \n         192          193          194          195          196 \n        제외         선수     연합뉴스         후반           명 \n         197          198          199          201          202 \n          판         문제         인권       뉴시스         부문 \n         203          204          205          206          207 \n        서울         개국         본선         여정           말 \n         208          213          214          215          216 \n        눈물         무대         연장         전반         퇴장 \n         217          218          219          220          221 \n        가능         감동   인스타그램       지휘봉         성적 \n         222          223          224          225          226 \n        강호           대         이하           바         상대 \n         227          228          229          230          231 \n      킬리안           페       이야기         진행         출연 \n         232          233          237          238          239 \n        성공         랭킹         이변         일본 \n         240          241          242          243 \n\n기사의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\n\n\nmat <- compact_bin\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 1000 \n\n군집 개수 선정 및 시각화\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n(#fig:plot_cluster_list)군집 개수 선정 및 시각화\n\n\n\n군집의 해석\n군집별 기사 ID를 추출하고 기사의 개수를 조회합니다.\n\n\nclusters <- k %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n\n\n\n# 기사의 개수\nclusters %>% \n  purrr::map_int(length)\n\n\n[1]  51  30  33 827  29  30\n\n기사 군집 1\n기사의 제목 조회\n20건만 선별 조회\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  select(title_text) %>% \n  head(n = 20)\n\n\n                                                       title_text\n1             이런 몸으로 헤딩까지손흥민 월드컵 출전은 도박이었다\n2             월드컵 메시 이례적으로 심판 비판그런 주심 투입 안돼\n3                  尹 여러분이 월드컵 우승팀벤투호 靑 영빈관 초청\n4           월드컵 손흥민 1 가능성 정말 크다고 느껴SNS에 감사인사\n5  월드컵 펠레 최다골 동률 네이마르 격려 도전하는 이들에게 영감을\n6         월드컵 불붙은 골든부트 경쟁8강을 넘어야 득점왕에 오른다\n7        마스크 쏘니 월드컵 참가 도박이었지만 英 의학 전문가 언급\n8                        이강인 불과 25세 2026 월드컵 한국 전망은\n9          월드컵 8강전 취재하던 美 기자 경기장서 돌연사향년 48살\n10        월드컵 우승 후보 브라질 승부차기서 크로아티아에 져 탈락\n11             신 빙속여제 김민선 월드컵 3회 연속 우승36초대 진입\n12                           스프 독재자들은 왜 월드컵을 좋아할까\n13               월드컵 2회 연속 8강서 탈락 브라질 치치 감독 사임\n14                   김민선 또 해냈다 빙속 월드컵 3차 500m 금메달\n15              월드컵 스타 황희찬 손목에 2억짜리 시계어느 브랜드\n16           2022월드컵 일본이 또이번엔 가미카제 티셔츠 들고 응원\n17      월드컵 펠레 자신 따라잡은 네이마르에 격려계속 영감을 달라\n18         카타르 월드컵 8강전 취재하던 美 기자 경기 중 돌연 사망\n19                          세기의 창들 창세기 전쟁주말 밤 월드컵\n20 이주 노동자 사망 논란에월드컵 조직위원장 죽음은 삶의 일부 망언\n\n워드클라우드 그리기\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  unnest_noun_ngrams(term, description_text, n = 1) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(term, sort = TRUE) %>% \n  filter(nchar(term) > 1) %>%   \n  filter(row_number() >= 15) %>% \n  wordcloud2::wordcloud2(fontFamily = \"NanumSquare\")\n\n\n\n\n\n(#fig:wcloud_news_wcupsim)월드컵 기사의 제목\n\n\n\nTopic 분석\n기사의 TF 기반의 DTM으로 Topic 분석을 수행합니다. ### 희박 단어의\n제거\n\n\ncompact_tf <- tm::removeSparseTerms(dtm_tf, sparse = 0.98) %>%\n  as.matrix()\n\ndim(compact_tf)\n\n\n[1] 1000  195\n\nOTF 계산\n\n\notf <- apply(compact_tf, 2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  names()\n\n\n\n불용어 제거\nOverall Term Frequency 상위 15개 단어를 불용어로 간주하여\n제거합니다.\n\n\nstop_word <- otf[1:20]\nstop_word\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"팀\"          \n [5] \"한국\"         \"강\"           \"축구\"         \"대표\"        \n [9] \"년\"           \"시간\"         \"아르헨티나\"   \"브라질\"      \n[13] \"국제축구연맹\" \"우승\"         \"대회\"         \"손흥민\"      \n[17] \"강전\"         \"경기\"         \"감독\"         \"진출\"        \n\ncompact_tf2 <- compact_tf[, !colnames(compact_tf) %in% stop_word] \ndim(compact_tf2)\n\n\n[1] 1000  175\n\nTopic Modeling\n\n\nlibrary(\"topicmodels\")\n\nk <- 2:10\n\ncompact_tf2 <- compact_tf2[compact_tf2 %>% apply(1, sum) != 0, ]\n\nmodels <- k %>% \n  purrr::map(\n    function(x) {\n      topicmodels::LDA(compact_tf2, k = x, control = list(seed = 123))\n    }\n  )\n\n\n\nTopic 개수 구하기\nLOG-LIKELIHOOD\n\n\nlog_ikelihood <- models %>% \n  purrr::map_dbl(logLik)\nlog_ikelihood\n\n\n[1] -47757.42 -42664.01 -40892.80 -39435.92 -39343.54 -38069.31\n[7] -37426.58 -36656.59 -36596.24\n\nwhich.max(log_ikelihood)\n\n\n[1] 9\n\nALPHA\n\n\nalpha <- models %>% \n  purrr::map_dbl(slot, \"alpha\")\nalpha\n\n\n[1] 43.68480347  0.08238568  0.05744443  0.04485914  0.04983525\n[6]  0.03917391  0.03579950  0.02816270  0.03088953\n\nwhich.min(alpha)\n\n\n[1] 8\n\nTop beta 단어의 시각화\n\n\nprob <- tidytext::tidy(models[[9]], matrix = \"beta\")\nprob\n\n\n# A tibble: 1,750 × 3\n   topic term       beta\n   <int> <chr>     <dbl>\n 1     1 스페인 1.23e-73\n 2     2 스페인 3.00e-55\n 3     3 스페인 1.32e-73\n 4     4 스페인 2.24e-73\n 5     5 스페인 2.04e-79\n 6     6 스페인 6.75e- 2\n 7     7 스페인 4.49e-35\n 8     8 스페인 1.03e-73\n 9     9 스페인 1.77e-73\n10    10 스페인 4.27e-34\n# … with 1,740 more rows\n\n\n\ntop_prob <- prob %>% \n  group_by(topic) %>% \n  top_n(10, beta) %>% \n  ungroup() %>% \n  arrange(topic, -beta)\ntop_prob\n\n\n# A tibble: 103 × 3\n   topic term     beta\n   <int> <chr>   <dbl>\n 1     1 출전   0.0979\n 2     1 토트넘 0.0718\n 3     1 인사   0.0606\n 4     1 감사   0.0606\n 5     1 팬     0.0519\n 6     1 도박   0.0458\n 7     1 응원   0.0433\n 8     1 선발   0.0433\n 9     1 영국   0.0381\n10     1 호날두 0.0346\n# … with 93 more rows\n\n\n\ntop_prob %>% \n  mutate(term = reorder(term, beta)) %>% \n  ggplot(aes(x = term,  y = beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~topic, scales = \"free\") +\n  coord_flip()\n\n\n\n\n(#fig:plot_top_prob)Top beta 단어의 시각화\n\n\n\n문서에서의 토픽의 비중\n\n\nnews_gamma <- tidytext::tidy(models[[9]], matrix = \"gamma\") %>% \n  mutate(gamma = gamma * 100)\n\nnews_gamma\n\n\n# A tibble: 10,000 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 41           1 0.423\n 2 140          1 0.423\n 3 239          1 0.423\n 4 338          1 0.423\n 5 437          1 0.423\n 6 536          1 0.423\n 7 635          1 0.423\n 8 734          1 0.423\n 9 833          1 0.423\n10 932          1 0.423\n# … with 9,990 more rows\n\n토픽이 포함된 문서 조회\n토픽 1의 주요 단어는 다음과 같습니다.\n\n\nterms(models[[9]], 10)[, 1]\n\n\n [1] \"출전\"   \"토트넘\" \"인사\"   \"감사\"   \"팬\"     \"도박\"   \"응원\"  \n [8] \"선발\"   \"영국\"   \"호날두\"\n\n토픽 1이 95% 이상 포함된 문서를 조회합니다.\n\n\nnews_gamma %>%\n  filter(topic == 1) %>%\n  filter(gamma >= 95) %>%\n  arrange(desc(gamma))\n\n\n# A tibble: 103 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 54           1  97.5\n 2 153          1  97.5\n 3 252          1  97.5\n 4 351          1  97.5\n 5 450          1  97.5\n 6 549          1  97.5\n 7 648          1  97.5\n 8 747          1  97.5\n 9 846          1  97.5\n10 945          1  97.5\n# … with 93 more rows\n\n61번째 기사의 이해\n\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(title_text) %>% \n  pull()\n\n\n[1] \"자칭 축구 종가 中 2026 월드컵에 명운 건다\"\n\n\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(description_text) %>% \n  pull()\n\n\n[1] \"대회 종반으로 치닫고 있는 2022 카타르월드컵에서 확인한 것은 아시아팀의 대약진이다. 한국은 지난 12월 3일(이하 한국시간) 유럽의 강호 포르투갈을 2 대 1로 누르고 2010년 남아공월드컵 이후 12년 만에 16강에... \"\n\n문서의 토픽 분해\n모든 문서는 토픽들의 복합체입니다. 기사 1을 분해하여 토픽의 비율을\n조해해 봅니다.\n\n\nnews_gamma %>%\n  filter(document %in% \"1\") %>% \n  arrange(desc(gamma)) \n\n\n# A tibble: 10 × 3\n   document topic  gamma\n   <chr>    <int>  <dbl>\n 1 1           10 70.3  \n 2 1            5 18.2  \n 3 1            1  9.63 \n 4 1            9  0.273\n 5 1            2  0.273\n 6 1            7  0.273\n 7 1            3  0.273\n 8 1            4  0.273\n 9 1            8  0.273\n10 1            6  0.273\n\n토픽의 단어 분해\n\n\ntop_prob %>% \n  filter(topic == 6) %>% \n  arrange(desc(beta)) \n\n\n# A tibble: 10 × 3\n   topic term         beta\n   <int> <chr>       <dbl>\n 1     6 크로아티아 0.117 \n 2     6 스타디움   0.0769\n 3     6 시티       0.0769\n 4     6 에듀케이션 0.0769\n 5     6 스페인     0.0675\n 6     6 얀         0.0634\n 7     6 연장전     0.0499\n 8     6 후보       0.0488\n 9     6 독일       0.0432\n10     6 위         0.0426\n\n이진분류 모형\n패키지 로드하기\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(bitTA)\n\n\n\n파생변수 만들기\n연합뉴스 여부\n연합뉴스 기사 : 1\n기타뉴스 기사 : 0\n\n\n\nnews_worldcup_yna <- news_worldcup_sim %>% \n  mutate(yna_flag = ifelse(stringr::str_detect(originallink, \"www.yna.co.kr\"), 1, 0))\n\nnews_worldcup_yna %>% \n  count(yna_flag) %>% \n  mutate(ratio = n /sum(n) * 100)\n\n\n  yna_flag   n ratio\n1        0 769  76.9\n2        1 231  23.1\n\n불균형 데이터의 언더 샘플링\n\n\nn_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1) %>% \n  tally() %>% \n  pull()\n\nn_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  tally() %>% \n  pull()\n\nset.seed(123)\nidx_sample <- sample(seq(n_not_yna), size = n_yna)\n\nsubset_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  filter(row_number() %in% idx_sample)\n\nsubset_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1)\n\nnews_sample_yna <- bind_rows(subset_not_yna, subset_yna)\n\nnews_sample_yna %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 231\n2        1 231\n\n데이터셋 분리\n\n\nset.seed(123)\nnews_split <- initial_split(news_sample_yna, strata = yna_flag)\n\ntrain <- rsample::training(news_split)\ntest <- rsample::testing(news_split)\n\ndim(train)\n\n\n[1] 346   9\n\ndim(test)\n\n\n[1] 116   9\n\ntrain %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 173\n2        1 173\n\ntest %>% \n  count(yna_flag)\n\n\n  yna_flag  n\n1        0 58\n2        1 58\n\ntokenize 반복기 정의\n\n\n# 일반명사 단위로 토큰을 생성\ntoken_fun <- bitTA::morpho_mecab\n\nit_train <- itoken_parallel(train$description_text, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken_parallel(test$description_text, \n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nFrequency 기반의 DTM 생성\nVOCABULARY 생성\n\n\nlibrary(doParallel)\n\nnc <- parallel::detectCores()\nregisterDoParallel(cores = nc)\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 346 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n          term term_count doc_count\n 1:     브라질         77        60\n 2:       우승         78        66\n 3:       대회         85        66\n 4: 아르헨티나         96        61\n 5:       대표         98        87\n 6:       축구        121       119\n 7:         강        131       120\n 8:         팀        133       111\n 9:     카타르        369       260\n10:     월드컵        661       335\n\nDOCUMENT TERM MATRIX\n생성하기\n\n\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train_tf <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train_tf)\n\n\n[1] 346 566\n\ndtm_test_tf <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test_tf)\n\n\n[1] 116 566\n\nN-Grams 기반의 DTM 생성\nVOCABULARY 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 1671    3\n\nPRUNE VOCABULARY\n\n\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 268   3\n\nDOCUMENTS TERM MATRIX 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1] 346 268\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1] 116 268\n\nTF-IDF 기반의 DTM 생성\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train_tf, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test_tf, tfidf) \n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train_tf)\n\n\n[1] 346 566\n\ndim(dtm_train_bigram)\n\n\n[1] 346 268\n\ndim(dtm_train_tfidf)\n\n\n[1] 346 566\n\nFrequency 기반 모델링\n\n\nNFOLDS <- 10\n\nclassifier_tf <- cv.glmnet(x = dtm_train_tf, y = train$yna_flag, \n                           family = \"binomial\",\n                           alpha = 1,\n                           parallel = TRUE, \n                           keep = TRUE)\n\n\n\n모델의 이해\n\n\nlibrary(broom)\n\ncoefs_tf <- classifier_tf$glmnet.fit %>%\n  tidy() %>%\n  filter(lambda == classifier_tf$lambda.1se)\ncoefs_tf \n\n\n# A tibble: 108 × 5\n   term         step      estimate  lambda dev.ratio\n   <chr>       <dbl>         <dbl>   <dbl>     <dbl>\n 1 (Intercept)    64 -2.84         0.00791     0.924\n 2 격무           64 -1.26         0.00791     0.924\n 3 네티즌         64 -1.16         0.00791     0.924\n 4 사이           64 -0.0000527    0.00791     0.924\n 5 숫자           64 -0.145        0.00791     0.924\n 6 시사           64 -2.60         0.00791     0.924\n 7 은퇴           64 -0.0000288    0.00791     0.924\n 8 의지           64 -0.0000158    0.00791     0.924\n 9 출신           64 -0.0123       0.00791     0.924\n10 해외           64 -0.0000000685 0.00791     0.924\n# … with 98 more rows\n\n\n\ncoefs_tf %>%\n  group_by(estimate > 0) %>%\n  top_n(10, abs(estimate)) %>%\n  ungroup() %>%\n  ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate > 0)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    title = \"예측에 영향을 주는 모델의 계수들 with TF\",\n    subtitle = \"네이버 월드컵 관련 뉴스\"\n  )\n\n\n\n\n(#fig:plot_coefs_tf)예측에 영향을 주는 모델의 계수들 with TF\n\n\n\n모델의 평가\n정오분류 행렬\n\n\nnews_tf <- predict(classifier_tf, dtm_test_tf, type = 'class')\ncm_tf <- confusionMatrix(factor(test$yna_flag), factor(news_tf), positive = \"1\")\ncm_tf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 56  2\n         1  1 57\n                                          \n               Accuracy : 0.9741          \n                 95% CI : (0.9263, 0.9946)\n    No Information Rate : 0.5086          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9483          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.9661          \n            Specificity : 0.9825          \n         Pos Pred Value : 0.9828          \n         Neg Pred Value : 0.9655          \n             Prevalence : 0.5086          \n         Detection Rate : 0.4914          \n   Detection Prevalence : 0.5000          \n      Balanced Accuracy : 0.9743          \n                                          \n       'Positive' Class : 1               \n                                          \n\nROC 커브\n\n\nlibrary(\"pROC\")\n\npredictions <- predict(classifier_tf, dtm_test_tf, type = 'response')\nroc_tf <- pROC::roc(test$yna_flag, predictions)\n\npROC::auc(roc_tf)\n\n\nArea under the curve: 0.9551\n\n\n\nplot(roc_tf)\n\n\n\n\n(#fig:plot_roctf)ROC 커브\n\n\n\n\n\nidx <- predictions %>% \n  which.max()\n\npredictions[idx]\n\n\n[1] 0.992495\n\ntest[idx, \"description_text\"]\n\n\n[1] \"2022 국제축구연맹(FIFA) 카타르 월드컵에서 한국의 16강 진출에 기여한 공격수 황희찬(26·울버햄프턴)이... 울버햄프턴은 카타르 월드컵 기간 정규리그 휴식기를 맞아 스페인 마르베야에서 담금질을 하고 있다. 이날... \"\n\n\n\nidx <- predictions %>% \n  which.min()\n\npredictions[idx]\n\n\n[1] 0.0008618372\n\ntest[idx, \"description_text\"]\n\n\n[1] \"카타르월드컵 선전이 대통령 지지율을 끌어올린 요인들로 꼽힌다. 대통령실에서는 내년 초까지 지지율... 카타르월드컵 16강 진출과 같은 호재가 더해졌다고 분석했다. 2002 한일월드컵 당시 김대중 대통령의 지지율이... \"\n\n\n\n\n",
      "last_modified": "2022-12-10T22:43:38+09:00"
    },
    {
      "path": "classifier_lasso.html",
      "title": "대통령 연설문 예측",
      "description": "2022학년도 2학기 텍스트 정보처리와 NLP 수업내용입니다.\n텍스트 분류모형을 개발하고, DTM의 종류별 성능 차이를 비교합니다.\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n준비하기\n패키지 로드하기\n\n분석 방법 정의\n데이터셋 샘플링\n데이터셋 분리\ntokenize 반복기 정의\n\nTF기반의 DTM 생성\nVocabulary 생성\nDocument Term Matrix\n생성하기\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\nPrune Vocabulary\nDocuments Term Matrix\n생성\n\nTF-IDF 기반의 DTM 생성\nDTM의 TF-IDF 변환\n\nDTM의 크기 비교\nLASSO 회귀모형 모델 적합\nFrequency 기반 모델링\nN-Grams 기반 모델링\nTF-IDF 기반의 모델\n\n모델 성능의 비교\n\n준비하기\n패키지 로드하기\n\n\n# ■ text2vec\n# -텍스트 분류모델 개발을 위해서 텍스트를 벡터화하는  패키지를 설치하고 불러오기\nif (!require(\"text2vec\")) {\n  install.packages(\"text2vec\")\n  library(\"text2vec\")\n}\n\n# ■ glmnet\n# - 분류모델 개발을 위한 glmnet 패키지를 설치하고 불러오기\n\nif (!require(\"glmnet\")) {\n  install.packages(\"glmnet\")\n  library(\"glmnet\")\n}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(caret)\nlibrary(bitTA)\n\n\n\n분석 방법 정의\n데이터셋 샘플링\n앞서 배운 tidymodels 패키지를 이용해서 데이터셋을 샘플링합니다.\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 87.5% : 12.5%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- rsample::initial_split(president_speech, prop = 7/8, strata = president)\n\npresident_smpl <- rsample::testing(president_split)\n\n\n\n데이터셋 분리\n비로소 모델 개발을 위한 데이터셋을 분리합니다.\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 70% : 30%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- initial_split(president_smpl, prop = 0.7, strata = president)\n\ntrain <- rsample::training(president_split)\ntest <- rsample::testing(president_split)\n\n\n\ntokenize 반복기 정의\ntokenizer로 text2vec::morpho_mecab()를 정의했기 때문에 띄어쓰기\n단위의 term이 생성될 것입니다.\n\n\n# 띄어쓰기 단위로 토큰을 생성\ntoken_fun <- text2vec::word_tokenizer\n\nit_train <- itoken(train$doc, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken(test$doc,\n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nTF기반의 DTM 생성\nVocabulary 생성\nvocabulary는 documents로부터 생성된 terms의 집합 여기서는 tokenizer를\n일반명사로 정의했기 때문에 일반명사 집합으로 vocabulary가 생성\n몇몇 데이터를 조회해보면 term별로 frequency와 document frequency가\n도출되었음을 알 수 있음\n또한 word2vec 패키지의 함수들은 parallel processing을 지원하므로,\nparallel 처리를 위한 multicores 사용을 지원하는 doMC, doParallel 등의\n패키지 사용이 필요.\n\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n        term term_count doc_count\n 1:   그리고        505       147\n 2:       한        505       134\n 3:       그        566       135\n 4:     있는        601       155\n 5:   여러분        607       175\n 6:       이        625       153\n 7:     우리        886       175\n 8:       수        935       167\n 9: 것입니다       1004       180\n10: 있습니다       1383       192\n\nDocument Term Matrix\n생성하기\ndocuments taxonomy 분류 모델을 수행하는 데이터셋은 DTM(Document Term\nMatrix) 구조여야 함. 그래서 vocabulary를 DTM으로 변환하는 작업을 수행.\ntext2vec::create_dtm() 함수를 사용.\n\n\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train)\n\n\n[1]   210 31602\n\n\n\ndtm_test <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test)\n\n\n[1]    92 31602\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 126313      3\n\n\n\nhead(vocab_bigram, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 2 \nVocabulary: \n            term term_count doc_count\n 1:          0.1          1         1\n 2:   0.1_미만의          1         1\n 3:     1,000_개          1         1\n 4: 1,000_만이나          1         1\n 5:        1,050          1         1\n 6:     1,050_억          1         1\n 7:        1,100          1         1\n 8: 1,100_여개의          1         1\n 9:        1,200          1         1\n10:   1,200_만이          1         1\n\nPrune Vocabulary\n\nDocuments의 개수가 증가하거나 Documents의 길이가 증가하면,\nVocabulary의 규모도 증가 함. 이것은 모델을 생성하는데 많은 컴퓨팅\n리소스를 소모해서 속도가 느려짐. 그래서 모델에 영향을 덜 줄 수 있는\nterms를 제거하는 작업이 필요함.\n\n\n\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 2046    3\n\nDocuments Term Matrix 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\n\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1]   92 2046\n\nTF-IDF 기반의 DTM 생성\nTF-IDF는 단일문서, 혹은 소수의 문서에서 의미가 있는 terms의 가중치를\n높이고 대부분의 문서에서 발현하는 terms의 가중치를 줄이는 용도로\n만들어진 측도입니다. 그러므로 DTM에 TF-IDF 변환을 수행하면 모델의 성능이\n개선됩니다\nText Anaytics에서는 documents의 길이의 차이가 있으면, 상대적으로\n짧거나 긴 documents에서 발현하는 terms들로 인해서 frequency scale에\n왜곡이 있을 수 있습니다. 이 경우에는 표준화를 수행해야 합니다. 그런데\nTF-IDF 변환은 자동으로 표준화가 되기 때문에 표준화의 잇점이 있습니다.\n만약 표준화를 수행하려면, normalize() 함수를 사용하면 됩니다.\nDTM의 TF-IDF 변환\nTfIdf class와 fit_transform() 함수를 이용해서 DTM에 TF-IDF 변환을\n수행합니다.\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test, tfidf) \n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train)\n\n\n[1]   210 31602\n\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\ndim(dtm_train_tfidf)\n\n\n[1]   210 31602\n\nLASSO 회귀모형 모델 적합\nFrequency 기반 모델링\n모델 생성\n\n\nNFOLDS <- 10\n\nclassifier <- cv.glmnet(x = dtm_train, y = train$president, \n                        family = 'multinomial', \n                        alpha = 1,\n                        type.measure = \"deviance\",\n                        nfolds = NFOLDS,\n                        thresh = 0.001,\n                        maxit = 1000,\n                        parallel = TRUE)\n\n\n\n모델의 평가\ntest 데이터로 평가한 결과 Accuracy가 0.869로 비교적 높게\n나타났습니다\n\n\npred_voca <- predict(classifier, dtm_test, type = 'response')[, , 1]\npresident_voca <- apply(pred_voca, 1, \n                        function(x) colnames(pred_voca)[which(max(x) == x)])\n\ncmat_voca <- confusionMatrix(factor(president_voca), factor(test$president))\ncmat_voca\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     21      0      2\n    노무현      7     25      4\n    이명박      3      5     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7717          \n                 95% CI : (0.6725, 0.8528)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.6579          \n                                          \n Mcnemar's Test P-Value : 0.06262         \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.6774        0.8333        0.8065\nSpecificity                 0.9672        0.8226        0.8689\nPos Pred Value              0.9130        0.6944        0.7576\nNeg Pred Value              0.8551        0.9107        0.8983\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2283        0.2717        0.2717\nDetection Prevalence        0.2500        0.3913        0.3587\nBalanced Accuracy           0.8223        0.8280        0.8377\n\nN-Grams 기반 모델링\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_bigram, y = train$president, \n                        family = 'multinomial', \n                        type.measure = \"deviance\",\n                        alpha = 1,                        \n                        nfolds = NFOLDS,\n                        parallel = TRUE)\n\n\n\n모델의 평가\nvocabulary를 가지지기했음에도 불구하고, 전체 vocabulary를 사용한\n모델보다 성능이 좋아졌습니다.\n\n\npred_bigram <- predict(classifier, dtm_test_bigram, type = 'response')[, , 1]\n\npresident_bigram <- apply(pred_bigram, 1, \n                          function(x) colnames(pred_bigram)[which(max(x) == x)])\n\ncmat_bigram <- confusionMatrix(factor(president_bigram), factor(test$president))\ncmat_bigram\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     22      1      1\n    노무현      3     25      5\n    이명박      6      4     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7826          \n                 95% CI : (0.6844, 0.8619)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.674           \n                                          \n Mcnemar's Test P-Value : 0.1966          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.7097        0.8333        0.8065\nSpecificity                 0.9672        0.8710        0.8361\nPos Pred Value              0.9167        0.7576        0.7143\nNeg Pred Value              0.8676        0.9153        0.8947\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2391        0.2717        0.2717\nDetection Prevalence        0.2609        0.3587        0.3804\nBalanced Accuracy           0.8384        0.8522        0.8213\n\nTF-IDF 기반의 모델\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_tfidf, y = train$president, \n                        family = 'multinomial', \n                        nfolds = NFOLDS,\n                        thresh = 1e-3,\n                        maxit = 1e3,\n                        parallel = TRUE)\n\n\n\n모델의 평가\n\n\npred_tfidf <- predict(classifier, dtm_test_tfidf, type = 'response')[, , 1]\n\npresident_tfidf <- apply(pred_tfidf, 1, \n                         function(x) colnames(pred_tfidf)\n                         [which(max(x) == x)])\n\ncmat_tfidf <- confusionMatrix(factor(president_tfidf), factor(test$president))\ncmat_tfidf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     28      7      4\n    노무현      2     20      2\n    이명박      1      3     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7935          \n                 95% CI : (0.6964, 0.8708)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.6899          \n                                          \n Mcnemar's Test P-Value : 0.1888          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.9032        0.6667        0.8065\nSpecificity                 0.8197        0.9355        0.9344\nPos Pred Value              0.7179        0.8333        0.8621\nNeg Pred Value              0.9434        0.8529        0.9048\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.3043        0.2174        0.2717\nDetection Prevalence        0.4239        0.2609        0.3152\nBalanced Accuracy           0.8614        0.8011        0.8704\n\n모델 성능의 비교\n모델의 성능은 TF-IDF > Bigram(Pruned) > Frequency의 순서로\n나타납니다.\n그러므로 성능을 높이기 위해서는 TF-IDF 방법을 사용하는 것이 좋으며,\n대용량의 데이터 분석에서는 적은 성능 감소와 수행 속도의 개선을 가져오는\nFeature Hashing 기법을 사용하면 될 것입니다. 이 경우에는 Purne\nVocabulary 전처리도 필요할 것입니다.\n다만, 몇몇 결과는 그 성능 차이가 작기 때문에 모델의 파라미터에 따라\n순서가 바뀔수도 있습니다\n\n\naccuracy <- rbind(cmat_voca$overall, \n                  cmat_bigram$overall, \n                  cmat_tfidf$overall) %>%\n  round(3)\n\ndata.frame(Method = c(\"Frequency\", \"Bigram\", \"TF-IDF\"),\n           accuracy) %>%\n  arrange(desc(Accuracy)) %>%\n  knitr::kable()\n\n\nMethod\nAccuracy\nKappa\nAccuracyLower\nAccuracyUpper\nAccuracyNull\nAccuracyPValue\nMcnemarPValue\nTF-IDF\n0.793\n0.690\n0.696\n0.871\n0.337\n0\n0.189\nBigram\n0.783\n0.674\n0.684\n0.862\n0.337\n0\n0.197\nFrequency\n0.772\n0.658\n0.672\n0.853\n0.337\n0\n0.063\n\n\n\n\n",
      "last_modified": "2022-12-10T22:39:34+09:00"
    },
    {
      "path": "create_website.html",
      "title": "웹 사이트 개발하기",
      "description": "웹 사이트 개발하는 방법을 간단하게 소개합니다.\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n설정사항\n수정해야할 사항\n웹 사이트 구성 파일\n개별 페이지 구성 정보\n\nData: USArrests\n표(tables) 출력\n플롯(plots) 출력\n\n\n\n\n\n\n들어가기\n이 웹 사이트는 예제를 위해서 만든 간단한 사이트입니다.\n\n여러분은 이 Skelton 사이트에 살을 붙여서 자신의 웹 사이트를 만들 수 있습니다. 그리고 이 작업은 사이트의 구조를 이해하는 것으로부터 시작됩니다.\n\n\n\n설정사항\n수정해야할 사항\n본 템플리트는 웹 사이트 중의 한 페이지로 bitReport\nwebsite라는 이름의 예제입니다. 환경 설정파일인\n_site.yml에 “샘플 웹 사이트”이라는 제목으로 연결되어\n있습니다. 만약에 예제 템플리트를 완성하려면 이 페이지의 이름을\n_site.yml에서의 create_website과 동일하게\n설정해야 합니다.\n웹 사이트 구성 파일\n웹 사이트를 구성하는 설정은 구성파일인 **_site.yml**에\n정의합니다.\n_site.yml 파일에서의 사용자가 설정해야할 항목은 다음과 같습니다.\nname: 웹 사이트의 이름\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ntitle: 웹 사이트의 타이틀\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ndescription: 웹 사이트의 설명\noutput_dir: 생성될 웹 사이트의 정적 HTML이 저장될 디렉토리\n“docs”로 기본설정됩니다. 이 디렉토리는 github page로 deploy할 때\n유용합니다.\n\nnavbar: 웹 사이트의 메뉴를 정의하는 섹션입니다.\n수정하지 않습니다.\n\nright: 웹 사이트의 메뉴를 정의합니다.\ntext는 메뉴 이름입니다.\nhref는 메뉴와 연결할 웹 페이지입니다. 확장자는\nhtml입니다.\nR markdown 파일과 동일하게 이름을 부여합니다.\n\nmenu는 서브메뉴를 정의합니다.\n빈 분리자를 만들기 위해서는 “- text:”—“를 사용합니다.\n\noutput: 웹 사이트 출력에 대한 설정입니다. 사용자가 수정하지\n않습니다.\n개별 페이지 구성 정보\n개별 페이지를 구성하기 위해서는 knitr YAML을 수정해야 합니다.\ntitle: 웹 페이지 제목입니다.\ndescription: 웹 페이지를 간단하게 소개하는 소개문입니다.\nauthor: 웹 페이지 컨텐츠 저작자 정보를 기술합니다.\nname: 저작자 이름\nurl: 저작자 개인 홈페이지 URL\naffiliation: 저작자 소속 회사/부서\naffiliation_url: 저작자 소속 회사/부서 홈페이지 URL\n\ndate: 컨텐츠를 생성한 날짜\noutput: 웹 사이트 출력에 대한 설정입니다.\ntoc: 목차를 출력할 지의 여부를 정의합니다. true이면 출력합니다.\ntoc_depth: 출력할 목차의 depth를 정의합니다. 3이면 3 depth까지\n표시합니다.\n\n\n이 예제 웹 사이트는 하나의 완성된 페이지를 만드는 것이 아닌, 가상의\nsite를 담은 Skelton만 제공합니다. 그러므로 개별 페이지의 내용에 신경쓸\n필요가 없습니다.\n\nData: USArrests\nUSArrests는 미국 주별 강력 범죄율을 기록한\n데이터입니다.\n이 데이터셋은 4개의 변수와 50개의 관측치로 구성된 데이터\n프레임(data.frame) 객체입니다.:\nMurder\nnumeric. 살인범 검거 건수(100,000건당)\n\nAssault\nnumeric. 폭행범 검거 건수(100,000건당)\n\nUrbanPop\nnumeric. 도시 인구 비율(백분율)\n\nRape\nnumeric. 강간범 검거 건수(100,000건당)\n\n\n\n# code here\n\n\n\n표(tables) 출력\n미국 주별 강력 범죄율을 기록한 데이터인 USArrests를 표로\n출력합니다.\n\n\nUSArrests %>% \n  tibble::rownames_to_column(\"주 (State)\") %>% \n  arrange(desc(Murder + Assault + Rape)) %>% \n  filter(row_number() <= 10) %>% \n  select(1:3, 5, 4) %>% \n  rename(`살인범` = Murder) %>% \n  rename(`폭행범` = Assault) %>% \n  rename(`강간범` = Rape) %>% \n  rename(`도시인구수(백분율)` = UrbanPop) %>%   \n  kableExtra::kbl(\n    caption = \"미국 범죄 상위 10개 주 현황\",\n    format.args = list(big.mark = \",\", digits = 1, scientific = 6)\n  ) %>% \n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>% \n  kableExtra::add_header_above(c(\" \" = 1, \"범죄자수 (인구 만명 당)\" = 3, \" \" = 1)) %>% \n  kableExtra::kable_classic(full_width = TRUE) \n\n\n\nTable 1: 미국 범죄 상위 10개 주 현황\n\n\n\n\n\n범죄자수 (인구 만명 당)\n\n\n\n\n\n주 (State)\n\n\n살인범\n\n\n폭행범\n\n\n강간범\n\n\n도시인구수(백분율)\n\n\nFlorida\n\n\n15\n\n\n335\n\n\n32\n\n\n80\n\n\nNorth Carolina\n\n\n13\n\n\n337\n\n\n16\n\n\n45\n\n\nMaryland\n\n\n11\n\n\n300\n\n\n28\n\n\n67\n\n\nArizona\n\n\n8\n\n\n294\n\n\n31\n\n\n80\n\n\nNew Mexico\n\n\n11\n\n\n285\n\n\n32\n\n\n70\n\n\nCalifornia\n\n\n9\n\n\n276\n\n\n41\n\n\n91\n\n\nAlaska\n\n\n10\n\n\n263\n\n\n44\n\n\n48\n\n\nSouth Carolina\n\n\n14\n\n\n279\n\n\n22\n\n\n48\n\n\nNevada\n\n\n12\n\n\n252\n\n\n46\n\n\n81\n\n\nMichigan\n\n\n12\n\n\n255\n\n\n35\n\n\n74\n\n\n플롯(plots) 출력\n이 예제는 가상의 설명을 포함하고 있는, 그저 템플리트를 위한\n예제입니다.\n온도에 따른 수은의 증기압을 기록한 데이터인 pressure 데이터 프레임을\n산점도록 시각화합니다.\n\n\nplot(pressure, pch = 16, main = \"Relation between temperature and pressure\")\nlines(loess(pressure ~ temperature, pressure), col = \"steelblue\")\n\n\n\n\nFigure 1: 플롯 예제\n\n\n\n\n\n\n",
      "last_modified": "2022-12-10T22:58:43+09:00"
    },
    {
      "path": "index.html",
      "title": "텍스트 데이터 분석",
      "description": "텍스트 분석은 자연어로 구성된 대량의 비정형 텍스트 또는 사전 정의된 형식이 없는 텍스트를 처리하여 패턴이나 관계를 알아내어 의미있는 정보를 찾는 것을 말한다. 방대한 양의 비정형 텍스트 문서로부터 주요 토픽",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n내가 기대하는 텍스트\n분석\n\n내가 기대하는 텍스트 분석\n연구자들은 텍스트 분석을 통해 짧은 시간에 많은 양의 기존\n문헌을 탐색하여 연구와 관련된 내용을 추출할 수\n있을 것이다.\n대통령 연설문 텍스트 분석을 통해 역대 대통령의 중심가치를\n파악할 수 있을 것이다.연설문에 나타난 단어의 빈도를\n분석하고 언어 네트워크 분석을 통해 역대\n대통령들의 중심가치 변화와 흐름을 분석할 수 있을 것이다.\n\n\n\n\n\n\n\n",
      "last_modified": "2022-12-10T22:58:28+09:00"
    }
  ],
  "collections": []
}
