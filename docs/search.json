{
  "articles": [
    {
      "path": "classifier_bert.html",
      "title": "캡스톤 프로젝트",
      "description": "2022학년도 2학기 텍스트 정보처리와 NLP 수업내용입니다.\n한 학기 과정의 핵심 내용을 실습을 통해서 다시한번 다지기\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n텍스트 데이터 수집\n데이터 수집\n간단한 데이터 요약\n\n정규표현식의 이해\n패턴 검색\n\nDocument Term Matrix의\n이해\nDTM 생성하기\n\nCorrelation Analysis\n연관분석\nBinary Term Frequency\n기반 DTM 생성\n불용어 제거\nTransactions 생성하기\n연관규칙 생성하기\n연관규칙 시각화하기\n\n단어의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\nClustering\n군집의 해석\n\n기사의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\n군집 개수 선정 및\n시각화\n군집의 해석\n기사 군집 1\n\nTopic 분석\nOTF 계산\n불용어 제거\nTopic Modeling\nTopic 개수 구하기\nTop beta 단어의 시각화\n문서에서의 토픽의 비중\n토픽이 포함된 문서 조회\n문서의 토픽 분해\n토픽의 단어 분해\n\n이진분류 모형\n패키지 로드하기\n파생변수 만들기\n불균형 데이터의 언더\n샘플링\n데이터셋 분리\ntokenize 반복기 정의\nFrequency 기반의 DTM\n생성\nN-Grams 기반의 DTM 생성\nTF-IDF 기반의 DTM 생성\nDTM의 크기 비교\nFrequency 기반 모델링\n모델의 이해\n모델의 평가\n\n\n텍스트 데이터 수집\n데이터 수집\n인증키와 키워드 입력\nclient_id, client_secret는 사용자의 API 인증키를 삽입\n\n\nlibrary(koscrap)\n\n# Naver 뉴스 API 인증키\nclient_id <- \"D_7oXG2_osfloS1rLW2X\"\nclient_secret <- \"7Q8pd9QSnM\"\n\n# 검색 키워드\nkeyword <- \"월드컵\"\n\n\n\n날짜 정렬 기준 수집\n날짜 기준 정렬로 1,000건의 뉴스를 수집\n\n\nn <- 1000\n# 날짜 정렬 수집\nnews_worldcup_date <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret,\n  do_done = TRUE, max_record = n\n)\n\n\n* 검색된 총 기사 건수는 2741070건입니다.\n- (100/1000)건 호출을 진행합니다.\n- (200/1000)건 호출을 진행합니다.\n- (300/1000)건 호출을 진행합니다.\n- (400/1000)건 호출을 진행합니다.\n- (500/1000)건 호출을 진행합니다.\n- (600/1000)건 호출을 진행합니다.\n- (700/1000)건 호출을 진행합니다.\n- (800/1000)건 호출을 진행합니다.\n- (900/1000)건 호출을 진행합니다.\n- (1000/1000)건 호출을 진행합니다.\n\n유사도 정렬 기준 수집\n유사도 기준 정렬로 1,000건의 뉴스를 수집\n\n\n# 유사도 정렬 수집\nnews_worldcup_sim <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret, sort = \"sim\",\n  do_done = TRUE, max_record = n\n)\n\n\n* 검색된 총 기사 건수는 2741070건입니다.\n- (100/1000)건 호출을 진행합니다.\n- (200/1000)건 호출을 진행합니다.\n- (300/1000)건 호출을 진행합니다.\n- (400/1000)건 호출을 진행합니다.\n- (500/1000)건 호출을 진행합니다.\n- (600/1000)건 호출을 진행합니다.\n- (700/1000)건 호출을 진행합니다.\n- (800/1000)건 호출을 진행합니다.\n- (900/1000)건 호출을 진행합니다.\n- (1000/1000)건 호출을 진행합니다.\n\n데이터를 수집하는 시점에 따라 결과가 다르겠지만, 각각 1000건의\n데이터가 수집되었습니다. 변수의 개수는 7개입니다.\n\n\ndim(news_worldcup_date)\n\n\n[1] 1000    7\n\ndim(news_worldcup_sim)\n\n\n[1] 1000    7\n\n앞, 뒤의 몇 건을 조회\n\n\nhead(news_worldcup_date)\n\n\n                                                                                                    title\n1                                   메시, WC 10호골→바티스투타와 나란히...4강서 &apos;단독 1위&apos; 겨냥\n2                        &apos;충격패&apos; 브라질의 새 감독은?...팬들은 &apos;세계적인 명장&apos; 원한다\n3                          &apos;8강 대진표&apos; 잉글랜드 대 프랑스 경기 중계·피파랭킹·예상선발라인업은?\n4 &apos;아형&apos; 윤시윤 &quot;전 세계 추기경들, &apos;탄생&apos; 시사회서 <b>월드컵<\/b> 얘기 한창&quot;\n5         &apos;전지적 참견 시점&apos;·&apos;그것이 알고싶다&apos; 2주 연속 결방, <b>월드컵<\/b> 중계 때문\n6                                            “치킨 눅눅해 지겼네” 5천원 배달비도 비싼데, 배달도 늦어진다?\n                                                       originallink\n1 http://www.interfootball.co.kr/news/articleView.html?idxno=591913\n2    http://www.fourfourtwo.co.kr/news/articleView.html?idxno=25155\n3     https://www.gukjenews.com/news/articleView.html?idxno=2611700\n4   https://www.starnewskorea.com/stview.php?no=2022121020541081352\n5                          http://www.mediapen.com/news/view/777183\n6             http://news.heraldcorp.com/view.php?ud=20221209000677\n                                                           link\n1 https://sports.news.naver.com/news.nhn?oid=413&aid=0000151550\n2 https://sports.news.naver.com/news.nhn?oid=411&aid=0000020277\n3 https://www.gukjenews.com/news/articleView.html?idxno=2611700\n4 https://n.news.naver.com/mnews/article/108/0003111938?sid=106\n5                      http://www.mediapen.com/news/view/777183\n6 https://n.news.naver.com/mnews/article/016/0002076587?sid=105\n                                                                                                                                                                                                                                             description\n1                                   카타르 <b>월드컵<\/b> 8강전에서 네덜란드와 2-2로 비긴 뒤 승부차기에서 4-3으로 승리하며 4강 진출에 성공했다. 오는 14일 오전 4시 브라질을 격추한 크로아티아와 대결을 치른다. 역대 <b>월드컵<\/b>에서 토너먼트만 되면... \n2                          브라질은 10일 오전 0시(한국시간) 카타르 알 라이얀에 위치한 에듀케이션 시티 스타디움에서 열린 2022 국제축구연맹(FIFA) 카타르 <b>월드컵<\/b> 8강전에서 크로아티아와 승부차기 끝에 패배(1-1, PK 2-4)했다. 우승 후보 1순위였던... \n3   &apos;2022 FIFA 카타르 <b>월드컵<\/b>&apos; 잉글랜드 대 프랑스의 토너먼트 8강 경기 / 사진=잉글랜드 축구협회 SNS &apos;2022 FIFA 카타르 <b>월드컵<\/b>&apos; 잉글랜드 대 프랑스의 토너먼트 8강 경기가 치러진다. 11일 오전 4시 알바이트 스타디움에서... \n4 이에 민경훈은 &quot;뭐라고 하고 계시더냐&quot;라며 흥미 있는 반응을 보였지만 윤시윤은 &quot;<b>월드컵<\/b> 얘기를 하고 계시더라&quot;라고 예상 외의 답변을 해 보는 이들로 하여금 웃음을 자아냈다. 이에 이수근은 &quot;전세계인의 축제니까&quot;라며... \n5    사진=MBC &apos;전지적 참견 시점&apos;, SBS &apos;그것이 알고 싶다&apos; 홈페이지 2022 카타르<b>월드컵<\/b> 중계방송 때문이다. 이날 밤 12시부터는 <b>월드컵<\/b> 8강전 모로코-포르투갈 경기가 열린다. 지상파 TV 3사가 모두 생중계를 한다. MBC는 밤... \n6                                   최근 <b>월드컵<\/b> 한국팀 경기가 있던 날 배달 수요가 공급을 따라가지 못해 1만원의 배달비가 등장할 만큼 배달비는 가파르게 상승하고 있다. 이에 한 소비자는 “배달비 너무 비싸서 놀랄 지경이다. 배달 질까지 내려가면... \n         publish_date\n1 2022-12-10 21:52:00\n2 2022-12-10 21:51:00\n3 2022-12-10 21:48:00\n4 2022-12-10 21:45:00\n5 2022-12-10 21:40:00\n6 2022-12-10 21:36:00\n                                                       title_text\n1           메시 WC 10호골→바티스투타와 나란히4강서 단독 1위 겨냥\n2            충격패 브라질의 새 감독은팬들은 세계적인 명장 원한다\n3 8강 대진표 잉글랜드 대 프랑스 경기 중계피파랭킹예상선발라인업은\n4     아형 윤시윤 전 세계 추기경들 탄생 시사회서 월드컵 얘기 한창\n5  전지적 참견 시점그것이 알고싶다 2주 연속 결방 월드컵 중계 때문\n6        치킨 눅눅해 지겼네 5천원 배달비도 비싼데 배달도 늦어진다\n                                                                                                                                                                                                        description_text\n1                 카타르 월드컵 8강전에서 네덜란드와 2-2로 비긴 뒤 승부차기에서 4-3으로 승리하며 4강 진출에 성공했다. 오는 14일 오전 4시 브라질을 격추한 크로아티아와 대결을 치른다. 역대 월드컵에서 토너먼트만 되면... \n2 브라질은 10일 오전 0시(한국시간) 카타르 알 라이얀에 위치한 에듀케이션 시티 스타디움에서 열린 2022 국제축구연맹(FIFA) 카타르 월드컵 8강전에서 크로아티아와 승부차기 끝에 패배(1-1, PK 2-4)했다. 우승 후보 1순위였던... \n3         2022 FIFA 카타르 월드컵 잉글랜드 대 프랑스의 토너먼트 8강 경기 / 사진=잉글랜드 축구협회 SNS 2022 FIFA 카타르 월드컵 잉글랜드 대 프랑스의 토너먼트 8강 경기가 치러진다. 11일 오전 4시 알바이트 스타디움에서... \n4            이에 민경훈은 뭐라고 하고 계시더냐라며 흥미 있는 반응을 보였지만 윤시윤은 월드컵 얘기를 하고 계시더라라고 예상 외의 답변을 해 보는 이들로 하여금 웃음을 자아냈다. 이에 이수근은 전세계인의 축제니까라며... \n5          사진=MBC 전지적 참견 시점, SBS 그것이 알고 싶다 홈페이지 2022 카타르월드컵 중계방송 때문이다. 이날 밤 12시부터는 월드컵 8강전 모로코-포르투갈 경기가 열린다. 지상파 TV 3사가 모두 생중계를 한다. MBC는 밤... \n6           최근 월드컵 한국팀 경기가 있던 날 배달 수요가 공급을 따라가지 못해 1만원의 배달비가 등장할 만큼 배달비는 가파르게 상승하고 있다. 이에 한 소비자는 배달비 너무 비싸서 놀랄 지경이다. 배달 질까지 내려가면... \n\ntail(news_worldcup_sim)\n\n\n                                                                                                 title\n995                                       <b>월드컵<\/b> 8강전도 멈췄다…그라운드로 뛰어드는 관중들, 왜?\n996                     &apos;랭킹 1위&apos; 김민선, <b>월드컵<\/b> 3회 연속 우승...생애 첫 36초대 진입\n997                                                          꿈의 대진? 어림없지!…9일 밤 <b>월드컵<\/b>\n998                  [<b>월드컵<\/b>] 8년 만에 4강 진출에도 화난 메시 &quot;심판 판정에 분노 느껴&quot;\n999                     [<b>월드컵<\/b>] 16강까지 경고 한번 없는 잉글랜드…&apos;축구도 신사적으로&apos;\n1000 [간밤의 <b>월드컵<\/b>] &apos;펠레의 저주?&apos; 브라질 충격 탈락...메시-네이마르 &apos;희비 교...\n                                                       originallink\n995            https://view.asiae.co.kr/article/2022121018544394179\n996                       http://www.osen.co.kr/article/G1112005893\n997  https://www.khan.co.kr/sports/worldcup/article/202212082228005\n998                           https://www.news1.kr/articles/4890739\n999     https://www.yna.co.kr/view/AKR20221209122400007?input=1195m\n1000                   http://news.tf.co.kr/read/soccer/1985087.htm\n                                                              link\n995  https://n.news.naver.com/mnews/article/277/0005190071?sid=104\n996  https://sports.news.naver.com/news.nhn?oid=109&aid=0004755695\n997  https://n.news.naver.com/mnews/article/032/0003191776?sid=104\n998  https://n.news.naver.com/mnews/article/421/0006511536?sid=104\n999  https://n.news.naver.com/mnews/article/001/0013633989?sid=104\n1000 https://n.news.naver.com/mnews/article/629/0000189389?sid=104\n                                                                                                                                                                                                                                                    description\n995                                 2022 국제축구연맹(FIFA) 카타르 <b>월드컵<\/b>에서 관중의 경기장 난입이 잇따르고 있다. 조별리그 경기 도중... 그는 2014년 브라질 <b>월드컵<\/b> 결승전 독일과 아르헨티나의 경기에서도 그라운드에 난입해 물의를 빚었다. 당시... \n996                                    의정부시청)이 <b>월드컵<\/b> 3회 연속 우승을 달성하며 랭킹 1위의 위용을 떨쳤다. 김민선은 10일(한국시간) 캐나다 캘거리 올림픽 오벌에서 열린 2022-2023 국제빙상경기연맹(ISU) 스피드스케이팅 <b>월드컵<\/b> 3차 대회 여자... \n997                            32년 만에 남미의 두 강호가 <b>월드컵<\/b>에서 만날까. 2022 카타르 <b>월드컵<\/b>도 막바지를 향하고 있다. 8강이 가려진 가운데 오는 주말부터 4강 경쟁이 시작된다. 10일 0시 브라질-크로아티아(에듀케이션 시티 스타디움), 오전 4시... \n998                          카타르 <b>월드컵<\/b> 8강전에서 연장전까지 2-2로 비긴 뒤 펼쳐진 승부차기에서 4PK3으로 이겼다. 이로써... 이는 역대 <b>월드컵<\/b> 한 경기 최다 옐로 카드 기록이다. 이날 AFP통신 등 외신에 따르면 메시는 경기 후 &quot;나는 주심에... \n999              2022 국제축구연맹(FIFA) 카타르 <b>월드컵<\/b>이 16강까지 일정을 마친 가운데 &apos;신사의 나라&apos; 잉글랜드가 유일하게... 사우디아라비아는 2018년 러시아 <b>월드컵<\/b> 때는 경고 1장으로 32개 참가국 가운데 최소를 기록했다. 2018년 러시아... \n1000 10일 2022 카타르 <b>월드컵<\/b> 8강전 크로아티아 42(1-1) 브라질 네덜란드 34(2-2) 아르헨티나 14일 아르헨-크로아 4강 격돌 &apos;펠레의 저주&apos;인가. <b>월드컵<\/b>의 &apos;영원한 우승 후보&apos; 브라질이 또 탈락하며 네이마르가 눈물을 흘렸다. 리오넬... \n            publish_date\n995  2022-12-10 20:22:00\n996  2022-12-10 14:59:00\n997  2022-12-08 22:31:00\n998  2022-12-10 10:16:00\n999  2022-12-09 16:45:00\n1000 2022-12-10 07:58:00\n                                                         title_text\n995              월드컵 8강전도 멈췄다그라운드로 뛰어드는 관중들 왜\n996         랭킹 1위 김민선 월드컵 3회 연속 우승생애 첫 36초대 진입\n997                                 꿈의 대진 어림없지9일 밤 월드컵\n998    월드컵 8년 만에 4강 진출에도 화난 메시 심판 판정에 분노 느껴\n999        월드컵 16강까지 경고 한번 없는 잉글랜드축구도 신사적으로\n1000 간밤의 월드컵 펠레의 저주 브라질 충격 탈락메시네이마르 희비 교\n                                                                                                                                                                                                         description_text\n995         2022 국제축구연맹(FIFA) 카타르 월드컵에서 관중의 경기장 난입이 잇따르고 있다. 조별리그 경기 도중... 그는 2014년 브라질 월드컵 결승전 독일과 아르헨티나의 경기에서도 그라운드에 난입해 물의를 빚었다. 당시... \n996            의정부시청)이 월드컵 3회 연속 우승을 달성하며 랭킹 1위의 위용을 떨쳤다. 김민선은 10일(한국시간) 캐나다 캘거리 올림픽 오벌에서 열린 2022-2023 국제빙상경기연맹(ISU) 스피드스케이팅 월드컵 3차 대회 여자... \n997    32년 만에 남미의 두 강호가 월드컵에서 만날까. 2022 카타르 월드컵도 막바지를 향하고 있다. 8강이 가려진 가운데 오는 주말부터 4강 경쟁이 시작된다. 10일 0시 브라질-크로아티아(에듀케이션 시티 스타디움), 오전 4시... \n998        카타르 월드컵 8강전에서 연장전까지 2-2로 비긴 뒤 펼쳐진 승부차기에서 4PK3으로 이겼다. 이로써... 이는 역대 월드컵 한 경기 최다 옐로 카드 기록이다. 이날 AFP통신 등 외신에 따르면 메시는 경기 후 나는 주심에... \n999  2022 국제축구연맹(FIFA) 카타르 월드컵이 16강까지 일정을 마친 가운데 신사의 나라 잉글랜드가 유일하게... 사우디아라비아는 2018년 러시아 월드컵 때는 경고 1장으로 32개 참가국 가운데 최소를 기록했다. 2018년 러시아... \n1000 10일 2022 카타르 월드컵 8강전 크로아티아 42(1-1) 브라질 네덜란드 34(2-2) 아르헨티나 14일 아르헨-크로아 4강 격돌 펠레의 저주인가. 월드컵의 영원한 우승 후보 브라질이 또 탈락하며 네이마르가 눈물을 흘렸다. 리오넬... \n\n간단한 데이터 요약\n뉴스 빈발 단어\n빈발단어를 워드클라우드로 시각화하는 함수를 만듦\n\n\n# create UDF\ncreate_wordcloud <- function(data, remove_n = 5, min_freq = 5, background = \"white\") {\n  data %>% \n    filter(nchar(description_text) > 0) %>%   \n    tidytext::unnest_tokens(noun, description_text, bitTA::morpho_mecab, type = \"noun\") %>% \n    group_by(noun) %>% \n    count() %>% \n    arrange(desc(n)) %>%     \n    ungroup() %>%\n    filter(n >= min_freq) %>% \n    filter(row_number() > remove_n) %>% \n    wordcloud2::wordcloud2(backgroundColor = background, \n                           fontFamily = \"NanumSquare\")\n}\n\n\n\n날짜 기준으로 정렬 수집한 뉴스에 대해서 워드클라우드를 그려\n봅니다.\n\n\nlibrary(bitReport)\n\nnews_worldcup_date %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n\n\n(#fig:wcloud_wcupdate)날짜 기준 월드컵 뉴스\n\n\n\n유사도 기준으로 정렬 수집한 뉴스에 대해서 워드클라우드를 그려\n봅니다.\n\n\nnews_worldcup_sim %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n\n\n(#fig:wcloud_wcupsim)유사도 기준 월드컵 뉴스\n\n\n\n정규표현식의 이해\n패턴 검색\n유사도 정렬 기준으로 수집한 뉴스 중에서 선수와 감독의 이름이 포함된\n기사의 건수를 계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_int(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        tally() %>% \n        pull()\n    }\n  )\n\n\n[1]  20 116  59  10  29 101\n\n각각의 기사에서 해당 선수와 감독의 이름이 평균 몇 번 등장하는지\n계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_dbl(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        mutate(n_talk = stringr::str_count(description_text, x)) %>% \n        summarise(n_avg = mean(n_talk, na.rm = TRUE)) %>% \n        pull()\n    }\n  )\n\n\n[1] 1.000000 1.801724 1.830508 1.000000 1.689655 1.099010\n\nDocument Term Matrix의 이해\nDTM 생성하기\n유사도 정렬 기준 뉴스의 Term Frequency 기반의 DTM과 TF-IDF 기반의\nDTM을 생성합니다. 뉴스 데이터는 문서 아이디로 사용할 변수가 없기 때문에\n아이디를 만듧니다.\n\n\nnews_worldcup_sim <- news_worldcup_sim %>% \n  mutate(id = row_number())\n\n\n\nTERM FREQUENCY 기반의 DTM\n인명인 고유명사도 함께 추출한 DTM을 만들기 위해서\nunnest_noun_ngrams() 함수의 type 인수값에 “noun2”를 사용합니다\n\n\nlibrary(tidyverse)\nlibrary(bitTA)\nlibrary(tidytext)\nlibrary(tm)\n\ndtm_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n)\n\ntm::inspect(dtm_tf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 710)>>\nNon-/sparse entries: 20576/689424\nSparsity           : 97%\nMaximal term length: 7\nWeighting          : term frequency (tf)\nSample             :\n     Terms\nDocs  강 년 대표 시간 월드컵 일 축구 카타르 팀 한국\n  146  0  2    1    0      2  1    1      1  1    0\n  245  0  2    1    0      2  1    1      1  1    0\n  344  0  2    1    0      2  1    1      1  1    0\n  443  0  2    1    0      2  1    1      1  1    0\n  47   0  2    1    0      2  1    1      1  1    0\n  542  0  2    1    0      2  1    1      1  1    0\n  641  0  2    1    0      2  1    1      1  1    0\n  740  0  2    1    0      2  1    1      1  1    0\n  839  0  2    1    0      2  1    1      1  1    0\n  938  0  2    1    0      2  1    1      1  1    0\n\nTF-IDF 기반의 DTM\n\n\ndtm_tfidf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightTfIdf)\n\ntm::inspect(dtm_tfidf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 710)>>\nNon-/sparse entries: 20576/689424\nSparsity           : 97%\nMaximal term length: 7\nWeighting          : term frequency - inverse document frequency (normalized) (tf-idf)\nSample             :\n     Terms\nDocs  강 강전 년 대표 브라질 손흥민 아르헨티나 우승 팀 한국\n  124  0    0  0    0      0      0          0    0  0    0\n  223  0    0  0    0      0      0          0    0  0    0\n  25   0    0  0    0      0      0          0    0  0    0\n  322  0    0  0    0      0      0          0    0  0    0\n  421  0    0  0    0      0      0          0    0  0    0\n  520  0    0  0    0      0      0          0    0  0    0\n  619  0    0  0    0      0      0          0    0  0    0\n  718  0    0  0    0      0      0          0    0  0    0\n  817  0    0  0    0      0      0          0    0  0    0\n  916  0    0  0    0      0      0          0    0  0    0\n\nCorrelation Analysis\n각각의 선수와 감독별로 상관계수가 0.4 이상인 단어를 추출해봅니다. ###\nTerm Frequency\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map(\n    function(x) tm::findAssocs(dtm_tf, terms = x, corlimit = 0.4)\n  )\n\n\n[[1]]\n[[1]]$벤투\n  결별   원정 파울루   역대   독일   연속 러시아 \n  1.00   1.00   1.00   0.88   0.84   0.49   0.41 \n\n\n[[2]]\n[[2]]$손흥민\n토트넘   도박   결정   수술   투명   감사   의학 전문가   주장   안면 \n  0.67   0.61   0.59   0.59   0.59   0.57   0.54   0.54   0.54   0.52 \n  인사   출전     팬   결장   생각   응원   후회 \n  0.51   0.51   0.51   0.45   0.45   0.43   0.41 \n\n\n[[3]]\n[[3]]$조규성\n      전북       출연   아나운서       주시       뉴스       대세 \n      0.87       0.76       0.64       0.64       0.64       0.64 \n      현대       스타       적설       자신       진행     이야기 \n      0.64       0.62       0.57       0.46       0.46       0.44 \n      가치       강조 스트라이커       중요       증명     뉴스룸 \n      0.42       0.42       0.42       0.42       0.42       0.42 \n        건       구체       멀티   에피소드     와이드       이적 \n      0.42       0.42       0.42       0.42       0.42       0.42 \n      최초       토요 \n      0.42       0.42 \n\n\n[[4]]\n[[4]]$이강인\n  여기   조규   주목   처음 북중미   본선   성공     이 \n  1.00   1.00   1.00   0.72   0.66   0.57   0.57   0.43 \n\n\n[[5]]\n[[5]]$호날두\n        제외     포르투갈       스위스         시각         코르 \n        0.95         0.82         0.67         0.67         0.67 \n크리스티아누         교체         명단         벤치       산투스 \n        0.67         0.67         0.67         0.67         0.67 \n    페르난두         협박         선발         보도         매체 \n        0.67         0.67         0.66         0.66         0.58 \n        소식           드       이야기         현지 \n        0.49         0.46         0.46         0.43 \n\n\n[[6]]\n[[6]]$메시\n      도움       통산 아르헨티나   토너먼트         호   네덜란드 \n      0.66       0.59       0.55       0.55       0.55       0.52 \n바티스투타       상대   승부차기       호골     리오넬       남미 \n      0.45       0.45       0.44       0.43       0.43       0.42 \n      최다 \n      0.40 \n\n연관분석\nBinary Term Frequency 기반\nDTM 생성\n\n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\n불용어 제거\n상위 50위인 단어를 불용어로 처리하여 제거합니다.\n\n\nstop_words <- dtm_bin_tf %>% \n  apply(2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  \"[\"(1:30) %>% \n  names()\nstop_words\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"한국\"        \n [5] \"팀\"           \"축구\"         \"강\"           \"대표\"        \n [9] \"시간\"         \"국제축구연맹\" \"년\"           \"우승\"        \n[13] \"강전\"         \"대회\"         \"브라질\"       \"경기\"        \n[17] \"진출\"         \"이번\"         \"아르헨티나\"   \"승부차기\"    \n[21] \"연속\"         \"만\"           \"카타르월드컵\" \"회\"          \n[25] \"크로아티아\"   \"손흥민\"       \"출전\"         \"차\"          \n[29] \"스타디움\"     \"감독\"        \n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!term %in% stop_words) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\nTransactions 생성하기\n\n\nlibrary(\"arules\")\n\ntrans <- as(dtm_bin_tf %>% as.matrix(), \"transactions\")\ntrans\n\n\ntransactions in sparse format with\n 1000 transactions (rows) and\n 679 items (columns)\n\nsummary(trans)\n\n\ntransactions as itemMatrix in sparse format with\n 1000 rows (elements/itemsets/transactions) and\n 679 columns (items) and a density of 0.01935199 \n\nmost frequent items:\n      끝 네덜란드       전     메시     탈락  (Other) \n     109      109      104      101      101    12616 \n\nelement (itemset/transaction) length distribution:\nsizes\n  5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  22 \n  9  50  10  10  60  80  67 146 140  88  82  69  85  49  17  28  10 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.00   11.00   13.00   13.14   16.00   22.00 \n\nincludes extended item information - examples:\n  labels\n1   호재\n2 스페인\n3   국가\n\nincludes extended transaction information - examples:\n  transactionID\n1            25\n2            28\n3            29\n\n연관규칙 생성하기\n\n\nrules <- apriori(trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support\n        0.6    0.1    1 none FALSE            TRUE       5    0.05\n minlen maxlen target  ext\n      1     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 50 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[679 item(s), 1000 transaction(s)] done [0.01s].\nsorting and recoding items ... [51 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4 5 6 7 done [0.00s].\nwriting ... [480 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\nsummary(rules)\n\n\nset of 480 rules\n\nrule length distribution (lhs + rhs):sizes\n  2   3   4   5   6   7 \n 62 120 144 105  42   7 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   3.000   4.000   3.929   5.000   7.000 \n\nsummary of quality measures:\n    support          confidence        coverage      \n Min.   :0.05000   Min.   :0.6471   Min.   :0.05000  \n 1st Qu.:0.05500   1st Qu.:1.0000   1st Qu.:0.05500  \n Median :0.05500   Median :1.0000   Median :0.05500  \n Mean   :0.05576   Mean   :0.9755   Mean   :0.05763  \n 3rd Qu.:0.05500   3rd Qu.:1.0000   3rd Qu.:0.05500  \n Max.   :0.07500   Max.   :1.0000   Max.   :0.08600  \n      lift            count      \n Min.   : 8.627   Min.   :50.00  \n 1st Qu.:13.333   1st Qu.:55.00  \n Median :13.333   Median :55.00  \n Mean   :14.760   Mean   :55.76  \n 3rd Qu.:18.182   3rd Qu.:55.00  \n Max.   :20.000   Max.   :75.00  \n\nmining info:\n  data ntransactions support confidence\n trans          1000    0.05        0.6\n                                                                                  call\n apriori(data = trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\narules::inspect(rules[1:5])\n\n\n    lhs             rhs          support confidence coverage lift    \n[1] {시티}       => {에듀케이션} 0.063   1.0000000  0.063    15.87302\n[2] {에듀케이션} => {시티}       0.063   1.0000000  0.063    15.87302\n[3] {윤석열}     => {여러분}     0.050   1.0000000  0.050    16.66667\n[4] {여러분}     => {윤석열}     0.050   0.8333333  0.060    16.66667\n[5] {윤석열}     => {대통령}     0.050   1.0000000  0.050    14.28571\n    count\n[1] 63   \n[2] 63   \n[3] 50   \n[4] 50   \n[5] 50   \n\n연관규칙 시각화하기\n\n\nlibrary(\"arulesViz\")\n\nplot(rules)\n\n\n\nrule2 <- sort(rules, by = \"confidence\")\ninspect(head(rule2, n = 10))\n\n\n     lhs             rhs          support confidence coverage\n[1]  {시티}       => {에듀케이션} 0.063   1          0.063   \n[2]  {에듀케이션} => {시티}       0.063   1          0.063   \n[3]  {윤석열}     => {여러분}     0.050   1          0.050   \n[4]  {윤석열}     => {대통령}     0.050   1          0.050   \n[5]  {조별}       => {리그}       0.056   1          0.056   \n[6]  {미국}       => {취재}       0.058   1          0.058   \n[7]  {취재}       => {미국}       0.058   1          0.058   \n[8]  {미국}       => {기자}       0.058   1          0.058   \n[9]  {취재}       => {기자}       0.058   1          0.058   \n[10] {빙상}       => {국제}       0.055   1          0.055   \n     lift     count\n[1]  15.87302 63   \n[2]  15.87302 63   \n[3]  16.66667 50   \n[4]  14.28571 50   \n[5]  11.62791 56   \n[6]  17.24138 58   \n[7]  17.24138 58   \n[8]  10.20408 58   \n[9]  10.20408 58   \n[10] 18.18182 55   \n\nplot(rules, method = \"grouped\")\n\n\n\nplot(rules, method = \"graph\")\n\n\n\n\n단어의 계층적 군집분석\n희박 단어의 제거\n\n\ndim(dtm_bin_tf)\n\n\n[1] 1000  679\n\ncompact_bin <- tm::removeSparseTerms(dtm_bin_tf, sparse = 0.985) %>%\n  as.matrix(compact_bin)\n\ndim(compact_bin)\n\n\n[1] 1000  253\n\n비상사도 행렬 생성\n\n\nmat <- t(compact_bin)\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 253 \n\nClustering\nk개 군집을 나눕니다.\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n군집의 해석\nk개 클러스터를 구성하는 단어들의 목록을 조회합니다.\n\n\nk %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n[[1]]\n  김민선 스케이팅   스피드     국제   디비전     빙상     여자 \n      22       37       38      142      143      144      146 \n    연맹     오벌   올림픽   의정부   캐나다   캘거리 \n     147      148      149      150      151      152 \n\n[[2]]\n      사망       개최     위원장       조직       관련     나세르 \n         9         31         55         56        128        130 \n    노동자 로이터통신       빈축       사건       사용         삶 \n       131        132        133        134        135        136 \n      이주       일부       죽음       카터       표현       문제 \n       137        138        139        140        141        214 \n      인권 \n       215 \n\n[[3]]\n  기자 기자석   미국   취재     그 경기장   발생   나이 베테랑   사고 \n     5      7      8     12     15     50     69    108    110    111 \n    세   세상   정도   통신 \n   112    113    115    168 \n\n[[4]]\n        중     아시아       리그       조별       이후       치치 \n        11         13         29         30         32         36 \n    루사일       독일       승리       메시         이     가운데 \n        41         44         48         54         58         59 \n    러시아         끝     북중미         것       도박         등 \n        60         63         71         74         75         76 \n        전       영국       의학     전문가   네덜란드         뒤 \n        79         90         91         92         97        102 \n      시티         얀 에듀케이션     연장전       탈락         번 \n       103        104        105        106        107        109 \n        월       기간       시청   마라도나     지난달       후보 \n       114        129        145        159        160        161 \n      이상       도하       선수         명       본선       이하 \n       166        179        207        211        224        237 \n      성공       일본       처음 \n       248        252        253 \n\n[[5]]\n    국가   대통령     만찬     귀국   여러분     우리     결과 \n       3       19       21       45       51       52      170 \n    국민 대한민국     성과   윤석열     환영     지원   청와대 \n     171      172      173      174      175      176      177 \n    초청   영빈관       저 \n     183      221      222 \n\n[[6]]\n        호재       스페인       조규성         인사       스포츠 \n           1            2            4            6           10 \n        전문       토트넘         황희         선전           윤 \n          14           16           17           18           20 \n        세계         최고         감사           팬     포르투갈 \n          23           24           25           26           27 \n      호날두         선발         호골         기록     네이마르 \n          28           33           34           35           39 \n    잉글랜드       금메달         적설         응원           위 \n          40           42           43           46           47 \n      프랑스         도움           시       경쟁국       글로벌 \n          49           53           57           61           62 \n        도전       마무리         채널         기사         내용 \n          64           65           66           67           68 \n        요약         전망         현지         부상         안면 \n          70           72           73           77           78 \n        착용           수         개막         살인         소화 \n          80           81           82           83           84 \n      스케줄         최근         결장         결정         수술 \n          85           86           87           88           89 \n        주장         투명           후           골       리오넬 \n          93           94           95           96           98 \n      마지막       맞대결         생애         남미   바티스투타 \n          99          100          101          116          117 \n        통산       공격수     그라운드         스타         자신 \n         118          119          120          121          122 \n        전북           개         나라         자리     준준결승 \n         123          124          125          126          127 \n        행진         득점           승         좌절         최다 \n         153          154          155          156          157 \n        펠레         논란         달성           데         등장 \n         158          162          163          164          165 \n          찬         격려       김건희         여사         예정 \n         167          169          178          180          181 \n        이날         빙속           신         여제           新 \n         182          184          185          186          187 \n        결승         격돌 프리미어리그   사회관계망       서비스 \n         188          189          190          191          192 \n      아쉬움         캡틴         후회         당시         분석 \n         193          194          195          196          197 \n          초       뉴스룸           때           분         도중 \n         198          199          200          201          202 \n          드         보도         소식         제외     연합뉴스 \n         203          204          205          206          208 \n        소속         후반       인터뷰           판       뉴시스 \n         209          210          212          213          216 \n        부문         서울         개인         차지         개국 \n         217          218          219          220          223 \n        무대         연장         전반         퇴장         가능 \n         225          226          227          228          229 \n        감동   인스타그램       지휘봉         성적         강호 \n         230          231          232          233          234 \n          대         유럽           바         상대       킬리안 \n         235          236          238          239          240 \n          페           곳         어디         제목       이야기 \n         241          242          243          244          245 \n        진행         출연           말         랭킹         이변 \n         246          247          249          250          251 \n\n기사의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\n\n\nmat <- compact_bin\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 1000 \n\n군집 개수 선정 및 시각화\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n(#fig:plot_cluster_list)군집 개수 선정 및 시각화\n\n\n\n군집의 해석\n군집별 기사 ID를 추출하고 기사의 개수를 조회합니다.\n\n\nclusters <- k %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n\n\n\n# 기사의 개수\nclusters %>% \n  purrr::map_int(length)\n\n\n[1]  55  17  30 828  30  40\n\n기사 군집 1\n기사의 제목 조회\n20건만 선별 조회\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  select(title_text) %>% \n  head(n = 20)\n\n\n                                                          title_text\n1                이런 몸으로 헤딩까지손흥민 월드컵 출전은 도박이었다\n2   월드컵 조직위원장 이주 노동자 사망에 죽음은 삶의 자연스러운 부분\n3  월드컵 16강 오르자 반전지켜보던 그들이 움직였다 신현보의 딥데이터\n4           월드컵 하차설 불거졌던 호날두 외부세력에 무너지지 않는다\n5   메시 웃었다 아르헨티나 승부차기 끝에 네덜란드 꺾고 4강 2022 카타\n6                       김민선 또 해냈다 빙속 월드컵 3차 500m 금메달\n7                  월드컵 스타 황희찬 손목에 2억짜리 시계어느 브랜드\n8               2022월드컵 일본이 또이번엔 가미카제 티셔츠 들고 응원\n9                    손흥민 월드컵 도박이었다부상 생각보다 훨씬 심각\n10               월드컵 메시 이례적으로 심판 비판그런 주심 투입 안돼\n11                    尹 우리에겐 월드컵 우승팀벤투호 16강 쾌거 격려\n12             월드컵 손흥민 1 가능성 정말 크다고 느껴SNS에 감사인사\n13  메시 웃었다 아르헨티나 승부차기 끝에 네덜란드 꺾고 4강 2022 카타\n14                      김민선 또 해냈다 빙속 월드컵 3차 500m 금메달\n15                 월드컵 스타 황희찬 손목에 2억짜리 시계어느 브랜드\n16              2022월드컵 일본이 또이번엔 가미카제 티셔츠 들고 응원\n17                   손흥민 월드컵 도박이었다부상 생각보다 훨씬 심각\n18               월드컵 메시 이례적으로 심판 비판그런 주심 투입 안돼\n19                    尹 우리에겐 월드컵 우승팀벤투호 16강 쾌거 격려\n20             월드컵 손흥민 1 가능성 정말 크다고 느껴SNS에 감사인사\n\n워드클라우드 그리기\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  unnest_noun_ngrams(term, description_text, n = 1) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(term, sort = TRUE) %>% \n  filter(nchar(term) > 1) %>%   \n  filter(row_number() >= 15) %>% \n  wordcloud2::wordcloud2(fontFamily = \"NanumSquare\")\n\n\n\n\n\n(#fig:wcloud_news_wcupsim)월드컵 기사의 제목\n\n\n\nTopic 분석\n기사의 TF 기반의 DTM으로 Topic 분석을 수행합니다. ### 희박 단어의\n제거\n\n\ncompact_tf <- tm::removeSparseTerms(dtm_tf, sparse = 0.98) %>%\n  as.matrix()\n\ndim(compact_tf)\n\n\n[1] 1000  199\n\nOTF 계산\n\n\notf <- apply(compact_tf, 2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  names()\n\n\n\n불용어 제거\nOverall Term Frequency 상위 15개 단어를 불용어로 간주하여\n제거합니다.\n\n\nstop_word <- otf[1:20]\nstop_word\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"팀\"          \n [5] \"한국\"         \"강\"           \"축구\"         \"대표\"        \n [9] \"년\"           \"시간\"         \"브라질\"       \"아르헨티나\"  \n[13] \"우승\"         \"국제축구연맹\" \"대회\"         \"강전\"        \n[17] \"경기\"         \"손흥민\"       \"이번\"         \"감독\"        \n\ncompact_tf2 <- compact_tf[, !colnames(compact_tf) %in% stop_word] \ndim(compact_tf2)\n\n\n[1] 1000  179\n\nTopic Modeling\n\n\nlibrary(\"topicmodels\")\n\nk <- 2:10\n\ncompact_tf2 <- compact_tf2[compact_tf2 %>% apply(1, sum) != 0, ]\n\nmodels <- k %>% \n  purrr::map(\n    function(x) {\n      topicmodels::LDA(compact_tf2, k = x, control = list(seed = 123))\n    }\n  )\n\n\n\nTopic 개수 구하기\nLOG-LIKELIHOOD\n\n\nlog_ikelihood <- models %>% \n  purrr::map_dbl(logLik)\nlog_ikelihood\n\n\n[1] -45706.35 -48654.83 -42981.98 -41146.83 -40583.02 -39390.48\n[7] -37974.52 -37694.40 -37073.90\n\nwhich.max(log_ikelihood)\n\n\n[1] 9\n\nALPHA\n\n\nalpha <- models %>% \n  purrr::map_dbl(slot, \"alpha\")\nalpha\n\n\n[1]  0.12945047 40.76406189  0.07686428  0.06227639  0.05763711\n[6]  0.04180651  0.03097738  0.03750115  0.03150149\n\nwhich.min(alpha)\n\n\n[1] 7\n\nTop beta 단어의 시각화\n\n\nprob <- tidytext::tidy(models[[9]], matrix = \"beta\")\nprob\n\n\n# A tibble: 1,790 × 3\n   topic term          beta\n   <int> <chr>        <dbl>\n 1     1 스페인   3.72e- 44\n 2     2 스페인   3.72e- 44\n 3     3 스페인   7.86e-321\n 4     4 스페인   3.72e- 44\n 5     5 스페인   3.72e- 44\n 6     6 스페인 Inf.  e-324\n 7     7 스페인   3.72e- 44\n 8     8 스페인   3.72e- 44\n 9     9 스페인   3.85e- 58\n10    10 스페인   5.24e-  2\n# … with 1,780 more rows\n\n\n\ntop_prob <- prob %>% \n  group_by(topic) %>% \n  top_n(10, beta) %>% \n  ungroup() %>% \n  arrange(topic, -beta)\ntop_prob\n\n\n# A tibble: 106 × 3\n   topic term       beta\n   <int> <chr>     <dbl>\n 1     1 메시     0.0818\n 2     1 만       0.0655\n 3     1 승부차기 0.0607\n 4     1 네덜란드 0.0486\n 5     1 끝       0.0448\n 6     1 통산     0.0369\n 7     1 기록     0.0339\n 8     1 최다     0.0317\n 9     1 호골     0.0295\n10     1 프랑스   0.0295\n# … with 96 more rows\n\n\n\ntop_prob %>% \n  mutate(term = reorder(term, beta)) %>% \n  ggplot(aes(x = term,  y = beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~topic, scales = \"free\") +\n  coord_flip()\n\n\n\n\n(#fig:plot_top_prob)Top beta 단어의 시각화\n\n\n\n문서에서의 토픽의 비중\n\n\nnews_gamma <- tidytext::tidy(models[[9]], matrix = \"gamma\") %>% \n  mutate(gamma = gamma * 100)\n\nnews_gamma\n\n\n# A tibble: 10,000 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 40           1 0.431\n 2 139          1 0.431\n 3 238          1 0.431\n 4 337          1 0.431\n 5 436          1 0.431\n 6 535          1 0.431\n 7 634          1 0.431\n 8 733          1 0.431\n 9 832          1 0.431\n10 931          1 0.431\n# … with 9,990 more rows\n\n토픽이 포함된 문서 조회\n토픽 1의 주요 단어는 다음과 같습니다.\n\n\nterms(models[[9]], 10)[, 1]\n\n\n [1] \"메시\"     \"만\"       \"승부차기\" \"네덜란드\" \"끝\"       \"통산\"    \n [7] \"기록\"     \"최다\"     \"호골\"     \"프랑스\"  \n\n토픽 1이 95% 이상 포함된 문서를 조회합니다.\n\n\nnews_gamma %>%\n  filter(topic == 1) %>%\n  filter(gamma >= 95) %>%\n  arrange(desc(gamma))\n\n\n# A tibble: 68 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 45           1  98.7\n 2 144          1  98.7\n 3 243          1  98.7\n 4 342          1  98.7\n 5 441          1  98.7\n 6 540          1  98.7\n 7 639          1  98.7\n 8 738          1  98.7\n 9 837          1  98.7\n10 936          1  98.7\n# … with 58 more rows\n\n61번째 기사의 이해\n\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(title_text) %>% \n  pull()\n\n\n[1] \"2022월드컵 대표팀 이탈설 호날두 끝까지 싸운다\"\n\n\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(description_text) %>% \n  pull()\n\n\n[1] \"호날두가 월드컵 선발 명단에서 제외되자 페르난두 산투스 포르투갈 대표팀 감독과 이야기를 나눴고, 팀을 떠나겠다고 협박했다는 보도입니다. 앞서 호날두는 카타르 월드컵 16강전에서 선발이 아닌 벤치를 지키다 교체... \"\n\n문서의 토픽 분해\n모든 문서는 토픽들의 복합체입니다. 기사 1을 분해하여 토픽의 비율을\n조해해 봅니다.\n\n\nnews_gamma %>%\n  filter(document %in% \"1\") %>% \n  arrange(desc(gamma)) \n\n\n# A tibble: 10 × 3\n   document topic  gamma\n   <chr>    <int>  <dbl>\n 1 1            6 57.1  \n 2 1            7 19.5  \n 3 1            1 13.5  \n 4 1            4  8.38 \n 5 1           10  0.256\n 6 1            3  0.256\n 7 1            2  0.256\n 8 1            8  0.256\n 9 1            9  0.256\n10 1            5  0.256\n\n토픽의 단어 분해\n\n\ntop_prob %>% \n  filter(topic == 6) %>% \n  arrange(desc(beta)) \n\n\n# A tibble: 10 × 3\n   topic term     beta\n   <int> <chr>   <dbl>\n 1     6 아시아 0.160 \n 2     6 중     0.103 \n 3     6 스포츠 0.0674\n 4     6 전문   0.0609\n 5     6 채널   0.0559\n 6     6 경쟁국 0.0510\n 7     6 뒤     0.0493\n 8     6 출전   0.0493\n 9     6 소속   0.0493\n10     6 연맹   0.0493\n\n이진분류 모형\n패키지 로드하기\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(bitTA)\n\n\n\n파생변수 만들기\n연합뉴스 여부\n연합뉴스 기사 : 1\n기타뉴스 기사 : 0\n\n\n\nnews_worldcup_yna <- news_worldcup_sim %>% \n  mutate(yna_flag = ifelse(stringr::str_detect(originallink, \"www.yna.co.kr\"), 1, 0))\n\nnews_worldcup_yna %>% \n  count(yna_flag) %>% \n  mutate(ratio = n /sum(n) * 100)\n\n\n  yna_flag   n ratio\n1        0 777  77.7\n2        1 223  22.3\n\n불균형 데이터의 언더 샘플링\n\n\nn_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1) %>% \n  tally() %>% \n  pull()\n\nn_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  tally() %>% \n  pull()\n\nset.seed(123)\nidx_sample <- sample(seq(n_not_yna), size = n_yna)\n\nsubset_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  filter(row_number() %in% idx_sample)\n\nsubset_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1)\n\nnews_sample_yna <- bind_rows(subset_not_yna, subset_yna)\n\nnews_sample_yna %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 223\n2        1 223\n\n데이터셋 분리\n\n\nset.seed(123)\nnews_split <- initial_split(news_sample_yna, strata = yna_flag)\n\ntrain <- rsample::training(news_split)\ntest <- rsample::testing(news_split)\n\ndim(train)\n\n\n[1] 334   9\n\ndim(test)\n\n\n[1] 112   9\n\ntrain %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 167\n2        1 167\n\ntest %>% \n  count(yna_flag)\n\n\n  yna_flag  n\n1        0 56\n2        1 56\n\ntokenize 반복기 정의\n\n\n# 일반명사 단위로 토큰을 생성\ntoken_fun <- bitTA::morpho_mecab\n\nit_train <- itoken_parallel(train$description_text, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken_parallel(test$description_text, \n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nFrequency 기반의 DTM 생성\nVOCABULARY 생성\n\n\nlibrary(doParallel)\n\nnc <- parallel::detectCores()\nregisterDoParallel(cores = nc)\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 334 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n          term term_count doc_count\n 1: 아르헨티나         78        53\n 2:       시간         83        83\n 3:       강전         86        81\n 4:     브라질         92        69\n 5:       대표        105        95\n 6:       축구        129       127\n 7:         팀        132       113\n 8:         강        136       118\n 9:     카타르        379       272\n10:     월드컵        634       328\n\nDOCUMENT TERM MATRIX\n생성하기\n\n\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train_tf <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train_tf)\n\n\n[1] 334 559\n\ndtm_test_tf <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test_tf)\n\n\n[1] 112 559\n\nN-Grams 기반의 DTM 생성\nVOCABULARY 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 1679    3\n\nPRUNE VOCABULARY\n\n\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 285   3\n\nDOCUMENTS TERM MATRIX 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1] 334 285\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1] 112 285\n\nTF-IDF 기반의 DTM 생성\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train_tf, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test_tf, tfidf) \n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train_tf)\n\n\n[1] 334 559\n\ndim(dtm_train_bigram)\n\n\n[1] 334 285\n\ndim(dtm_train_tfidf)\n\n\n[1] 334 559\n\nFrequency 기반 모델링\n\n\nNFOLDS <- 10\n\nclassifier_tf <- cv.glmnet(x = dtm_train_tf, y = train$yna_flag, \n                           family = \"binomial\",\n                           alpha = 1,\n                           parallel = TRUE, \n                           keep = TRUE)\n\n\n\n모델의 이해\n\n\nlibrary(broom)\n\ncoefs_tf <- classifier_tf$glmnet.fit %>%\n  tidy() %>%\n  filter(lambda == classifier_tf$lambda.1se)\ncoefs_tf \n\n\n# A tibble: 110 × 5\n   term         step estimate  lambda dev.ratio\n   <chr>       <dbl>    <dbl>   <dbl>     <dbl>\n 1 (Intercept)    72  -3.16   0.00523     0.947\n 2 결승전         72  -2.71   0.00523     0.947\n 3 공격           72  -1.23   0.00523     0.947\n 4 관중           72  -0.0206 0.00523     0.947\n 5 근처           72  -3.86   0.00523     0.947\n 6 물의           72  -0.0143 0.00523     0.947\n 7 순위           72  -2.70   0.00523     0.947\n 8 포인트         72  -0.0141 0.00523     0.947\n 9 新             72  -2.66   0.00523     0.947\n10 기후           72  -0.607  0.00523     0.947\n# … with 100 more rows\n\n\n\ncoefs_tf %>%\n  group_by(estimate > 0) %>%\n  top_n(10, abs(estimate)) %>%\n  ungroup() %>%\n  ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate > 0)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    title = \"예측에 영향을 주는 모델의 계수들 with TF\",\n    subtitle = \"네이버 월드컵 관련 뉴스\"\n  )\n\n\n\n\n(#fig:plot_coefs_tf)예측에 영향을 주는 모델의 계수들 with TF\n\n\n\n모델의 평가\n정오분류 행렬\n\n\nnews_tf <- predict(classifier_tf, dtm_test_tf, type = 'class')\ncm_tf <- confusionMatrix(factor(test$yna_flag), factor(news_tf), positive = \"1\")\ncm_tf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 56  0\n         1  1 55\n                                          \n               Accuracy : 0.9911          \n                 95% CI : (0.9513, 0.9998)\n    No Information Rate : 0.5089          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9821          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.9825          \n         Pos Pred Value : 0.9821          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.4911          \n         Detection Rate : 0.4911          \n   Detection Prevalence : 0.5000          \n      Balanced Accuracy : 0.9912          \n                                          \n       'Positive' Class : 1               \n                                          \n\nROC 커브\n\n\nlibrary(\"pROC\")\n\npredictions <- predict(classifier_tf, dtm_test_tf, type = 'response')\nroc_tf <- pROC::roc(test$yna_flag, predictions)\n\npROC::auc(roc_tf)\n\n\nArea under the curve: 0.9828\n\n\n\nplot(roc_tf)\n\n\n\n\n(#fig:plot_roctf)ROC 커브\n\n\n\n\n\nidx <- predictions %>% \n  which.max()\n\npredictions[idx]\n\n\n[1] 0.9895764\n\ntest[idx, \"description_text\"]\n\n\n[1] \"지난달 2022 카타르 월드컵 조별리그 첫 경기를 앞두고 소속팀인 맨체스터 유나이티드(잉글랜드)와 갈등 끝에... 이달 3일 한국과 카타르 월드컵 조별리그 H조 3차전(한국 2-1 승)에서 아쉬운 경기력을 선보이며 후반 20분... \"\n\n\n\nidx <- predictions %>% \n  which.min()\n\npredictions[idx]\n\n\n[1] 0.001710634\n\ntest[idx, \"description_text\"]\n\n\n[1] \"카타르 월드컵에서 12년 만에 16강 진출에 성공한 한국 축구대표팀의 4년 뒤에도 괜찮은 성적을 거둘 것이라는 외신 보도가 나왔다. ESPN은 9일(한국시간) 아시아 국가 중 2026년 FIFA 월드컵에서 가장 높은 곳에 오를... \"\n\n\n\n\n",
      "last_modified": "2022-12-10T21:54:57+09:00"
    },
    {
      "path": "classifier_lasso.html",
      "title": "대통령 연설문 예측",
      "description": "2022학년도 2학기 텍스트 정보처리와 NLP 수업내용입니다.\n텍스트 분류모형을 개발하고, DTM의 종류별 성능 차이를 비교합니다.\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n준비하기\n패키지 로드하기\n\n분석 방법 정의\n데이터셋 샘플링\n데이터셋 분리\ntokenize 반복기 정의\n\nTF기반의 DTM 생성\nVocabulary 생성\nDocument Term Matrix\n생성하기\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\nPrune Vocabulary\nDocuments Term Matrix\n생성\n\nTF-IDF 기반의 DTM 생성\nDTM의 TF-IDF 변환\n\nDTM의 크기 비교\nLASSO 회귀모형 모델 적합\nFrequency 기반 모델링\nN-Grams 기반 모델링\nTF-IDF 기반의 모델\n\n모델 성능의 비교\n\n준비하기\n패키지 로드하기\n\n\n# ■ text2vec\n# -텍스트 분류모델 개발을 위해서 텍스트를 벡터화하는  패키지를 설치하고 불러오기\nif (!require(\"text2vec\")) {\n  install.packages(\"text2vec\")\n  library(\"text2vec\")\n}\n\n# ■ glmnet\n# - 분류모델 개발을 위한 glmnet 패키지를 설치하고 불러오기\n\nif (!require(\"glmnet\")) {\n  install.packages(\"glmnet\")\n  library(\"glmnet\")\n}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(caret)\nlibrary(bitTA)\n\n\n\n분석 방법 정의\n데이터셋 샘플링\n앞서 배운 tidymodels 패키지를 이용해서 데이터셋을 샘플링합니다.\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 87.5% : 12.5%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- rsample::initial_split(president_speech, prop = 7/8, strata = president)\n\npresident_smpl <- rsample::testing(president_split)\n\n\n\n데이터셋 분리\n비로소 모델 개발을 위한 데이터셋을 분리합니다.\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 70% : 30%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- initial_split(president_smpl, prop = 0.7, strata = president)\n\ntrain <- rsample::training(president_split)\ntest <- rsample::testing(president_split)\n\n\n\ntokenize 반복기 정의\ntokenizer로 text2vec::morpho_mecab()를 정의했기 때문에 띄어쓰기\n단위의 term이 생성될 것입니다.\n\n\n# 띄어쓰기 단위로 토큰을 생성\ntoken_fun <- text2vec::word_tokenizer\n\nit_train <- itoken(train$doc, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken(test$doc,\n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nTF기반의 DTM 생성\nVocabulary 생성\nvocabulary는 documents로부터 생성된 terms의 집합 여기서는 tokenizer를\n일반명사로 정의했기 때문에 일반명사 집합으로 vocabulary가 생성\n몇몇 데이터를 조회해보면 term별로 frequency와 document frequency가\n도출되었음을 알 수 있음\n또한 word2vec 패키지의 함수들은 parallel processing을 지원하므로,\nparallel 처리를 위한 multicores 사용을 지원하는 doMC, doParallel 등의\n패키지 사용이 필요.\n\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n        term term_count doc_count\n 1:   그리고        505       147\n 2:       한        505       134\n 3:       그        566       135\n 4:     있는        601       155\n 5:   여러분        607       175\n 6:       이        625       153\n 7:     우리        886       175\n 8:       수        935       167\n 9: 것입니다       1004       180\n10: 있습니다       1383       192\n\nDocument Term Matrix\n생성하기\ndocuments taxonomy 분류 모델을 수행하는 데이터셋은 DTM(Document Term\nMatrix) 구조여야 함. 그래서 vocabulary를 DTM으로 변환하는 작업을 수행.\ntext2vec::create_dtm() 함수를 사용.\n\n\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train)\n\n\n[1]   210 31602\n\n\n\ndtm_test <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test)\n\n\n[1]    92 31602\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 126313      3\n\n\n\nhead(vocab_bigram, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 2 \nVocabulary: \n            term term_count doc_count\n 1:          0.1          1         1\n 2:   0.1_미만의          1         1\n 3:     1,000_개          1         1\n 4: 1,000_만이나          1         1\n 5:        1,050          1         1\n 6:     1,050_억          1         1\n 7:        1,100          1         1\n 8: 1,100_여개의          1         1\n 9:        1,200          1         1\n10:   1,200_만이          1         1\n\nPrune Vocabulary\n\nDocuments의 개수가 증가하거나 Documents의 길이가 증가하면,\nVocabulary의 규모도 증가 함. 이것은 모델을 생성하는데 많은 컴퓨팅\n리소스를 소모해서 속도가 느려짐. 그래서 모델에 영향을 덜 줄 수 있는\nterms를 제거하는 작업이 필요함.\n\n\n\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 2046    3\n\nDocuments Term Matrix 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\n\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1]   92 2046\n\nTF-IDF 기반의 DTM 생성\nTF-IDF는 단일문서, 혹은 소수의 문서에서 의미가 있는 terms의 가중치를\n높이고 대부분의 문서에서 발현하는 terms의 가중치를 줄이는 용도로\n만들어진 측도입니다. 그러므로 DTM에 TF-IDF 변환을 수행하면 모델의 성능이\n개선됩니다\nText Anaytics에서는 documents의 길이의 차이가 있으면, 상대적으로\n짧거나 긴 documents에서 발현하는 terms들로 인해서 frequency scale에\n왜곡이 있을 수 있습니다. 이 경우에는 표준화를 수행해야 합니다. 그런데\nTF-IDF 변환은 자동으로 표준화가 되기 때문에 표준화의 잇점이 있습니다.\n만약 표준화를 수행하려면, normalize() 함수를 사용하면 됩니다.\nDTM의 TF-IDF 변환\nTfIdf class와 fit_transform() 함수를 이용해서 DTM에 TF-IDF 변환을\n수행합니다.\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test, tfidf) \n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train)\n\n\n[1]   210 31602\n\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\ndim(dtm_train_tfidf)\n\n\n[1]   210 31602\n\nLASSO 회귀모형 모델 적합\nFrequency 기반 모델링\n모델 생성\n\n\nNFOLDS <- 10\n\nclassifier <- cv.glmnet(x = dtm_train, y = train$president, \n                        family = 'multinomial', \n                        alpha = 1,\n                        type.measure = \"deviance\",\n                        nfolds = NFOLDS,\n                        thresh = 0.001,\n                        maxit = 1000,\n                        parallel = TRUE)\n\n\n\n모델의 평가\ntest 데이터로 평가한 결과 Accuracy가 0.869로 비교적 높게\n나타났습니다\n\n\npred_voca <- predict(classifier, dtm_test, type = 'response')[, , 1]\npresident_voca <- apply(pred_voca, 1, \n                        function(x) colnames(pred_voca)[which(max(x) == x)])\n\ncmat_voca <- confusionMatrix(factor(president_voca), factor(test$president))\ncmat_voca\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     21      0      2\n    노무현      7     25      4\n    이명박      3      5     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7717          \n                 95% CI : (0.6725, 0.8528)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.6579          \n                                          \n Mcnemar's Test P-Value : 0.06262         \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.6774        0.8333        0.8065\nSpecificity                 0.9672        0.8226        0.8689\nPos Pred Value              0.9130        0.6944        0.7576\nNeg Pred Value              0.8551        0.9107        0.8983\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2283        0.2717        0.2717\nDetection Prevalence        0.2500        0.3913        0.3587\nBalanced Accuracy           0.8223        0.8280        0.8377\n\nN-Grams 기반 모델링\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_bigram, y = train$president, \n                        family = 'multinomial', \n                        type.measure = \"deviance\",\n                        alpha = 1,                        \n                        nfolds = NFOLDS,\n                        parallel = TRUE)\n\n\n\n모델의 평가\nvocabulary를 가지지기했음에도 불구하고, 전체 vocabulary를 사용한\n모델보다 성능이 좋아졌습니다.\n\n\npred_bigram <- predict(classifier, dtm_test_bigram, type = 'response')[, , 1]\n\npresident_bigram <- apply(pred_bigram, 1, \n                          function(x) colnames(pred_bigram)[which(max(x) == x)])\n\ncmat_bigram <- confusionMatrix(factor(president_bigram), factor(test$president))\ncmat_bigram\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     22      1      1\n    노무현      3     25      5\n    이명박      6      4     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7826          \n                 95% CI : (0.6844, 0.8619)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.674           \n                                          \n Mcnemar's Test P-Value : 0.1966          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.7097        0.8333        0.8065\nSpecificity                 0.9672        0.8710        0.8361\nPos Pred Value              0.9167        0.7576        0.7143\nNeg Pred Value              0.8676        0.9153        0.8947\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2391        0.2717        0.2717\nDetection Prevalence        0.2609        0.3587        0.3804\nBalanced Accuracy           0.8384        0.8522        0.8213\n\nTF-IDF 기반의 모델\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_tfidf, y = train$president, \n                        family = 'multinomial', \n                        nfolds = NFOLDS,\n                        thresh = 1e-3,\n                        maxit = 1e3,\n                        parallel = TRUE)\n\n\n\n모델의 평가\n\n\npred_tfidf <- predict(classifier, dtm_test_tfidf, type = 'response')[, , 1]\n\npresident_tfidf <- apply(pred_tfidf, 1, \n                         function(x) colnames(pred_tfidf)\n                         [which(max(x) == x)])\n\ncmat_tfidf <- confusionMatrix(factor(president_tfidf), factor(test$president))\ncmat_tfidf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     28      7      4\n    노무현      2     20      2\n    이명박      1      3     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7935          \n                 95% CI : (0.6964, 0.8708)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.6899          \n                                          \n Mcnemar's Test P-Value : 0.1888          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.9032        0.6667        0.8065\nSpecificity                 0.8197        0.9355        0.9344\nPos Pred Value              0.7179        0.8333        0.8621\nNeg Pred Value              0.9434        0.8529        0.9048\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.3043        0.2174        0.2717\nDetection Prevalence        0.4239        0.2609        0.3152\nBalanced Accuracy           0.8614        0.8011        0.8704\n\n모델 성능의 비교\n모델의 성능은 TF-IDF > Bigram(Pruned) > Frequency의 순서로\n나타납니다.\n그러므로 성능을 높이기 위해서는 TF-IDF 방법을 사용하는 것이 좋으며,\n대용량의 데이터 분석에서는 적은 성능 감소와 수행 속도의 개선을 가져오는\nFeature Hashing 기법을 사용하면 될 것입니다. 이 경우에는 Purne\nVocabulary 전처리도 필요할 것입니다.\n다만, 몇몇 결과는 그 성능 차이가 작기 때문에 모델의 파라미터에 따라\n순서가 바뀔수도 있습니다\n\n\naccuracy <- rbind(cmat_voca$overall, \n                  cmat_bigram$overall, \n                  cmat_tfidf$overall) %>%\n  round(3)\n\ndata.frame(Method = c(\"Frequency\", \"Bigram\", \"TF-IDF\"),\n           accuracy) %>%\n  arrange(desc(Accuracy)) %>%\n  knitr::kable()\n\n\nMethod\nAccuracy\nKappa\nAccuracyLower\nAccuracyUpper\nAccuracyNull\nAccuracyPValue\nMcnemarPValue\nTF-IDF\n0.793\n0.690\n0.696\n0.871\n0.337\n0\n0.189\nBigram\n0.783\n0.674\n0.684\n0.862\n0.337\n0\n0.197\nFrequency\n0.772\n0.658\n0.672\n0.853\n0.337\n0\n0.063\n\n\n\n\n",
      "last_modified": "2022-12-10T22:09:48+09:00"
    },
    {
      "path": "create_website.html",
      "title": "웹 사이트 개발하기",
      "description": "웹 사이트 개발하는 방법을 간단하게 소개합니다.\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n설정사항\n수정해야할 사항\n웹 사이트 구성 파일\n개별 페이지 구성 정보\n\nData: USArrests\n표(tables) 출력\n플롯(plots) 출력\n\n\n\n\n\n\n들어가기\n이 웹 사이트는 예제를 위해서 만든 간단한 사이트입니다.\n\n여러분은 이 Skelton 사이트에 살을 붙여서 자신의 웹 사이트를 만들 수 있습니다. 그리고 이 작업은 사이트의 구조를 이해하는 것으로부터 시작됩니다.\n\n\n\n설정사항\n수정해야할 사항\n본 템플리트는 웹 사이트 중의 한 페이지로 bitReport\nwebsite라는 이름의 예제입니다. 환경 설정파일인\n_site.yml에 “샘플 웹 사이트”이라는 제목으로 연결되어\n있습니다. 만약에 예제 템플리트를 완성하려면 이 페이지의 이름을\n_site.yml에서의 create_website과 동일하게\n설정해야 합니다.\n웹 사이트 구성 파일\n웹 사이트를 구성하는 설정은 구성파일인 **_site.yml**에\n정의합니다.\n_site.yml 파일에서의 사용자가 설정해야할 항목은 다음과 같습니다.\nname: 웹 사이트의 이름\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ntitle: 웹 사이트의 타이틀\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ndescription: 웹 사이트의 설명\noutput_dir: 생성될 웹 사이트의 정적 HTML이 저장될 디렉토리\n“docs”로 기본설정됩니다. 이 디렉토리는 github page로 deploy할 때\n유용합니다.\n\nnavbar: 웹 사이트의 메뉴를 정의하는 섹션입니다.\n수정하지 않습니다.\n\nright: 웹 사이트의 메뉴를 정의합니다.\ntext는 메뉴 이름입니다.\nhref는 메뉴와 연결할 웹 페이지입니다. 확장자는\nhtml입니다.\nR markdown 파일과 동일하게 이름을 부여합니다.\n\nmenu는 서브메뉴를 정의합니다.\n빈 분리자를 만들기 위해서는 “- text:”—“를 사용합니다.\n\noutput: 웹 사이트 출력에 대한 설정입니다. 사용자가 수정하지\n않습니다.\n개별 페이지 구성 정보\n개별 페이지를 구성하기 위해서는 knitr YAML을 수정해야 합니다.\ntitle: 웹 페이지 제목입니다.\ndescription: 웹 페이지를 간단하게 소개하는 소개문입니다.\nauthor: 웹 페이지 컨텐츠 저작자 정보를 기술합니다.\nname: 저작자 이름\nurl: 저작자 개인 홈페이지 URL\naffiliation: 저작자 소속 회사/부서\naffiliation_url: 저작자 소속 회사/부서 홈페이지 URL\n\ndate: 컨텐츠를 생성한 날짜\noutput: 웹 사이트 출력에 대한 설정입니다.\ntoc: 목차를 출력할 지의 여부를 정의합니다. true이면 출력합니다.\ntoc_depth: 출력할 목차의 depth를 정의합니다. 3이면 3 depth까지\n표시합니다.\n\n\n이 예제 웹 사이트는 하나의 완성된 페이지를 만드는 것이 아닌, 가상의\nsite를 담은 Skelton만 제공합니다. 그러므로 개별 페이지의 내용에 신경쓸\n필요가 없습니다.\n\nData: USArrests\nUSArrests는 미국 주별 강력 범죄율을 기록한\n데이터입니다.\n이 데이터셋은 4개의 변수와 50개의 관측치로 구성된 데이터\n프레임(data.frame) 객체입니다.:\nMurder\nnumeric. 살인범 검거 건수(100,000건당)\n\nAssault\nnumeric. 폭행범 검거 건수(100,000건당)\n\nUrbanPop\nnumeric. 도시 인구 비율(백분율)\n\nRape\nnumeric. 강간범 검거 건수(100,000건당)\n\n\n\n# code here\n\n\n\n표(tables) 출력\n미국 주별 강력 범죄율을 기록한 데이터인 USArrests를 표로\n출력합니다.\n\n\nUSArrests %>% \n  tibble::rownames_to_column(\"주 (State)\") %>% \n  arrange(desc(Murder + Assault + Rape)) %>% \n  filter(row_number() <= 10) %>% \n  select(1:3, 5, 4) %>% \n  rename(`살인범` = Murder) %>% \n  rename(`폭행범` = Assault) %>% \n  rename(`강간범` = Rape) %>% \n  rename(`도시인구수(백분율)` = UrbanPop) %>%   \n  kableExtra::kbl(\n    caption = \"미국 범죄 상위 10개 주 현황\",\n    format.args = list(big.mark = \",\", digits = 1, scientific = 6)\n  ) %>% \n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>% \n  kableExtra::add_header_above(c(\" \" = 1, \"범죄자수 (인구 만명 당)\" = 3, \" \" = 1)) %>% \n  kableExtra::kable_classic(full_width = TRUE) \n\n\n\nTable 1: 미국 범죄 상위 10개 주 현황\n\n\n\n\n\n범죄자수 (인구 만명 당)\n\n\n\n\n\n주 (State)\n\n\n살인범\n\n\n폭행범\n\n\n강간범\n\n\n도시인구수(백분율)\n\n\nFlorida\n\n\n15\n\n\n335\n\n\n32\n\n\n80\n\n\nNorth Carolina\n\n\n13\n\n\n337\n\n\n16\n\n\n45\n\n\nMaryland\n\n\n11\n\n\n300\n\n\n28\n\n\n67\n\n\nArizona\n\n\n8\n\n\n294\n\n\n31\n\n\n80\n\n\nNew Mexico\n\n\n11\n\n\n285\n\n\n32\n\n\n70\n\n\nCalifornia\n\n\n9\n\n\n276\n\n\n41\n\n\n91\n\n\nAlaska\n\n\n10\n\n\n263\n\n\n44\n\n\n48\n\n\nSouth Carolina\n\n\n14\n\n\n279\n\n\n22\n\n\n48\n\n\nNevada\n\n\n12\n\n\n252\n\n\n46\n\n\n81\n\n\nMichigan\n\n\n12\n\n\n255\n\n\n35\n\n\n74\n\n\n플롯(plots) 출력\n이 예제는 가상의 설명을 포함하고 있는, 그저 템플리트를 위한\n예제입니다.\n온도에 따른 수은의 증기압을 기록한 데이터인 pressure 데이터 프레임을\n산점도록 시각화합니다.\n\n\nplot(pressure, pch = 16, main = \"Relation between temperature and pressure\")\nlines(loess(pressure ~ temperature, pressure), col = \"steelblue\")\n\n\n\n\nFigure 1: 플롯 예제\n\n\n\n\n\n\n",
      "last_modified": "2022-10-29T00:12:19+09:00"
    },
    {
      "path": "index.html",
      "title": "텍스트 데이터 분석",
      "description": "텍스트 분석은 자연어로 구성된 대량의 비정형 텍스트 또는 사전 정의된 형식이 없는 텍스트를 처리하여 패턴이나 관계를 알아내어 의미있는 정보를 찾는 것을 말한다. 방대한 양의 비정형 텍스트 문서로부터 주요 토픽",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n내가 기대하는 텍스트\n분석\n\n내가 기대하는 텍스트 분석\n연구자들은 텍스트 분석을 통해 짧은 시간에 많은 양의 기존\n문헌을 탐색하여 연구와 관련된 내용을 추출할 수\n있을 것이다.\n대통령 연설문 텍스트 분석을 통해 역대 대통령의 중심가치를\n파악할 수 있을 것이다.연설문에 나타난 단어의 빈도를\n분석하고 언어 네트워크 분석을 통해 역대\n대통령들의 중심가치 변화와 흐름을 분석할 수 있을 것이다.\n\n\n\n\n\n\n\n",
      "last_modified": "2022-10-29T00:12:20+09:00"
    }
  ],
  "collections": []
}
