{
  "articles": [
    {
      "path": "classifier_bert.html",
      "title": "캡스톤 프로젝트",
      "description": "2022학년도 2학기 텍스트 정보처리와 NLP 수업내용입니다.\n한 학기 과정의 핵심 내용을 실습을 통해서 다시한번 다지기\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n텍스트 데이터 수집\n데이터 수집\n간단한 데이터 요약\n\n정규표현식의 이해\n패턴 검색\n\nDocument Term Matrix의\n이해\nDTM 생성하기\n\nCorrelation Analysis\n연관분석\nBinary Term Frequency\n기반 DTM 생성\n불용어 제거\nTransactions 생성하기\n연관규칙 생성하기\n연관규칙 시각화하기\n\n단어의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\nClustering\n군집의 해석\n\n기사의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\nClustering\n군집 개수 선정 및\n시각화\n군집의 해석\n기사 군집 1\n\nTopic 분석\nOTF 계산\n불용어 제거\nTopic Modeling\nTopic 개수 구하기\nTop beta 단어의 시각화\n문서에서의 토픽의 비중\n토픽이 포함된 문서 조회\n문서의 토픽 분해\n토픽의 단어 분해\n\n이진분류 모형\n패키지 로드하기\n파생변수 만들기\n불균형 데이터의 언더\n샘플링\n데이터셋 분리\ntokenize 반복기 정의\nFrequency 기반의 DTM\n생성\nN-Grams 기반의 DTM 생성\nTF-IDF 기반의 DTM 생성\nDTM의 크기 비교\nFrequency 기반 모델링\n모델의 이해\n모델의 평가\n\n\n텍스트 데이터 수집\n데이터 수집\n인증키와 키워드 입력\nclient_id, client_secret는 사용자의 API 인증키를 삽입\n\n\nlibrary(koscrap)\n\n# Naver 뉴스 API 인증키\nclient_id <- \"D_7oXG2_osfloS1rLW2X\"\nclient_secret <- \"7Q8pd9QSnM\"\n\n# 검색 키워드\nkeyword <- \"월드컵\"\n\n\n\n날짜 정렬 기준 수집\n날짜 기준 정렬로 1,000건의 뉴스를 수집\n\n\nn <- 1000\n# 날짜 정렬 수집\nnews_worldcup_date <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret,\n  do_done = TRUE, max_record = n\n)\n\n\n* 검색된 총 기사 건수는 2750720건입니다.\n- (100/1000)건 호출을 진행합니다.\n- (200/1000)건 호출을 진행합니다.\n- (300/1000)건 호출을 진행합니다.\n- (400/1000)건 호출을 진행합니다.\n- (500/1000)건 호출을 진행합니다.\n- (600/1000)건 호출을 진행합니다.\n- (700/1000)건 호출을 진행합니다.\n- (800/1000)건 호출을 진행합니다.\n- (900/1000)건 호출을 진행합니다.\n- (1000/1000)건 호출을 진행합니다.\n\n유사도 정렬 기준 수집\n유사도 기준 정렬로 1,000건의 뉴스를 수집\n\n\n# 유사도 정렬 수집\nnews_worldcup_sim <- search_naver(\n  keyword, client_id = client_id, client_secret = client_secret, sort = \"sim\",\n  do_done = TRUE, max_record = n\n)\n\n\n* 검색된 총 기사 건수는 2750720건입니다.\n- (100/1000)건 호출을 진행합니다.\n- (200/1000)건 호출을 진행합니다.\n- (300/1000)건 호출을 진행합니다.\n- (400/1000)건 호출을 진행합니다.\n- (500/1000)건 호출을 진행합니다.\n- (600/1000)건 호출을 진행합니다.\n- (700/1000)건 호출을 진행합니다.\n- (800/1000)건 호출을 진행합니다.\n- (900/1000)건 호출을 진행합니다.\n- (1000/1000)건 호출을 진행합니다.\n\n데이터를 수집하는 시점에 따라 결과가 다르겠지만, 각각 1000건의\n데이터가 수집되었습니다. 변수의 개수는 7개입니다.\n\n\ndim(news_worldcup_date)\n\n\n[1] 1000    7\n\ndim(news_worldcup_sim)\n\n\n[1] 1000    7\n\n앞, 뒤의 몇 건을 조회\n\n\nhead(news_worldcup_date)\n\n\n                                                                                     title\n1 &apos;구찌와 함께&apos;… 카메라 앞 &apos;황소&apos; 황희찬, &apos;독보적 매력 발산&apos;\n2                                         권영찬 교수, 19일 공기업 초청 송년회서 특강 진행\n3                                      조용한 왕국 모로코 축구 반란, MENA권 희망의 슛 쏘다\n4     [<b>월드컵<\/b>] 메시 원맨팀 아니다…아르헨티나 &apos;비밀병기&apos; 페르난데스에 기대\n5                벤투, FIFA 인터뷰서 태극전사에 감탄사 &quot;프로 의식에 특히 고맙다&quot;\n6                                         WC 결승 주심, 2년 전 클롭 분노케 한 바로 그 주심\n                                                                                                                                     originallink\n1                                                                                   https://www.besteleven.com/news/articleView.html?idxno=214751\n2                                                                                             https://www.jejutwn.com/news/article.html?no=156243\n3                                                                                                     https://www.joongang.co.kr/article/25126412\n4                                                                                  https://www.spotvnews.co.kr/news/articleView.html?idxno=572547\n5                                                                                                      https://www.xportsnews.com/article/1666412\n6 http://www.mydaily.co.kr/new_yk/html/read.php?newsid=202212170005128242&ext=na&utm_campaign=naver_news&utm_source=naver&utm_medium=related_news\n                                                           link\n1 https://sports.news.naver.com/news.nhn?oid=343&aid=0000118389\n2           https://www.jejutwn.com/news/article.html?no=156243\n3 https://n.news.naver.com/mnews/article/353/0000043818?sid=102\n4 https://sports.news.naver.com/news.nhn?oid=477&aid=0000400586\n5 https://sports.news.naver.com/news.nhn?oid=311&aid=0001536351\n6 https://sports.news.naver.com/news.nhn?oid=117&aid=0003678722\n                                                                                                                                                                                                                                 description\n1                     잉글랜드 프리미어리그(EPL) 클럽 울버햄튼 원더러스 소속의 황희찬은 얼마 전 대한민국 국가대표팀의 유니폼을 입고 2022 FIFA(국제축구연맹) 카타르 <b>월드컵<\/b>에 출전했다. 조별 라운드 3번째 경기였던 포르투갈전에서는... \n2                        지난 16일 소속사에 따르면 권 교수는 이번 강연에서 최근 카타르 <b>월드컵<\/b>에서 12년 만에 원정 16강이라는 염원을 현실로 이뤄낸 우리 대표팀의 불꽃 투혼과 더불어 EPL에서 뛰고 있는 ‘캡틴’ 손흥민과 ‘황소’ 황희찬... \n3                   ━ 지구촌 정치 지형 바꾼 <b>월드컵<\/b> FIFA <b>월드컵<\/b>은 글로벌 사회의 진열대이자 문화 교류의 응접실이다. 시합 중계를 통해 전 세계 축구 선수들의 기량·전술과 경기 결과는 물론 경기장을 찾은 개최국·출전국 관람객과... \n4 아르헨티나가 2022 카타르 <b>월드컵<\/b> 결승전을 앞두고 있다. 19일 새벽 12시(이하 한국시간) 프랑스와 우승컵을 놓고 다툰다. 이번 대회는 메시의 마지막 <b>월드컵<\/b>으로 주목을 받는다. <b>월드컵<\/b> 우승만 빼고 이룰 건 다 이룬 메시다.... \n5                   파울루 벤투 전 한국 축구대표팀 감독이 카타르 <b>월드컵<\/b>에서 대한민국을 지도한 것에 대해 “내 인생에서... FIFA가 공개한 내용에서 벤투 감독은 “2022 카타르 <b>월드컵<\/b>에서 대한민국을 지도한 것이 내 인생에서 가장... \n6              2022 카타르 <b>월드컵<\/b> 대망의 결승. 아르헨티나와 프랑스가 오는 19일 격돌한다. 이 경기에 나설 주심이 결정됐다. 주인공은 폴란드 출신의 시몬 마르치니아크 심판이다. 폴란드 심판이 FIFA <b>월드컵<\/b> 결승 주심으로 배정된... \n         publish_date\n1 2022-12-17 00:51:00\n2 2022-12-17 00:48:00\n3 2022-12-17 00:38:00\n4 2022-12-17 00:38:00\n5 2022-12-17 00:36:00\n6 2022-12-17 00:31:00\n                                                      title_text\n1             구찌와 함께 카메라 앞 황소 황희찬 독보적 매력 발산\n2                권영찬 교수 19일 공기업 초청 송년회서 특강 진행\n3             조용한 왕국 모로코 축구 반란 MENA권 희망의 슛 쏘다\n4 월드컵 메시 원맨팀 아니다아르헨티나 비밀병기 페르난데스에 기대\n5   벤투 FIFA 인터뷰서 태극전사에 감탄사 프로 의식에 특히 고맙다\n6                WC 결승 주심 2년 전 클롭 분노케 한 바로 그 주심\n                                                                                                                                                                                                       description_text\n1       잉글랜드 프리미어리그(EPL) 클럽 울버햄튼 원더러스 소속의 황희찬은 얼마 전 대한민국 국가대표팀의 유니폼을 입고 2022 FIFA(국제축구연맹) 카타르 월드컵에 출전했다. 조별 라운드 3번째 경기였던 포르투갈전에서는... \n2          지난 16일 소속사에 따르면 권 교수는 이번 강연에서 최근 카타르 월드컵에서 12년 만에 원정 16강이라는 염원을 현실로 이뤄낸 우리 대표팀의 불꽃 투혼과 더불어 EPL에서 뛰고 있는 ‘캡틴’ 손흥민과 ‘황소’ 황희찬... \n3            ━ 지구촌 정치 지형 바꾼 월드컵 FIFA 월드컵은 글로벌 사회의 진열대이자 문화 교류의 응접실이다. 시합 중계를 통해 전 세계 축구 선수들의 기량·전술과 경기 결과는 물론 경기장을 찾은 개최국·출전국 관람객과... \n4 아르헨티나가 2022 카타르 월드컵 결승전을 앞두고 있다. 19일 새벽 12시(이하 한국시간) 프랑스와 우승컵을 놓고 다툰다. 이번 대회는 메시의 마지막 월드컵으로 주목을 받는다. 월드컵 우승만 빼고 이룰 건 다 이룬 메시다.... \n5              파울루 벤투 전 한국 축구대표팀 감독이 카타르 월드컵에서 대한민국을 지도한 것에 대해 내 인생에서... FIFA가 공개한 내용에서 벤투 감독은 2022 카타르 월드컵에서 대한민국을 지도한 것이 내 인생에서 가장... \n6       2022 카타르 월드컵 대망의 결승. 아르헨티나와 프랑스가 오는 19일 격돌한다. 이 경기에 나설 주심이 결정됐다. 주인공은 폴란드 출신의 시몬 마르치니아크 심판이다. 폴란드 심판이 FIFA 월드컵 결승 주심으로 배정된... \n\ntail(news_worldcup_sim)\n\n\n                                                                                  title\n995                         [2022<b>월드컵<\/b>] 프랑스, 모로코 꺾어…아르헨티나와 결승전\n996                          메시vs음바페, <b>월드컵<\/b> 우승 놓고 신들의 전쟁 펼쳐진다\n997                          콤팩트 <b>월드컵<\/b> 효과…인판티노 FIFA회장 모든 경기 관전\n998  압도적 격차…카타르 <b>월드컵<\/b>에서 가장 인상적으로 활약한 선수 1위, 좀 뜻밖이...\n999          박지성, &apos;<b>월드컵<\/b> 스타&apos; 조규성과 현대차 대강당에 선 사연은?\n1000                         김상겸, 이탈리아 스노보드 <b>월드컵<\/b>서 11위…이상호 20위\n                                                                   originallink\n995             https://news.jtbc.co.kr/article/article.aspx?news_id=NB12107173\n996       http://starin.edaily.co.kr/news/newspath.asp?newsid=01108646632559176\n997  http://www.newsis.com/view/?id=NISX20221214_0002123590&cID=10523&pID=10500\n998                                  https://www.wikitree.co.kr/articles/816025\n999                               http://news.tf.co.kr/read/economy/1986329.htm\n1000 http://www.newsis.com/view/?id=NISX20221216_0002125336&cID=10501&pID=10500\n                                                              link\n995  https://n.news.naver.com/mnews/article/437/0000325156?sid=104\n996  https://n.news.naver.com/mnews/article/018/0005388183?sid=104\n997  https://n.news.naver.com/mnews/article/003/0011592305?sid=104\n998                     https://www.wikitree.co.kr/articles/816025\n999  https://n.news.naver.com/mnews/article/629/0000190477?sid=101\n1000 https://sports.news.naver.com/news.nhn?oid=003&aid=0011594558\n                                                                                                                                                                                                                                                   description\n995                                                프랑스가 2회 연속 <b>월드컵<\/b> 우승에 도전합니다. 15일(한국시간) 카타르 알바이트 스타디움에서 열린 4강전에서 프랑스는 모로코를 상대로 2대0 승리했습니다. 프랑스는 공격 중심의 축구로 전반부터 모로코를... \n996                                   사진=AP PHOTO 2022 카타르<b>월드컵<\/b> 결승전에서 전세계 축구팬들이 바라는 ‘축구 신들의 전쟁’이 펼쳐진다.... 이로써 프랑스는 4년 전 우승을 차지했던 러시아<b>월드컵<\/b>에 이어 또다시 결승에 진출했다. 만약 프랑스가... \n997                               카타르<b>월드컵<\/b>에서 사실상 거의 모든 경기를 현장에서 직관한 것으로 알려졌다. 15일 대한축구협회 고위 관계자에 따르면 인판티노 회장은 역대 피파 회장으로는 처음으로 <b>월드컵<\/b> 전 경기를 현장에서 관전했다고 자랑한... \n998                                  카타르 <b>월드컵<\/b>에서 가장 인상적으로 활약한 선수에 대한 여론 조사 결과가 발표됐다. 한국갤럽은 지난 13일... 그는 비록 이번 <b>월드컵<\/b>에서 득점을 기록하진 못했지만 국민들의 압도적인 지지를 받으며 당당히 1위에... \n999  현대차 <b>월드컵<\/b> 캠페인 글로벌 홍보대사 박지성, 임직원 대상 특강 박지성 &quot;환경·지속가능성 중요성 알리고 해결책 찾아야&quot; 현대자동차(현대차) <b>월드컵<\/b> 캠페인 글로벌 홍보대사 박지성과 2022 FIFA <b>월드컵<\/b>(이하 2022 <b>월드컵<\/b>)... \n1000                                  스노보드 <b>월드컵<\/b> 이탈리아 대회에서 11위에 올랐다. 김상겸은 15일(현지시간) 이탈리아 카레차에서 열린 2022~2023 FIS 스노보드 <b>월드컵<\/b> 알파인 남자 평행대회전 16강전에서 안드레아스 프롬메거(오스트리아)에 0.... \n            publish_date\n995  2022-12-15 06:35:00\n996  2022-12-16 07:19:00\n997  2022-12-15 09:00:00\n998  2022-12-16 12:32:00\n999  2022-12-16 11:01:00\n1000 2022-12-16 08:59:00\n                                                                 title_text\n995                        2022월드컵 프랑스 모로코 꺾어아르헨티나와 결승전\n996                      메시vs음바페 월드컵 우승 놓고 신들의 전쟁 펼쳐진다\n997                      콤팩트 월드컵 효과인판티노 FIFA회장 모든 경기 관전\n998  압도적 격차카타르 월드컵에서 가장 인상적으로 활약한 선수 1위 좀 뜻밖이\n999                   박지성 월드컵 스타 조규성과 현대차 대강당에 선 사연은\n1000                      김상겸 이탈리아 스노보드 월드컵서 11위이상호 20위\n                                                                                                                                                                                                      description_text\n995               프랑스가 2회 연속 월드컵 우승에 도전합니다. 15일(한국시간) 카타르 알바이트 스타디움에서 열린 4강전에서 프랑스는 모로코를 상대로 2대0 승리했습니다. 프랑스는 공격 중심의 축구로 전반부터 모로코를... \n996         사진=AP PHOTO 2022 카타르월드컵 결승전에서 전세계 축구팬들이 바라는 ‘축구 신들의 전쟁’이 펼쳐진다.... 이로써 프랑스는 4년 전 우승을 차지했던 러시아월드컵에 이어 또다시 결승에 진출했다. 만약 프랑스가... \n997     카타르월드컵에서 사실상 거의 모든 경기를 현장에서 직관한 것으로 알려졌다. 15일 대한축구협회 고위 관계자에 따르면 인판티노 회장은 역대 피파 회장으로는 처음으로 월드컵 전 경기를 현장에서 관전했다고 자랑한... \n998        카타르 월드컵에서 가장 인상적으로 활약한 선수에 대한 여론 조사 결과가 발표됐다. 한국갤럽은 지난 13일... 그는 비록 이번 월드컵에서 득점을 기록하진 못했지만 국민들의 압도적인 지지를 받으며 당당히 1위에... \n999  현대차 월드컵 캠페인 글로벌 홍보대사 박지성, 임직원 대상 특강 박지성 환경·지속가능성 중요성 알리고 해결책 찾아야 현대자동차(현대차) 월드컵 캠페인 글로벌 홍보대사 박지성과 2022 FIFA 월드컵(이하 2022 월드컵)... \n1000        스노보드 월드컵 이탈리아 대회에서 11위에 올랐다. 김상겸은 15일(현지시간) 이탈리아 카레차에서 열린 2022~2023 FIS 스노보드 월드컵 알파인 남자 평행대회전 16강전에서 안드레아스 프롬메거(오스트리아)에 0.... \n\n간단한 데이터 요약\n뉴스 빈발 단어\n빈발단어를 워드클라우드로 시각화하는 함수를 만듦\n\n\n# create UDF\ncreate_wordcloud <- function(data, remove_n = 5, min_freq = 5, background = \"white\") {\n  data %>% \n    filter(nchar(description_text) > 0) %>%   \n    tidytext::unnest_tokens(noun, description_text, bitTA::morpho_mecab, type = \"noun\") %>% \n    group_by(noun) %>% \n    count() %>% \n    arrange(desc(n)) %>%     \n    ungroup() %>%\n    filter(n >= min_freq) %>% \n    filter(row_number() > remove_n) %>% \n    wordcloud2::wordcloud2(backgroundColor = background, \n                           fontFamily = \"NanumSquare\")\n}\n\n\n\n날짜 기준으로 정렬 수집한 뉴스에 대해서 워드클라우드를 그려\n봅니다.\n\n\nlibrary(bitReport)\n\nnews_worldcup_date %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n\n\n(#fig:wcloud_wcupdate)날짜 기준 월드컵 뉴스\n\n\n\n유사도 기준으로 정렬 수집한 뉴스에 대해서 워드클라우드를 그려\n봅니다.\n\n\nnews_worldcup_sim %>% \n  create_wordcloud(remove_n = 20, min_freq = 2)\n\n\n\n\n\n(#fig:wcloud_wcupsim)유사도 기준 월드컵 뉴스\n\n\n\n정규표현식의 이해\n패턴 검색\n유사도 정렬 기준으로 수집한 뉴스 중에서 선수와 감독의 이름이 포함된\n기사의 건수를 계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_int(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        tally() %>% \n        pull()\n    }\n  )\n\n\n[1]  98 239  41  41  20 161\n\n각각의 기사에서 해당 선수와 감독의 이름이 평균 몇 번 등장하는지\n계산합니다.\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map_dbl(\n    function(x) {\n      news_worldcup_sim %>% \n        filter(stringr::str_detect(description_text, x)) %>% \n        mutate(n_talk = stringr::str_count(description_text, x)) %>% \n        summarise(n_avg = mean(n_talk, na.rm = TRUE)) %>% \n        pull()\n    }\n  )\n\n\n[1] 1.102041 1.209205 1.243902 1.975610 1.500000 1.621118\n\nDocument Term Matrix의 이해\nDTM 생성하기\n유사도 정렬 기준 뉴스의 Term Frequency 기반의 DTM과 TF-IDF 기반의\nDTM을 생성합니다. 뉴스 데이터는 문서 아이디로 사용할 변수가 없기 때문에\n아이디를 만듧니다.\n\n\nnews_worldcup_sim <- news_worldcup_sim %>% \n  mutate(id = row_number())\n\n\n\nTERM FREQUENCY 기반의 DTM\n인명인 고유명사도 함께 추출한 DTM을 만들기 위해서\nunnest_noun_ngrams() 함수의 type 인수값에 “noun2”를 사용합니다\n\n\nlibrary(tidyverse)\nlibrary(bitTA)\nlibrary(tidytext)\nlibrary(tm)\n\ndtm_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n)\n\ntm::inspect(dtm_tf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 616)>>\nNon-/sparse entries: 19670/596330\nSparsity           : 97%\nMaximal term length: 6\nWeighting          : term frequency (tf)\nSample             :\n     Terms\nDocs  결승전 선수 시간 월드컵 일 카타르 팀 프랑스 한국 활약\n  197      0    0    0      2  2      0  0      0    0    0\n  296      0    0    0      2  2      0  0      0    0    0\n  395      0    0    0      2  2      0  0      0    0    0\n  494      0    0    0      2  2      0  0      0    0    0\n  593      0    0    0      2  2      0  0      0    0    0\n  692      0    0    0      2  2      0  0      0    0    0\n  791      0    0    0      2  2      0  0      0    0    0\n  890      0    0    0      2  2      0  0      0    0    0\n  98       0    0    0      2  2      0  0      0    0    0\n  989      0    0    0      2  2      0  0      0    0    0\n\nTF-IDF 기반의 DTM\n\n\ndtm_tfidf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightTfIdf)\n\ntm::inspect(dtm_tfidf)\n\n\n<<DocumentTermMatrix (documents: 1000, terms: 616)>>\nNon-/sparse entries: 19670/596330\nSparsity           : 97%\nMaximal term length: 6\nWeighting          : term frequency - inverse document frequency (normalized) (tf-idf)\nSample             :\n      Terms\nDocs   결승전 메시 명 선수 손흥민 아르헨티나 인상 팀 프랑스 활약\n  1000      0    0  0    0      0          0    0  0      0    0\n  174       0    0  0    0      0          0    0  0      0    0\n  273       0    0  0    0      0          0    0  0      0    0\n  372       0    0  0    0      0          0    0  0      0    0\n  471       0    0  0    0      0          0    0  0      0    0\n  700       0    0  0    0      0          0    0  0      0    0\n  75        0    0  0    0      0          0    0  0      0    0\n  799       0    0  0    0      0          0    0  0      0    0\n  898       0    0  0    0      0          0    0  0      0    0\n  997       0    0  0    0      0          0    0  0      0    0\n\nCorrelation Analysis\n각각의 선수와 감독별로 상관계수가 0.4 이상인 단어를 추출해봅니다. ###\nTerm Frequency\n\n\npersons <- c(\"벤투\", \"손흥민\", \"조규성\", \"이강인\", \"호날두\", \"메시\")\n\npersons %>% \n  purrr::map(\n    function(x) tm::findAssocs(dtm_tf, terms = x, corlimit = 0.4)\n  )\n\n\n[[1]]\n[[1]]$벤투\n  감독 파울루   동행 \n  0.80   0.70   0.57 \n\n\n[[2]]\n[[2]]$손흥민\n  인상   활약 토트넘   선수 국내외   갤럽   결과   국민   전국     명 \n  0.72   0.72   0.68   0.62   0.56   0.50   0.50   0.48   0.48   0.44 \n  이상     세 \n  0.42   0.42 \n\n\n[[3]]\n[[3]]$조규성\n등장 외국 이름 황희 \n0.81 0.81 0.81 0.49 \n\n\n[[4]]\n[[4]]$이강인\n마요르카   유튜브     일원     채널     복귀   스페인       팀 \n    0.95     0.95     0.95     0.95     0.67     0.67     0.48 \n    소속 \n    0.48 \n\n\n[[5]]\n[[5]]$호날두\n    상태 마드리드     사용     시설     조기     퇴장       몸 \n    0.95     0.89     0.89     0.89     0.89     0.89     0.77 \n    일정     이후     휴식 포르투갈     결별       드     맨유 \n    0.63     0.63     0.63     0.55     0.44     0.44     0.44 \n맨체스터     무적     신세 유나이티     유지 잉글랜드     좌절 \n    0.44     0.44     0.44     0.44     0.44     0.44     0.44 \n      뒤       수 \n    0.43     0.43 \n\n\n[[6]]\n[[6]]$메시\n    리오넬 아르헨티나   생제르맹       파리       불참       관리 \n      0.69       0.59       0.55       0.55       0.47       0.43 \n    의료진       정기       훈련 \n      0.43       0.43       0.41 \n\n연관분석\nBinary Term Frequency 기반\nDTM 생성\n\n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\n불용어 제거\n상위 50위인 단어를 불용어로 처리하여 제거합니다.\n\n\nstop_words <- dtm_bin_tf %>% \n  apply(2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  \"[\"(1:30) %>% \n  names()\nstop_words\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"한국\"        \n [5] \"선수\"         \"시간\"         \"프랑스\"       \"활약\"        \n [9] \"팀\"           \"손흥민\"       \"대표\"         \"결승전\"      \n[13] \"국제축구연맹\" \"인상\"         \"축구\"         \"만\"          \n[17] \"아르헨티나\"   \"명\"           \"년\"           \"결승\"        \n[21] \"세\"           \"메시\"         \"강\"           \"카타르월드컵\"\n[25] \"진출\"         \"국내외\"       \"이번\"         \"전국\"        \n[29] \"국민\"         \"이상\"        \n\ndtm_bin_tf <- news_worldcup_sim %>% \n  unnest_noun_ngrams(term, description_text, n = 1, type = \"noun2\") %>% \n  filter(!term %in% stop_words) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(id, term, sort = TRUE) %>% \n  cast_dtm(id, term, n, weighting = tm::weightBin)\n\n\n\nTransactions 생성하기\n\n\nlibrary(\"arules\")\n\ntrans <- as(dtm_bin_tf %>% as.matrix(), \"transactions\")\ntrans\n\n\ntransactions in sparse format with\n 1000 transactions (rows) and\n 585 items (columns)\n\nsummary(trans)\n\n\ntransactions as itemMatrix in sparse format with\n 1000 rows (elements/itemsets/transactions) and\n 585 columns (items) and a density of 0.0195641 \n\nmost frequent items:\n 토트넘    갤럽    우승      중    영국 (Other) \n    145     142     141     117     114   10786 \n\nelement (itemset/transaction) length distribution:\nsizes\n  2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 \n 10  74  32  24  30  40  53  31  75 113  85  78 126  62  52  11  54 \n 19  21  24  25 \n 20  10  10  10 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00    8.00   12.00   11.45   14.00   25.00 \n\nincludes extended item information - examples:\n  labels\n1     개\n2 이강인\n3 스포츠\n\nincludes extended transaction information - examples:\n  transactionID\n1            40\n2            43\n3            46\n\n연관규칙 생성하기\n\n\nrules <- apriori(trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support\n        0.6    0.1    1 none FALSE            TRUE       5    0.05\n minlen maxlen target  ext\n      1     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 50 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[585 item(s), 1000 transaction(s)] done [0.00s].\nsorting and recoding items ... [42 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 done [0.00s].\nwriting ... [17 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\nsummary(rules)\n\n\nset of 17 rules\n\nrule length distribution (lhs + rhs):sizes\n 2  3 \n14  3 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   2.000   2.000   2.176   2.000   3.000 \n\nsummary of quality measures:\n    support          confidence        coverage      \n Min.   :0.05000   Min.   :0.6000   Min.   :0.05000  \n 1st Qu.:0.05000   1st Qu.:0.6483   1st Qu.:0.06000  \n Median :0.05000   Median :0.7500   Median :0.07800  \n Mean   :0.05871   Mean   :0.7824   Mean   :0.07853  \n 3rd Qu.:0.06000   3rd Qu.:0.8333   3rd Qu.:0.08000  \n Max.   :0.09400   Max.   :1.0000   Max.   :0.14500  \n      lift            count      \n Min.   : 4.546   Min.   :50.00  \n 1st Qu.: 7.267   1st Qu.:50.00  \n Median : 9.259   Median :50.00  \n Mean   : 9.809   Mean   :58.71  \n 3rd Qu.:12.500   3rd Qu.:60.00  \n Max.   :16.667   Max.   :94.00  \n\nmining info:\n  data ntransactions support confidence\n trans          1000    0.05        0.6\n                                                                                  call\n apriori(data = trans, parameter = list(support = 0.05, conf = 0.6, target = \"rules\"))\n\narules::inspect(rules[1:5])\n\n\n    lhs           rhs        support confidence coverage lift     \n[1] {생제르맹} => {파리}     0.050   1.0000000  0.050    16.666667\n[2] {파리}     => {생제르맹} 0.050   0.8333333  0.060    16.666667\n[3] {갤럽}     => {토트넘}   0.094   0.6619718  0.142     4.565323\n[4] {토트넘}   => {갤럽}     0.094   0.6482759  0.145     4.565323\n[5] {심판}     => {주심}     0.060   1.0000000  0.060    12.500000\n    count\n[1] 50   \n[2] 50   \n[3] 94   \n[4] 94   \n[5] 60   \n\n연관규칙 시각화하기\n\n\nlibrary(\"arulesViz\")\n\nplot(rules)\n\n\n\nrule2 <- sort(rules, by = \"confidence\")\ninspect(head(rule2, n = 10))\n\n\n     lhs               rhs        support confidence coverage\n[1]  {생제르맹}     => {파리}     0.05    1.0000000  0.05    \n[2]  {심판}         => {주심}     0.06    1.0000000  0.06    \n[3]  {벤투}         => {감독}     0.06    1.0000000  0.06    \n[4]  {심판, 폴란드} => {주심}     0.05    1.0000000  0.05    \n[5]  {파리}         => {생제르맹} 0.05    0.8333333  0.06    \n[6]  {심판}         => {폴란드}   0.05    0.8333333  0.06    \n[7]  {심판, 주심}   => {폴란드}   0.05    0.8333333  0.06    \n[8]  {폴란드, 주심} => {심판}     0.05    0.8333333  0.06    \n[9]  {주심}         => {심판}     0.06    0.7500000  0.08    \n[10] {주심}         => {폴란드}   0.06    0.7500000  0.08    \n     lift      count\n[1]  16.666667 50   \n[2]  12.500000 60   \n[3]  10.000000 60   \n[4]  12.500000 50   \n[5]  16.666667 50   \n[6]   9.259259 50   \n[7]   9.259259 50   \n[8]  13.888889 50   \n[9]  12.500000 60   \n[10]  8.333333 60   \n\nplot(rules, method = \"grouped\")\n\n\n\nplot(rules, method = \"graph\")\n\n\n\n\n단어의 계층적 군집분석\n희박 단어의 제거\n\n\ndim(dtm_bin_tf)\n\n\n[1] 1000  585\n\ncompact_bin <- tm::removeSparseTerms(dtm_bin_tf, sparse = 0.985) %>%\n  as.matrix(compact_bin)\n\ndim(compact_bin)\n\n\n[1] 1000  213\n\n비상사도 행렬 생성\n\n\nmat <- t(compact_bin)\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 213 \n\nClustering\nk개 군집을 나눕니다.\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n군집의 해석\nk개 클러스터를 구성하는 단어들의 목록을 조회합니다.\n\n\nk %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n[[1]]\n    중 토트넘   갤럽   결과 \n    35     43     45     46 \n\n[[2]]\n    박지성     글로벌     캠페인   홍보대사     현대차       강당 \n         4         14         15         16         40        138 \n      본사       사옥       세기     양재동     임직원       전북 \n       139        140        141        142        143        144 \n      현대 현대자동차     강연회     브랜드 \n       146        147        190        192 \n\n[[3]]\n    대회     우승   모로코   러시아       번   루사일 스타디움 \n      32       33       37       65       81       91       93 \n      시     승리   알코르   바이트       알     계단     통산 \n      94      173      174      175      176      199      201 \n\n[[4]]\n마르치   시몬   심판   아크 폴란드   주심 \n    21     22     23     24     25     26 \n\n[[5]]\n    개 보상금   구단   덕분     억     원   전망   조직 \n     1      5     48     49     51     52     54     55 \n\n[[6]]\n    이강인     스포츠       강전     산투스   포르투갈       유럽 \n         2          3          6          7          8          9 \n      우리     조규성       불참       훈련       출전       경기 \n        10         11         12         13         17         18 \n      매체       영국         조       황희     호날두       문제 \n        19         20         27         28         29         30 \n      인권       조사       감독       현지     김민재   이탈리아 \n        31         34         36         38         39         41 \n        전         간       최고         등     위원회         것 \n        42         44         47         50         53         56 \n      대상         천       주장         그       절반       개최 \n        57         58         59         60         61         62 \n      곳곳       규탄     움직임   준결승전       침해   한국갤럽 \n        63         64         66         67         68         69 \n      천만     특파원       혜란       동행         뒤       벤투 \n        70         71         72         73         74         75 \n    파울루       국가       동료       리그     마지막   생제르맹 \n        76         77         78         79         80         82 \n    유니폼       파리     리오넬       부상       세계       차례 \n        83         84         85         86         87         88 \n      도전       도하       무대       시작       이해       적기 \n        89         90         92         95         96         97 \n      주기       지금       참가   페르난두       협회         후 \n        98         99        100        101        102        103 \n      골절       수술       돌풍       스키         이       여론 \n       104        105        106        107        108        109 \n        골       관심       기자     뉴시스       박대       서울 \n       110        111        112        113        114        115 \n        선       일본       설문         위       차지       국내 \n       116        117        118        119        120        121 \n    우승컵       투호       나라       성과       예비       개막 \n       122        123        124        125        126        127 \n      멤버       보름     오현규       일정       우려       기사 \n       128        129        130        131        132        133 \n      내용       요약       기간         몸       출신       이하 \n       134        135        136        137        145        148 \n익스프레스     챔피언       최초       소식       여정         수 \n       149        150        151        152        153        154 \n  마요르카       소속     유튜브       일원       채널   대한민국 \n       155        156        157        158        159        160 \n      시각       상태     경기력         밤       관장     테일러 \n       161        162        163        164        165        166 \n      후보       휘슬       결정     맞대결       성사       조국 \n       167        168        169        170        171        172 \n      연속         차       배정       사상       이후       휴식 \n       177        178        179        180        181        182 \n      부진   슈틸리케       예선       지휘       탈락       디펜 \n       183        184        185        186        187        188 \n        딩       공개   비하인드       특별     보이콧     나폴리 \n       189        191        193        194        195        196 \n      새벽       투혼         바         페         벤       직전 \n       197        198        200        202        203        204 \n      연맹       대망       물결       거론         회         대 \n       205        206        207        208        209        210 \n      과거       상대       국제 \n       211        212        213 \n\n기사의 계층적 군집분석\n희박 단어의 제거\n비상사도 행렬 생성\n\n\nmat <- compact_bin\n\ndist_matrix <- dist(scale(mat))\n\n\n\nClustering\n\n\nfit <- hclust(dist_matrix, method = \"ward.D\")\nfit\n\n\n\nCall:\nhclust(d = dist_matrix, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 1000 \n\n군집 개수 선정 및 시각화\n\n\nk <- 6\n\nplot(fit)\ncluster_list <- rect.hclust(fit, k = k)\n\n\n\n\n군집의 해석\n군집별 기사 ID를 추출하고 기사의 개수를 조회합니다.\n\n\nclusters <- k %>% \n  seq() %>% \n  purrr::map(\n    function(x) {\n      cluster_list[[x]]\n    }\n  )\n\n\n\n\n\n# 기사의 개수\nclusters %>% \n  purrr::map_int(length)\n\n\n[1]  30 144  24  20  20 762\n\n기사 군집 1\n기사의 제목 조회\n20건만 선별 조회\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  select(title_text) %>% \n  head(n = 20)\n\n\n                                                            title_text\n1                월드컵 아르헨프랑스 결승전 주심에 사상 첫 폴란드 심판\n2                   월드컵 한국모로코에 패한 포르투갈 산투스 감독 사퇴\n3                         월드컵 못 뛴 홀란 맹훈련 중득점포 재가동할까\n4                       조규성 스코틀랜드 셀틱서 日 월드컵 스타와 경쟁\n5                         국민 59가 월드컵서 가장 활약한 선수로 손흥민\n6                       카타르월드컵 결승전 주심에 첫 폴란드 심판 휘슬\n7            월드컵 토트넘 손흥민 대회 출전 보상금으로 2억9천만원 수령\n8           현대차 월드컵 캠페인 홍보대사 박지성 임직원 대상 특강 실시\n9     월드컵서 가장 인상적인 선수는국민 10명 중 6명이 캡틴 손흥민 지목\n10                 국민 59가 월드컵에서 가장 활약한 선수로 손흥민 꼽아\n11               월드컵 맹활약 이강인 마요르카 복귀 첫 훈련격한 환영식\n12           월드컵 모로코 감독 졌지만 최선 다해세계에 자랑스러운 우리\n13                        국민 59 손흥민이 월드컵에서 가장 인상적 활약\n14                 월드컵 누가 가장 인상적이었나국민 59 이 선수 꼽았다\n15                           카타르 월드컵 가장 인상적인 선수는 손흥민\n16                메시 햄스트링 통증 훈련 불참아르헨티나 초비상 월드컵\n17                  음바페 vs 메시 다시는 볼 수 없는 월드컵 결승전이다\n18              아르헨티나 언론 메시 부상 괜찮다 월드컵 결승전 나설 것\n19              월드컵 모로코 언론 프랑스전 눈부시게 싸웠지만 여기까지\n20 월드컵 영상 메시 햄스트링 부상에 훈련 불참준결승전 메시 모습 자세히\n\n워드클라우드 그리기\n\n\nnews_worldcup_sim %>% \n  filter(id %in% clusters[[1]]) %>% \n  unnest_noun_ngrams(term, description_text, n = 1) %>% \n  filter(!str_detect(term, \"[[a-zA-Z]]+|[[0-9]]+\")) %>%  \n  count(term, sort = TRUE) %>% \n  filter(nchar(term) > 1) %>%   \n  filter(row_number() >= 15) %>% \n  wordcloud2::wordcloud2(fontFamily = \"NanumSquare\")\n\n\n\n\n\n(#fig:wcloud_news_wcupsim)월드컵 기사의 제목\n\n\n\nTopic 분석\n기사의 TF 기반의 DTM으로 Topic 분석을 수행합니다. ### 희박 단어의\n제거\n\n\ncompact_tf <- tm::removeSparseTerms(dtm_tf, sparse = 0.98) %>%\n  as.matrix()\n\ndim(compact_tf)\n\n\n[1] 1000  158\n\nOTF 계산\n\n\notf <- apply(compact_tf, 2, sum) %>% \n  sort(decreasing = TRUE) %>% \n  names()\n\n\n\n불용어 제거\nOverall Term Frequency 상위 15개 단어를 불용어로 간주하여\n제거합니다.\n\n\nstop_word <- otf[1:20]\nstop_word\n\n\n [1] \"월드컵\"       \"카타르\"       \"일\"           \"한국\"        \n [5] \"프랑스\"       \"선수\"         \"팀\"           \"활약\"        \n [9] \"시간\"         \"결승전\"       \"인상\"         \"명\"          \n[13] \"손흥민\"       \"대표\"         \"메시\"         \"아르헨티나\"  \n[17] \"축구\"         \"만\"           \"국제축구연맹\" \"결승\"        \n\ncompact_tf2 <- compact_tf[, !colnames(compact_tf) %in% stop_word] \ndim(compact_tf2)\n\n\n[1] 1000  138\n\nTopic Modeling\n\n\nlibrary(\"topicmodels\")\n\nk <- 2:10\n\ncompact_tf2 <- compact_tf2[compact_tf2 %>% apply(1, sum) != 0, ]\n\nmodels <- k %>% \n  purrr::map(\n    function(x) {\n      topicmodels::LDA(compact_tf2, k = x, control = list(seed = 123))\n    }\n  )\n\n\n\nTopic 개수 구하기\nLOG-LIKELIHOOD\n\n\nlog_ikelihood <- models %>% \n  purrr::map_dbl(logLik)\nlog_ikelihood\n\n\n[1] -40821.84 -40835.22 -40836.77 -35185.51 -34620.22 -33990.18\n[7] -33137.78 -32821.21 -31938.16\n\nwhich.max(log_ikelihood)\n\n\n[1] 9\n\nALPHA\n\n\nalpha <- models %>% \n  purrr::map_dbl(slot, \"alpha\")\nalpha\n\n\n[1] 40.56635882 37.03810981 37.39977375  0.06952115  0.06746002\n[6]  0.06613153  0.06216561  0.06117039  0.03940365\n\nwhich.min(alpha)\n\n\n[1] 9\n\nTop beta 단어의 시각화\n\n\nprob <- tidytext::tidy(models[[9]], matrix = \"beta\")\nprob\n\n\n# A tibble: 1,380 × 3\n   topic term       beta\n   <int> <chr>     <dbl>\n 1     1 개    5   e-323\n 2     2 개    3.72e- 44\n 3     3 개    1.18e- 56\n 4     4 개    1.03e-  1\n 5     5 개    4.11e-315\n 6     6 개    2.5 e-323\n 7     7 개    3.72e- 44\n 8     8 개    2.92e-210\n 9     9 개    6.89e- 28\n10    10 개    9.96e- 76\n# … with 1,370 more rows\n\n\n\ntop_prob <- prob %>% \n  group_by(topic) %>% \n  top_n(10, beta) %>% \n  ungroup() %>% \n  arrange(topic, -beta)\ntop_prob\n\n\n# A tibble: 104 × 3\n   topic term       beta\n   <int> <chr>     <dbl>\n 1     1 모로코   0.118 \n 2     1 스타디움 0.0821\n 3     1 알코르   0.0768\n 4     1 바이트   0.0589\n 5     1 알       0.0512\n 6     1 승리     0.0461\n 7     1 도전     0.0461\n 8     1 이탈리아 0.0410\n 9     1 현지     0.0397\n10     1 준결승전 0.0384\n# … with 94 more rows\n\n\n\ntop_prob %>% \n  mutate(term = reorder(term, beta)) %>% \n  ggplot(aes(x = term,  y = beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~topic, scales = \"free\") +\n  coord_flip()\n\n\n\n\n(#fig:plot_top_prob)Top beta 단어의 시각화\n\n\n\n문서에서의 토픽의 비중\n\n\nnews_gamma <- tidytext::tidy(models[[9]], matrix = \"gamma\") %>% \n  mutate(gamma = gamma * 100)\n\nnews_gamma\n\n\n# A tibble: 10,000 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 49           1 0.897\n 2 89           1 0.533\n 3 148          1 0.897\n 4 188          1 0.533\n 5 247          1 0.897\n 6 287          1 0.533\n 7 346          1 0.897\n 8 386          1 0.533\n 9 445          1 0.897\n10 485          1 0.533\n# … with 9,990 more rows\n\n토픽이 포함된 문서 조회\n토픽 1의 주요 단어는 다음과 같습니다.\n\n\nterms(models[[9]], 10)[, 1]\n\n\n [1] \"모로코\"   \"스타디움\" \"알코르\"   \"바이트\"   \"알\"       \"승리\"    \n [7] \"도전\"     \"이탈리아\" \"현지\"     \"준결승전\"\n\n토픽 1이 95% 이상 포함된 문서를 조회합니다.\n\n\nnews_gamma %>%\n  filter(topic == 1) %>%\n  filter(gamma >= 95) %>%\n  arrange(desc(gamma))\n\n\n# A tibble: 47 × 3\n   document topic gamma\n   <chr>    <int> <dbl>\n 1 88           1  96.6\n 2 187          1  96.6\n 3 286          1  96.6\n 4 385          1  96.6\n 5 484          1  96.6\n 6 583          1  96.6\n 7 682          1  96.6\n 8 781          1  96.6\n 9 880          1  96.6\n10 979          1  96.6\n# … with 37 more rows\n\n61번째 기사의 이해\n\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(title_text) %>% \n  pull()\n\n\n[1] \"슈틸리케 월드컵 뛴 韓선수 절반 내가 3년 가르쳐\"\n\n\n\nnews_worldcup_sim %>% \n  filter(id %in% \"61\") %>% \n  select(description_text) %>% \n  pull()\n\n\n[1] \"카타르월드컵에서 한국의 경기력을 높이 평가했다. 슈틸리케 전 감독은 최근 스페인어 온라인 매체... 2018 러시아월드컵 예선을 지휘했다. 그는 지도력 부족과 성적 부진 등 이유로 월드컵 본선을 치르지 못하고 경질됐다.\"\n\n문서의 토픽 분해\n모든 문서는 토픽들의 복합체입니다. 기사 1을 분해하여 토픽의 비율을\n조해해 봅니다.\n\n\nnews_gamma %>%\n  filter(document %in% \"1\") %>% \n  arrange(desc(gamma)) \n\n\n# A tibble: 10 × 3\n   document topic  gamma\n   <chr>    <int>  <dbl>\n 1 1            9 94.5  \n 2 1            3  0.616\n 3 1            2  0.616\n 4 1           10  0.616\n 5 1            1  0.616\n 6 1            4  0.616\n 7 1            5  0.616\n 8 1            6  0.616\n 9 1            7  0.616\n10 1            8  0.616\n\n토픽의 단어 분해\n\n\ntop_prob %>% \n  filter(topic == 6) %>% \n  arrange(desc(beta)) \n\n\n# A tibble: 10 × 3\n   topic term     beta\n   <int> <chr>   <dbl>\n 1     6 폴란드 0.146 \n 2     6 주심   0.131 \n 3     6 심판   0.118 \n 4     6 마르치 0.0656\n 5     6 시몬   0.0656\n 6     6 아크   0.0656\n 7     6 루사일 0.0394\n 8     6 후보   0.0394\n 9     6 무대   0.0394\n10     6 매체   0.0312\n\n이진분류 모형\n패키지 로드하기\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(bitTA)\n\n\n\n파생변수 만들기\n연합뉴스 여부\n연합뉴스 기사 : 1\n기타뉴스 기사 : 0\n\n\n\nnews_worldcup_yna <- news_worldcup_sim %>% \n  mutate(yna_flag = ifelse(stringr::str_detect(originallink, \"www.yna.co.kr\"), 1, 0))\n\nnews_worldcup_yna %>% \n  count(yna_flag) %>% \n  mutate(ratio = n /sum(n) * 100)\n\n\n  yna_flag   n ratio\n1        0 809  80.9\n2        1 191  19.1\n\n불균형 데이터의 언더 샘플링\n\n\nn_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1) %>% \n  tally() %>% \n  pull()\n\nn_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  tally() %>% \n  pull()\n\nset.seed(123)\nidx_sample <- sample(seq(n_not_yna), size = n_yna)\n\nsubset_not_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 0) %>% \n  filter(row_number() %in% idx_sample)\n\nsubset_yna <- news_worldcup_yna %>% \n  filter(yna_flag == 1)\n\nnews_sample_yna <- bind_rows(subset_not_yna, subset_yna)\n\nnews_sample_yna %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 191\n2        1 191\n\n데이터셋 분리\n\n\nset.seed(123)\nnews_split <- initial_split(news_sample_yna, strata = yna_flag)\n\ntrain <- rsample::training(news_split)\ntest <- rsample::testing(news_split)\n\ndim(train)\n\n\n[1] 286   9\n\ndim(test)\n\n\n[1] 96  9\n\ntrain %>% \n  count(yna_flag)\n\n\n  yna_flag   n\n1        0 143\n2        1 143\n\ntest %>% \n  count(yna_flag)\n\n\n  yna_flag  n\n1        0 48\n2        1 48\n\ntokenize 반복기 정의\n\n\n# 일반명사 단위로 토큰을 생성\ntoken_fun <- bitTA::morpho_mecab\n\nit_train <- itoken_parallel(train$description_text, \n                   tokenizer = token_fun, \n                   ids = train$id, \n                   progressbar = FALSE)\n\nit_test <- itoken_parallel(test$description_text, \n                  tokenizer = token_fun, \n                  ids = test$id, \n                  progressbar = FALSE)\n\n\n\nFrequency 기반의 DTM 생성\nVOCABULARY 생성\n\n\nlibrary(doParallel)\n\nnc <- parallel::detectCores()\nregisterDoParallel(cores = nc)\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 286 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n      term term_count doc_count\n 1: 결승전         69        46\n 2:   우승         69        53\n 3:   대표         75        65\n 4:   선수         75        55\n 5:   결승        105        85\n 6:     팀        107        77\n 7:   시간        130       126\n 8: 프랑스        204       115\n 9: 카타르        367       228\n10: 월드컵        558       280\n\nDOCUMENT TERM MATRIX\n생성하기\n\n\nvectorizer <-  vocab_vectorizer(vocab)\n\ndtm_train_tf <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train_tf)\n\n\n[1] 286 490\n\ndtm_test_tf <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test_tf)\n\n\n[1]  96 490\n\nN-Grams 기반의 DTM 생성\nVOCABULARY 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 1525    3\n\nPRUNE VOCABULARY\n\n\nvocab_bigram <- vocab_bigram %>% \n  prune_vocabulary(term_count_min = 10,\n                   doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 197   3\n\nDOCUMENTS TERM MATRIX 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1] 286 197\n\ndtm_test_bigram  <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1]  96 197\n\nTF-IDF 기반의 DTM 생성\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train_tf, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test_tf, tfidf) \n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train_tf)\n\n\n[1] 286 490\n\ndim(dtm_train_bigram)\n\n\n[1] 286 197\n\ndim(dtm_train_tfidf)\n\n\n[1] 286 490\n\nFrequency 기반 모델링\n\n\nNFOLDS <- 10\n\nclassifier_tf <- cv.glmnet(x = dtm_train_tf, y = train$yna_flag, \n                           family = \"binomial\",\n                           alpha = 1,\n                           parallel = TRUE, \n                           keep = TRUE)\n\n\n\n모델의 이해\n\n\nlibrary(broom)\n\ncoefs_tf <- classifier_tf$glmnet.fit %>%\n  tidy() %>%\n  filter(lambda == classifier_tf$lambda.1se)\ncoefs_tf \n\n\n# A tibble: 52 × 5\n   term         step  estimate  lambda dev.ratio\n   <chr>       <dbl>     <dbl>   <dbl>     <dbl>\n 1 (Intercept)    81 -3.60e+ 0 0.00538     0.963\n 2 공격           81 -3.90e+ 0 0.00538     0.963\n 3 상승세         81 -3.54e+ 0 0.00538     0.963\n 4 수록           81 -8.91e-16 0.00538     0.963\n 5 전반           81 -1.59e- 2 0.00538     0.963\n 6 중심           81 -1.07e-15 0.00538     0.963\n 7 격파           81 -2.29e+ 0 0.00538     0.963\n 8 결국           81 -4.88e+ 0 0.00538     0.963\n 9 기회           81 -3.05e- 2 0.00538     0.963\n10 동안           81 -3.35e- 4 0.00538     0.963\n# … with 42 more rows\n\n\n\ncoefs_tf %>%\n  group_by(estimate > 0) %>%\n  top_n(10, abs(estimate)) %>%\n  ungroup() %>%\n  ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate > 0)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    title = \"예측에 영향을 주는 모델의 계수들 with TF\",\n    subtitle = \"네이버 월드컵 관련 뉴스\"\n  )\n\n\n\n\n(#fig:plot_coefs_tf)예측에 영향을 주는 모델의 계수들 with TF\n\n\n\n모델의 평가\n정오분류 행렬\n\n\nnews_tf <- predict(classifier_tf, dtm_test_tf, type = 'class')\ncm_tf <- confusionMatrix(factor(test$yna_flag), factor(news_tf), positive = \"1\")\ncm_tf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 48  0\n         1  1 47\n                                          \n               Accuracy : 0.9896          \n                 95% CI : (0.9433, 0.9997)\n    No Information Rate : 0.5104          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9792          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.9796          \n         Pos Pred Value : 0.9792          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.4896          \n         Detection Rate : 0.4896          \n   Detection Prevalence : 0.5000          \n      Balanced Accuracy : 0.9898          \n                                          \n       'Positive' Class : 1               \n                                          \n\nROC 커브\n\n\nlibrary(\"pROC\")\n\npredictions <- predict(classifier_tf, dtm_test_tf, type = 'response')\nroc_tf <- pROC::roc(test$yna_flag, predictions)\n\npROC::auc(roc_tf)\n\n\nArea under the curve: 0.9865\n\n\n\nplot(roc_tf)\n\n\n\n\n(#fig:plot_roctf)ROC 커브\n\n\n\n\n\nidx <- predictions %>% \n  which.max()\n\npredictions[idx]\n\n\n[1] 0.9961728\n\ntest[idx, \"description_text\"]\n\n\n[1] \"카타르 월드컵 결승행에 이바지했다. 프랑스는 15일(한국시간) 카타르 알코르의 알바이트 스타디움에서 열린... 그러나 월드컵이 시작되자 이런 비판의 목소리는 싹 사라진 분위기다. 프랑스는 이번 대회를 앞두고 은골로... \"\n\n\n\nidx <- predictions %>% \n  which.min()\n\npredictions[idx]\n\n\n[1] 0.002243855\n\ntest[idx, \"description_text\"]\n\n\n[1] \"2022 국제축구연맹(FIFA) 카타르 월드컵에서 가장 인상적인 활약을 펼친 선수를 묻는 설문 조사에서 절반이... 보여줬다며 월드컵 직전 가장 기대되는 선수로 꼽혔다. 매년 조사하는 올해의 스포츠선수에서 6년 연속... \"\n\n\n\n\n",
      "last_modified": "2023-01-01T00:42:58+09:00"
    },
    {
      "path": "classifier_lasso.html",
      "title": "대통령 연설문 예측",
      "description": "2022학년도 2학기 텍스트 정보처리와 NLP 수업내용입니다.\n텍스트 분류모형을 개발하고, DTM의 종류별 성능 차이를 비교합니다.\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n준비하기\n패키지 로드하기\n\n분석 방법 정의\n데이터셋 샘플링\n데이터셋 분리\ntokenize 반복기 정의\n\nTF기반의 DTM 생성\nVocabulary 생성\nDocument Term Matrix\n생성하기\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\nPrune Vocabulary\nDocuments Term Matrix\n생성\n\nTF-IDF 기반의 DTM 생성\nDTM의 TF-IDF 변환\n\nDTM의 크기 비교\nLASSO 회귀모형 모델 적합\nFrequency 기반 모델링\nN-Grams 기반 모델링\nTF-IDF 기반의 모델\n\n모델 성능의 비교\n\n준비하기\n패키지 로드하기\n\n\n# ■ text2vec -텍스트 분류모델 개발을 위해서 텍스트를 벡터화하는\n# 패키지를 설치하고 불러오기\nif (!require(\"text2vec\")) {\n    install.packages(\"text2vec\")\n    library(\"text2vec\")\n}\n\n# ■ glmnet - 분류모델 개발을 위한 glmnet 패키지를 설치하고 불러오기\n\nif (!require(\"glmnet\")) {\n    install.packages(\"glmnet\")\n    library(\"glmnet\")\n}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(caret)\nlibrary(bitTA)\n\n\n\n분석 방법 정의\n데이터셋 샘플링\n앞서 배운 tidymodels 패키지를 이용해서 데이터셋을 샘플링합니다.\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 87.5% : 12.5%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- rsample::initial_split(president_speech, prop = 7/8,\n    strata = president)\n\npresident_smpl <- rsample::testing(president_split)\n\n\n\n데이터셋 분리\n비로소 모델 개발을 위한 데이터셋을 분리합니다.\ninitial_split(), initial_split(), initial_split() 함수로 원 데이터를\n학습 : 평가 = 70% : 30%로 분리를 수행합니다.\n\n\nset.seed(123)\npresident_split <- initial_split(president_smpl, prop = 0.7, strata = president)\n\ntrain <- rsample::training(president_split)\ntest <- rsample::testing(president_split)\n\n\n\ntokenize 반복기 정의\ntokenizer로 text2vec::morpho_mecab()를 정의했기 때문에 띄어쓰기\n단위의 term이 생성될 것입니다.\n\n\n# 띄어쓰기 단위로 토큰을 생성\ntoken_fun <- text2vec::word_tokenizer\n\nit_train <- itoken(train$doc, tokenizer = token_fun, ids = train$id, progressbar = T)\n\nit_test <- itoken(test$doc, tokenizer = token_fun, ids = test$id, progressbar = FALSE)\n\n\n\nTF기반의 DTM 생성\nVocabulary 생성\nvocabulary는 documents로부터 생성된 terms의 집합 여기서는 tokenizer를\n일반명사로 정의했기 때문에 일반명사 집합으로 vocabulary가 생성\n몇몇 데이터를 조회해보면 term별로 frequency와 document frequency가\n도출되었음을 알 수 있음\n또한 word2vec 패키지의 함수들은 parallel processing을 지원하므로,\nparallel 처리를 위한 multicores 사용을 지원하는 doMC, doParallel 등의\n패키지 사용이 필요.\n\n\nvocab <- create_vocabulary(it_train)\n\ntail(vocab, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n        term term_count doc_count\n 1:   그리고        505       147\n 2:       한        505       134\n 3:       그        566       135\n 4:     있는        601       155\n 5:   여러분        607       175\n 6:       이        625       153\n 7:     우리        886       175\n 8:       수        935       167\n 9: 것입니다       1004       180\n10: 있습니다       1383       192\n\nDocument Term Matrix\n생성하기\ndocuments taxonomy 분류 모델을 수행하는 데이터셋은 DTM(Document Term\nMatrix) 구조여야 함. 그래서 vocabulary를 DTM으로 변환하는 작업을 수행.\ntext2vec::create_dtm() 함수를 사용.\n\n\nvectorizer <- vocab_vectorizer(vocab)\n\ndtm_train <- text2vec::create_dtm(it_train, vectorizer)\ndim(dtm_train)\n\n\n[1]   210 31602\n\n\n\ndtm_test <- text2vec::create_dtm(it_test, vectorizer)\ndim(dtm_test)\n\n\n[1]    92 31602\n\nN-Grams 기반의 DTM 생성\nVocabulary 생성\n\n\nvocab_bigram <- create_vocabulary(it_train, ngram = c(1L, 2L))\ndim(vocab_bigram)\n\n\n[1] 126313      3\n\n\n\nhead(vocab_bigram, n = 10)\n\n\nNumber of docs: 210 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 2 \nVocabulary: \n            term term_count doc_count\n 1:          0.1          1         1\n 2:   0.1_미만의          1         1\n 3:     1,000_개          1         1\n 4: 1,000_만이나          1         1\n 5:        1,050          1         1\n 6:     1,050_억          1         1\n 7:        1,100          1         1\n 8: 1,100_여개의          1         1\n 9:        1,200          1         1\n10:   1,200_만이          1         1\n\nPrune Vocabulary\n\nDocuments의 개수가 증가하거나 Documents의 길이가 증가하면,\nVocabulary의 규모도 증가 함. 이것은 모델을 생성하는데 많은 컴퓨팅\n리소스를 소모해서 속도가 느려짐. 그래서 모델에 영향을 덜 줄 수 있는\nterms를 제거하는 작업이 필요함.\n\n\n\nvocab_bigram <- vocab_bigram %>%\n    prune_vocabulary(term_count_min = 10, doc_proportion_max = 0.5)\ndim(vocab_bigram)\n\n\n[1] 2046    3\n\nDocuments Term Matrix 생성\n\n\nvectorizer_bigram <- vocab_vectorizer(vocab_bigram)\n\ndtm_train_bigram <- create_dtm(it_train, vectorizer_bigram)\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\n\n\ndtm_test_bigram <- create_dtm(it_test, vectorizer_bigram)\ndim(dtm_test_bigram)\n\n\n[1]   92 2046\n\nTF-IDF 기반의 DTM 생성\nTF-IDF는 단일문서, 혹은 소수의 문서에서 의미가 있는 terms의 가중치를\n높이고 대부분의 문서에서 발현하는 terms의 가중치를 줄이는 용도로\n만들어진 측도입니다. 그러므로 DTM에 TF-IDF 변환을 수행하면 모델의 성능이\n개선됩니다\nText Anaytics에서는 documents의 길이의 차이가 있으면, 상대적으로\n짧거나 긴 documents에서 발현하는 terms들로 인해서 frequency scale에\n왜곡이 있을 수 있습니다. 이 경우에는 표준화를 수행해야 합니다. 그런데\nTF-IDF 변환은 자동으로 표준화가 되기 때문에 표준화의 잇점이 있습니다.\n만약 표준화를 수행하려면, normalize() 함수를 사용하면 됩니다.\nDTM의 TF-IDF 변환\nTfIdf class와 fit_transform() 함수를 이용해서 DTM에 TF-IDF 변환을\n수행합니다.\n\n\ntfidf <- TfIdf$new()\n\ndtm_train_tfidf <- fit_transform(dtm_train, tfidf)\ndtm_test_tfidf <- fit_transform(dtm_test, tfidf)\n\n\n\nDTM의 크기 비교\n\n\ndim(dtm_train)\n\n\n[1]   210 31602\n\ndim(dtm_train_bigram)\n\n\n[1]  210 2046\n\ndim(dtm_train_tfidf)\n\n\n[1]   210 31602\n\nLASSO 회귀모형 모델 적합\nFrequency 기반 모델링\n모델 생성\n\n\nNFOLDS <- 10\n\nclassifier <- cv.glmnet(x = dtm_train, y = train$president, family = \"multinomial\",\n    alpha = 1, type.measure = \"deviance\", nfolds = NFOLDS, thresh = 0.001,\n    maxit = 1000, parallel = TRUE)\n\n\n\n모델의 평가\ntest 데이터로 평가한 결과 Accuracy가 0.869로 비교적 높게\n나타났습니다\n\n\npred_voca <- predict(classifier, dtm_test, type = \"response\")[, , 1]\npresident_voca <- apply(pred_voca, 1, function(x) colnames(pred_voca)[which(max(x) ==\n    x)])\n\ncmat_voca <- confusionMatrix(factor(president_voca), factor(test$president))\ncmat_voca\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     21      0      2\n    노무현      7     25      4\n    이명박      3      5     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7717          \n                 95% CI : (0.6725, 0.8528)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.6579          \n                                          \n Mcnemar's Test P-Value : 0.06262         \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.6774        0.8333        0.8065\nSpecificity                 0.9672        0.8226        0.8689\nPos Pred Value              0.9130        0.6944        0.7576\nNeg Pred Value              0.8551        0.9107        0.8983\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2283        0.2717        0.2717\nDetection Prevalence        0.2500        0.3913        0.3587\nBalanced Accuracy           0.8223        0.8280        0.8377\n\nN-Grams 기반 모델링\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_bigram, y = train$president, family = \"multinomial\",\n    type.measure = \"deviance\", alpha = 1, nfolds = NFOLDS, parallel = TRUE)\n\n\n\n모델의 평가\nvocabulary를 가지지기했음에도 불구하고, 전체 vocabulary를 사용한\n모델보다 성능이 좋아졌습니다.\n\n\npred_bigram <- predict(classifier, dtm_test_bigram, type = \"response\")[,\n    , 1]\n\npresident_bigram <- apply(pred_bigram, 1, function(x) colnames(pred_bigram)[which(max(x) ==\n    x)])\n\ncmat_bigram <- confusionMatrix(factor(president_bigram), factor(test$president))\ncmat_bigram\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     22      1      1\n    노무현      3     25      5\n    이명박      6      4     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7826          \n                 95% CI : (0.6844, 0.8619)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.674           \n                                          \n Mcnemar's Test P-Value : 0.1966          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.7097        0.8333        0.8065\nSpecificity                 0.9672        0.8710        0.8361\nPos Pred Value              0.9167        0.7576        0.7143\nNeg Pred Value              0.8676        0.9153        0.8947\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.2391        0.2717        0.2717\nDetection Prevalence        0.2609        0.3587        0.3804\nBalanced Accuracy           0.8384        0.8522        0.8213\n\nTF-IDF 기반의 모델\n모델 생성\n\n\nclassifier <- cv.glmnet(x = dtm_train_tfidf, y = train$president, family = \"multinomial\",\n    nfolds = NFOLDS, thresh = 0.001, maxit = 1000, parallel = TRUE)\n\n\n\n모델의 평가\n\n\npred_tfidf <- predict(classifier, dtm_test_tfidf, type = \"response\")[,\n    , 1]\n\npresident_tfidf <- apply(pred_tfidf, 1, function(x) colnames(pred_tfidf)[which(max(x) ==\n    x)])\n\ncmat_tfidf <- confusionMatrix(factor(president_tfidf), factor(test$president))\ncmat_tfidf\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 김대중 노무현 이명박\n    김대중     28      7      4\n    노무현      2     20      2\n    이명박      1      3     25\n\nOverall Statistics\n                                          \n               Accuracy : 0.7935          \n                 95% CI : (0.6964, 0.8708)\n    No Information Rate : 0.337           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.6899          \n                                          \n Mcnemar's Test P-Value : 0.1888          \n\nStatistics by Class:\n\n                     Class: 김대중 Class: 노무현 Class: 이명박\nSensitivity                 0.9032        0.6667        0.8065\nSpecificity                 0.8197        0.9355        0.9344\nPos Pred Value              0.7179        0.8333        0.8621\nNeg Pred Value              0.9434        0.8529        0.9048\nPrevalence                  0.3370        0.3261        0.3370\nDetection Rate              0.3043        0.2174        0.2717\nDetection Prevalence        0.4239        0.2609        0.3152\nBalanced Accuracy           0.8614        0.8011        0.8704\n\n모델 성능의 비교\n모델의 성능은 TF-IDF > Bigram(Pruned) > Frequency의 순서로\n나타납니다.\n그러므로 성능을 높이기 위해서는 TF-IDF 방법을 사용하는 것이 좋으며,\n대용량의 데이터 분석에서는 적은 성능 감소와 수행 속도의 개선을 가져오는\nFeature Hashing 기법을 사용하면 될 것입니다. 이 경우에는 Purne\nVocabulary 전처리도 필요할 것입니다.\n다만, 몇몇 결과는 그 성능 차이가 작기 때문에 모델의 파라미터에 따라\n순서가 바뀔수도 있습니다\n\n\naccuracy <- rbind(cmat_voca$overall, cmat_bigram$overall, cmat_tfidf$overall) %>%\n    round(3)\n\ndata.frame(Method = c(\"Frequency\", \"Bigram\", \"TF-IDF\"), accuracy) %>%\n    arrange(desc(Accuracy)) %>%\n    knitr::kable()\n\n\nMethod\nAccuracy\nKappa\nAccuracyLower\nAccuracyUpper\nAccuracyNull\nAccuracyPValue\nMcnemarPValue\nTF-IDF\n0.793\n0.690\n0.696\n0.871\n0.337\n0\n0.189\nBigram\n0.783\n0.674\n0.684\n0.862\n0.337\n0\n0.197\nFrequency\n0.772\n0.658\n0.672\n0.853\n0.337\n0\n0.063\n\n\n\n\n",
      "last_modified": "2023-01-01T01:34:15+09:00"
    },
    {
      "path": "create_website.html",
      "title": "웹 사이트 개발하기",
      "description": "웹 사이트 개발하는 방법을 간단하게 소개합니다.\n",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n설정사항\n수정해야할 사항\n웹 사이트 구성 파일\n개별 페이지 구성 정보\n\nData: USArrests\n표(tables) 출력\n플롯(plots) 출력\n\n\n\n\n\n\n들어가기\n이 웹 사이트는 예제를 위해서 만든 간단한 사이트입니다.\n\n여러분은 이 Skelton 사이트에 살을 붙여서 자신의 웹 사이트를 만들 수 있습니다. 그리고 이 작업은 사이트의 구조를 이해하는 것으로부터 시작됩니다.\n\n\n\n설정사항\n수정해야할 사항\n본 템플리트는 웹 사이트 중의 한 페이지로 bitReport\nwebsite라는 이름의 예제입니다. 환경 설정파일인\n_site.yml에 “샘플 웹 사이트”이라는 제목으로 연결되어\n있습니다. 만약에 예제 템플리트를 완성하려면 이 페이지의 이름을\n_site.yml에서의 create_website과 동일하게\n설정해야 합니다.\n웹 사이트 구성 파일\n웹 사이트를 구성하는 설정은 구성파일인 **_site.yml**에\n정의합니다.\n_site.yml 파일에서의 사용자가 설정해야할 항목은 다음과 같습니다.\nname: 웹 사이트의 이름\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ntitle: 웹 사이트의 타이틀\n헤더의 네비게이션 바의 왼쪽에 링크표시됩니다.\n\ndescription: 웹 사이트의 설명\noutput_dir: 생성될 웹 사이트의 정적 HTML이 저장될 디렉토리\n“docs”로 기본설정됩니다. 이 디렉토리는 github page로 deploy할 때\n유용합니다.\n\nnavbar: 웹 사이트의 메뉴를 정의하는 섹션입니다.\n수정하지 않습니다.\n\nright: 웹 사이트의 메뉴를 정의합니다.\ntext는 메뉴 이름입니다.\nhref는 메뉴와 연결할 웹 페이지입니다. 확장자는\nhtml입니다.\nR markdown 파일과 동일하게 이름을 부여합니다.\n\nmenu는 서브메뉴를 정의합니다.\n빈 분리자를 만들기 위해서는 “- text:”—“를 사용합니다.\n\noutput: 웹 사이트 출력에 대한 설정입니다. 사용자가 수정하지\n않습니다.\n개별 페이지 구성 정보\n개별 페이지를 구성하기 위해서는 knitr YAML을 수정해야 합니다.\ntitle: 웹 페이지 제목입니다.\ndescription: 웹 페이지를 간단하게 소개하는 소개문입니다.\nauthor: 웹 페이지 컨텐츠 저작자 정보를 기술합니다.\nname: 저작자 이름\nurl: 저작자 개인 홈페이지 URL\naffiliation: 저작자 소속 회사/부서\naffiliation_url: 저작자 소속 회사/부서 홈페이지 URL\n\ndate: 컨텐츠를 생성한 날짜\noutput: 웹 사이트 출력에 대한 설정입니다.\ntoc: 목차를 출력할 지의 여부를 정의합니다. true이면 출력합니다.\ntoc_depth: 출력할 목차의 depth를 정의합니다. 3이면 3 depth까지\n표시합니다.\n\n\n이 예제 웹 사이트는 하나의 완성된 페이지를 만드는 것이 아닌, 가상의\nsite를 담은 Skelton만 제공합니다. 그러므로 개별 페이지의 내용에 신경쓸\n필요가 없습니다.\n\nData: USArrests\nUSArrests는 미국 주별 강력 범죄율을 기록한\n데이터입니다.\n이 데이터셋은 4개의 변수와 50개의 관측치로 구성된 데이터\n프레임(data.frame) 객체입니다.:\nMurder\nnumeric. 살인범 검거 건수(100,000건당)\n\nAssault\nnumeric. 폭행범 검거 건수(100,000건당)\n\nUrbanPop\nnumeric. 도시 인구 비율(백분율)\n\nRape\nnumeric. 강간범 검거 건수(100,000건당)\n\n\n\n# code here\n\n\n\n표(tables) 출력\n미국 주별 강력 범죄율을 기록한 데이터인 USArrests를 표로\n출력합니다.\n\n\nUSArrests %>%\n    tibble::rownames_to_column(\"주 (State)\") %>%\n    arrange(desc(Murder + Assault + Rape)) %>%\n    filter(row_number() <= 10) %>%\n    select(1:3, 5, 4) %>%\n    rename(살인범 = Murder) %>%\n    rename(폭행범 = Assault) %>%\n    rename(강간범 = Rape) %>%\n    rename(`도시인구수(백분율)` = UrbanPop) %>%\n    kableExtra::kbl(caption = \"미국 범죄 상위 10개 주 현황\",\n        format.args = list(big.mark = \",\", digits = 1, scientific = 6)) %>%\n    kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n    kableExtra::add_header_above(c(` ` = 1, `범죄자수 (인구 만명 당)` = 3,\n        ` ` = 1)) %>%\n    kableExtra::kable_classic(full_width = TRUE)\n\n\n\nTable 1: 미국 범죄 상위 10개 주 현황\n\n\n\n\n\n범죄자수 (인구 만명 당)\n\n\n\n\n\n주 (State)\n\n\n살인범\n\n\n폭행범\n\n\n강간범\n\n\n도시인구수(백분율)\n\n\nFlorida\n\n\n15\n\n\n335\n\n\n32\n\n\n80\n\n\nNorth Carolina\n\n\n13\n\n\n337\n\n\n16\n\n\n45\n\n\nMaryland\n\n\n11\n\n\n300\n\n\n28\n\n\n67\n\n\nArizona\n\n\n8\n\n\n294\n\n\n31\n\n\n80\n\n\nNew Mexico\n\n\n11\n\n\n285\n\n\n32\n\n\n70\n\n\nCalifornia\n\n\n9\n\n\n276\n\n\n41\n\n\n91\n\n\nAlaska\n\n\n10\n\n\n263\n\n\n44\n\n\n48\n\n\nSouth Carolina\n\n\n14\n\n\n279\n\n\n22\n\n\n48\n\n\nNevada\n\n\n12\n\n\n252\n\n\n46\n\n\n81\n\n\nMichigan\n\n\n12\n\n\n255\n\n\n35\n\n\n74\n\n\n플롯(plots) 출력\n이 예제는 가상의 설명을 포함하고 있는, 그저 템플리트를 위한\n예제입니다.\n온도에 따른 수은의 증기압을 기록한 데이터인 pressure 데이터 프레임을\n산점도록 시각화합니다.\n\n\nplot(pressure, pch = 16, main = \"Relation between temperature and pressure\")\nlines(loess(pressure ~ temperature, pressure), col = \"steelblue\")\n\n\n\n\nFigure 1: 플롯 예제\n\n\n\n\n\n\n",
      "last_modified": "2023-01-01T01:34:34+09:00"
    },
    {
      "path": "index.html",
      "title": "텍스트 데이터 분석",
      "description": "텍스트 분석은 자연어로 구성된 대량의 비정형 텍스트 또는 사전 정의된 형식이 없는 텍스트를 처리하여 패턴이나 관계를 알아내어 의미있는 정보를 찾는 것을 말한다. 방대한 양의 비정형 텍스트 문서로부터 주요 토픽",
      "author": [
        {
          "name": "김동수",
          "url": "https://github.com/garnet-Kim"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n내가 기대하는 텍스트\n분석\n\n내가 기대하는 텍스트 분석\n연구자들은 텍스트 분석을 통해 짧은 시간에 많은 양의 기존\n문헌을 탐색하여 연구와 관련된 내용을 추출할 수\n있을 것이다.\n대통령 연설문 텍스트 분석을 통해 역대 대통령의 중심가치를\n파악할 수 있을 것이다.연설문에 나타난 단어의 빈도를\n분석하고 언어 네트워크 분석을 통해 역대\n대통령들의 중심가치 변화와 흐름을 분석할 수 있을 것이다.\n\n\n\n\n\n\n\n",
      "last_modified": "2023-01-01T00:53:12+09:00"
    }
  ],
  "collections": []
}
